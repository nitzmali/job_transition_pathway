{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import random\n",
    "import os \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "# Set a random seed for reproducibility\n",
    "seed_value = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "import pandas as pd \n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Bidirectional\n",
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "## load job models \n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import pickle\n",
    "encoder_model = load_model('/Users/nyzy/Library/CloudStorage/GoogleDrive-nitinmali999@gmail.com/.shortcut-targets-by-id/1yEbTjc1DwwTDd2CB86Il6F-3DhFUn8pU/Data Mining/data/processed_datasets/processed_datasets_v2/models/job/encoder_model.h5')\n",
    "\n",
    "# Save the decoder model\n",
    "decoder_model = load_model('/Users/nyzy/Library/CloudStorage/GoogleDrive-nitinmali999@gmail.com/.shortcut-targets-by-id/1yEbTjc1DwwTDd2CB86Il6F-3DhFUn8pU/Data Mining/data/processed_datasets/processed_datasets_v2/models/job/decoder_model.h5')\n",
    "\n",
    "with open('/Users/nyzy/Library/CloudStorage/GoogleDrive-nitinmali999@gmail.com/.shortcut-targets-by-id/1yEbTjc1DwwTDd2CB86Il6F-3DhFUn8pU/Data Mining/data/processed_datasets/processed_datasets_v2/models/job/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer_j_p = pickle.load(handle)\n",
    "\n",
    "def decode_sequence_job(input_seq):\n",
    "    # Encode the input sequence to get the internal states\n",
    "    states_value = encoder_model.predict(input_seq,verbose=0)\n",
    "\n",
    "    # Generate empty target sequence of length 1 with only the start token\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    start_token_index = tokenizer_j_p.word_index['start']  # Assuming you have a 'start' token\n",
    "    target_seq[0, 0] = start_token_index\n",
    "\n",
    "    # Sampling loop to generate sequence\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token and add its corresponding word to the decoded sequence\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = tokenizer_j_p.index_word[sampled_token_index]\n",
    "        if sampled_word != 'end':  # Assuming you have an 'end' token\n",
    "            decoded_sentence += ' ' + sampled_word\n",
    "\n",
    "        # Exit condition: either hit max length or find stop token\n",
    "        if sampled_word == 'end' or len(decoded_sentence) > 50:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1) and states\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "## load job test data \n",
    "\n",
    "tokenizer_j_e = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = TFAutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer_j_e(text, return_tensors=\"tf\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(inputs)\n",
    "    return tf.reduce_mean(outputs.last_hidden_state, 1).numpy()[0]  # Mean pooling\n",
    "\n",
    "def batch_encode(texts, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer_j_e(batch, return_tensors=\"tf\", padding=True, truncation=True, max_length=512)\n",
    "        outputs = model(inputs)\n",
    "        batch_embeddings = tf.reduce_mean(outputs.last_hidden_state, 1).numpy()\n",
    "        embeddings.extend(batch_embeddings)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "\n",
    "df_j = pd.read_csv(\"/Users/nyzy/Library/CloudStorage/GoogleDrive-nitinmali999@gmail.com/.shortcut-targets-by-id/1yEbTjc1DwwTDd2CB86Il6F-3DhFUn8pU/Data Mining/data/processed_datasets/processed_datasets_v2/original_data/jobs.csv\")\n",
    "df_user = df_j[df_j[\"Current Job\"]==\"data scientist\"][0:1]\n",
    "\n",
    "def predict_job(df_user):\n",
    "    text_columns = ['Current Job', 'Next Job', 'Current Skills']\n",
    "    embeddings_dict_user = {}\n",
    "    for col in text_columns:\n",
    "        embeddings_dict_user[col] = batch_encode(df_user[col].tolist())\n",
    "\n",
    "    feature_columns = ['Current Job', 'Current Skills']\n",
    "    # Stack embeddings horizontally (axis=1)\n",
    "    user_embedding = np.hstack((embeddings_dict_user[each] for each in feature_columns)) \n",
    "\n",
    "    user_embedding.shape\n",
    "    user_embedding = user_embedding.reshape(1, len(feature_columns), -1)\n",
    "\n",
    "    X_user_tensor = tf.convert_to_tensor(user_embedding, dtype=tf.float32)\n",
    "    next_job = decode_sequence_job(X_user_tensor[0:1])\n",
    "    return  next_job.replace(\"start \",\"\").lstrip().rstrip()\n",
    "#predict_job(df_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/17/gws30jys63j9xx5l0mwr5r4r0000gq/T/ipykernel_72876/1555905880.py:9: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  user_embedding = np.hstack((embeddings_dict_user[each] for each in feature_columns))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1 and the array at index 1 has size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[190], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     next_job \u001b[39m=\u001b[39m decode_sequence_job(X_user_tensor[\u001b[39m0\u001b[39m:\u001b[39m1\u001b[39m])\n\u001b[1;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m  next_job\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mstart \u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mlstrip()\u001b[39m.\u001b[39mrstrip()\n\u001b[0;32m---> 18\u001b[0m predict_job([\u001b[39m\"\u001b[39;49m\u001b[39mdata product manager\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39manalytics, project management, business analysis, agile software development\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "Cell \u001b[0;32mIn[190], line 9\u001b[0m, in \u001b[0;36mpredict_job\u001b[0;34m(df_user)\u001b[0m\n\u001b[1;32m      5\u001b[0m     embeddings_dict_user[name] \u001b[39m=\u001b[39m batch_encode(col)\n\u001b[1;32m      8\u001b[0m \u001b[39m# Stack embeddings horizontally (axis=1)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m user_embedding \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mhstack((embeddings_dict_user[each] \u001b[39mfor\u001b[39;49;00m each \u001b[39min\u001b[39;49;00m feature_columns)) \n\u001b[1;32m     11\u001b[0m user_embedding\u001b[39m.\u001b[39mshape\n\u001b[1;32m     12\u001b[0m user_embedding \u001b[39m=\u001b[39m user_embedding\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(feature_columns), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/sandbox/lib/python3.9/site-packages/numpy/core/shape_base.py:370\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39mconcatenate(arrs, \u001b[39m0\u001b[39m, dtype\u001b[39m=\u001b[39mdtype, casting\u001b[39m=\u001b[39mcasting)\n\u001b[1;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 370\u001b[0m     \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m1\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, casting\u001b[39m=\u001b[39;49mcasting)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1 and the array at index 1 has size 3"
     ]
    }
   ],
   "source": [
    "def predict_job(df_user):\n",
    "    feature_columns = ['Current Job', 'Current Skills']\n",
    "    embeddings_dict_user = {}\n",
    "    for col,name in zip(df_user,feature_columns):\n",
    "        embeddings_dict_user[name] = batch_encode(col)\n",
    "\n",
    "\n",
    "    # Stack embeddings horizontally (axis=1)\n",
    "    user_embedding = np.hstack((embeddings_dict_user[each] for each in feature_columns)) \n",
    "\n",
    "    user_embedding.shape\n",
    "    user_embedding = user_embedding.reshape(1, len(feature_columns), -1)\n",
    "\n",
    "    X_user_tensor = tf.convert_to_tensor(user_embedding, dtype=tf.float32)\n",
    "    next_job = decode_sequence_job(X_user_tensor[0:1])\n",
    "    return  next_job.replace(\"start \",\"\").lstrip().rstrip()\n",
    "\n",
    "predict_job([\"software\",\"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Current Job</th>\n",
       "      <th>Next Job</th>\n",
       "      <th>Current Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>director of product management</td>\n",
       "      <td>chief product officer</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>business analyst</td>\n",
       "      <td>senior business analyst</td>\n",
       "      <td>java, sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>data product manager</td>\n",
       "      <td>senior data product manager</td>\n",
       "      <td>analytics, project management, business analysis, agile software development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>senior data analyst</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>bigquery, python, sql, airflow, problem solving, data pipelines, data driven decision making, analytics, data visualization, data engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>database administrator</td>\n",
       "      <td>senior database administrator</td>\n",
       "      <td>data modeling, sql, data quality, pl sql, java, data cleansing, database systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4228</th>\n",
       "      <td>34164</td>\n",
       "      <td>director of business intelligence</td>\n",
       "      <td>chief information officer</td>\n",
       "      <td>power bi, data modeling, data warehousing, machine learning, data governance, data driven decision making, analytics, amazon redshift, business intelligence, data mining, data visualization, artificial intelligence, visualization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4229</th>\n",
       "      <td>34176</td>\n",
       "      <td>quantitative research manager</td>\n",
       "      <td>senior data architect</td>\n",
       "      <td>project management, business analysis, statistical analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4230</th>\n",
       "      <td>34177</td>\n",
       "      <td>machine learning manager</td>\n",
       "      <td>senior business analyst</td>\n",
       "      <td>devops, computer science, computer vision, data maintenance, nlp, data collection, machine learning, code review, deep learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>34194</td>\n",
       "      <td>director of business intelligence</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>database queries, power bi, sql, computer science, database marketing, data analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>34212</td>\n",
       "      <td>quantitative research manager</td>\n",
       "      <td>senior machine learning engineer</td>\n",
       "      <td>digital data, data driven decision making, generative ai, statistical, machine learning, artificial intelligence, data science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4233 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                        Current Job  \\\n",
       "0              0     director of product management   \n",
       "1              1                   business analyst   \n",
       "2              2               data product manager   \n",
       "3              3                senior data analyst   \n",
       "4              4             database administrator   \n",
       "...          ...                                ...   \n",
       "4228       34164  director of business intelligence   \n",
       "4229       34176      quantitative research manager   \n",
       "4230       34177           machine learning manager   \n",
       "4231       34194  director of business intelligence   \n",
       "4232       34212      quantitative research manager   \n",
       "\n",
       "                              Next Job  \\\n",
       "0                chief product officer   \n",
       "1              senior business analyst   \n",
       "2          senior data product manager   \n",
       "3                        data engineer   \n",
       "4        senior database administrator   \n",
       "...                                ...   \n",
       "4228         chief information officer   \n",
       "4229             senior data architect   \n",
       "4230           senior business analyst   \n",
       "4231                     data engineer   \n",
       "4232  senior machine learning engineer   \n",
       "\n",
       "                                                                                                                                                                                                                             Current Skills  \n",
       "0                                                                                                                                                                                                                                         c  \n",
       "1                                                                                                                                                                                                                                 java, sql  \n",
       "2                                                                                                                                                              analytics, project management, business analysis, agile software development  \n",
       "3                                                                                             bigquery, python, sql, airflow, problem solving, data pipelines, data driven decision making, analytics, data visualization, data engineering  \n",
       "4                                                                                                                                                          data modeling, sql, data quality, pl sql, java, data cleansing, database systems  \n",
       "...                                                                                                                                                                                                                                     ...  \n",
       "4228  power bi, data modeling, data warehousing, machine learning, data governance, data driven decision making, analytics, amazon redshift, business intelligence, data mining, data visualization, artificial intelligence, visualization  \n",
       "4229                                                                                                                                                                            project management, business analysis, statistical analysis  \n",
       "4230                                                                                                        devops, computer science, computer vision, data maintenance, nlp, data collection, machine learning, code review, deep learning  \n",
       "4231                                                                                                                                                   database queries, power bi, sql, computer science, database marketing, data analysis  \n",
       "4232                                                                                                         digital data, data driven decision making, generative ai, statistical, machine learning, artificial intelligence, data science  \n",
       "\n",
       "[4233 rows x 4 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#load skills models \n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import pickle\n",
    "encoder_model_s = load_model('/Users/nyzy/Library/CloudStorage/GoogleDrive-nitinmali999@gmail.com/.shortcut-targets-by-id/1yEbTjc1DwwTDd2CB86Il6F-3DhFUn8pU/Data Mining/data/processed_datasets/processed_datasets_v2/models/skills/encoder_model.h5')\n",
    "\n",
    "# Save the decoder model\n",
    "decoder_model_s = load_model('/Users/nyzy/Library/CloudStorage/GoogleDrive-nitinmali999@gmail.com/.shortcut-targets-by-id/1yEbTjc1DwwTDd2CB86Il6F-3DhFUn8pU/Data Mining/data/processed_datasets/processed_datasets_v2/models/skills/decoder_model.h5')\n",
    "\n",
    "with open('/Users/nyzy/Library/CloudStorage/GoogleDrive-nitinmali999@gmail.com/.shortcut-targets-by-id/1yEbTjc1DwwTDd2CB86Il6F-3DhFUn8pU/Data Mining/data/processed_datasets/processed_datasets_v2/models/skills/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer_s_p = pickle.load(handle)\n",
    "\n",
    "def decode_sequence_skills(input_seq):\n",
    "    # Encode the input sequence to get the internal states\n",
    "    states_value = encoder_model_s.predict(input_seq,verbose=0)\n",
    "\n",
    "    # Generate empty target sequence of length 1 with only the start token\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    start_token_index = tokenizer_s_p.word_index['start']  # Assuming you have a 'start' token\n",
    "    target_seq[0, 0] = start_token_index\n",
    "\n",
    "    # Sampling loop to generate sequence\n",
    "    stop_condition = False\n",
    "    decoded_sequence = []\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model_s.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = tokenizer_s_p.index_word.get(sampled_token_index, '?')\n",
    "\n",
    "        # Check for 'end' token or maximum length\n",
    "        if sampled_word == 'end' or len(decoded_sequence) > 50:  # 'end' is your end-of-sequence token\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sequence.append(sampled_word)\n",
    "\n",
    "        # Update the target sequence (of length 1) and states\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "\n",
    "    # Join the words with a comma\n",
    "    decoded_sentence = ', '.join(decoded_sequence)\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "## load skills test data \n",
    "\n",
    "tokenizer_s_e = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = TFAutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer_s_e(text, return_tensors=\"tf\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(inputs)\n",
    "    return tf.reduce_mean(outputs.last_hidden_state, 1).numpy()[0]  # Mean pooling\n",
    "\n",
    "def batch_encode(texts, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer_s_e(batch, return_tensors=\"tf\", padding=True, truncation=True, max_length=512)\n",
    "        outputs = model(inputs)\n",
    "        batch_embeddings = tf.reduce_mean(outputs.last_hidden_state, 1).numpy()\n",
    "        embeddings.extend(batch_embeddings)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "\n",
    "#df = pd.read_csv(\"//Users/nyzy/Library/CloudStorage/GoogleDrive-nitinmali999@gmail.com/.shortcut-targets-by-id/1yEbTjc1DwwTDd2CB86Il6F-3DhFUn8pU/Data Mining/data/processed_datasets/processed_datasets_v2/original_data/skills.csv\")\n",
    "#df_user = df[df[\"Current Job\"]==\"data scientist\"][0:1]\n",
    "\n",
    "def predict_skills(df_user):\n",
    "    embeddings_dict_user_skills = {}\n",
    "    text_columns = ['Current Job', 'Next Job', 'Current Skills']\n",
    "    for col in text_columns:\n",
    "        embeddings_dict_user_skills[col] = batch_encode(df_user[col].tolist())\n",
    "\n",
    "    feature_columns = ['Current Job', 'Next Job','Current Skills']\n",
    "    #print(embeddings_dict_user_skills.keys())\n",
    "    # Stack embeddings horizontally (axis=1)\n",
    "    user_embedding = np.hstack([embeddings_dict_user_skills[each] for each in feature_columns]) \n",
    "\n",
    "    user_embedding.shape\n",
    "    user_embedding = user_embedding.reshape(1, len(feature_columns), -1)\n",
    "\n",
    "    X_user_tensor = tf.convert_to_tensor(user_embedding, dtype=tf.float32)\n",
    "    next_skills = decode_sequence_skills(X_user_tensor[0:1]).strip().lstrip().rstrip()\n",
    "    next_skills = next_skills.replace(\"start \",\"\").replace(\"end \",\"\").strip().lstrip().rstrip()\n",
    "    return next_skills\n",
    "#predict_skills(df_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_course_score(course, skill_gap, weight_skill_match=1, weight_subscribers=0.001, weight_rating=0.5):\n",
    "    # Calculate the proportion of skill gap covered by course\n",
    "    skills_matched = sum(skill in course['skills_tagged'] for skill in skill_gap)\n",
    "    skill_match_score = skills_matched / len(skill_gap) if skill_gap else 0\n",
    "\n",
    "    # Factor in course popularity and rating\n",
    "    #subscriber_score = course['num_subscribers'] * weight_subscribers if 'num_subscribers' in course else 0\n",
    "    #rating_score = course['rating'] * weight_rating if 'rating' in course else 0\n",
    "\n",
    "    # Calculate total score\n",
    "    total_score = (skill_match_score * weight_skill_match) #+ subscriber_score + rating_score\n",
    "    return total_score\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_c_cleaned[\"full_description\"])\n",
    "\n",
    "def calculate_similarity_score(skill_gap,df_c_cleaned):\n",
    "\n",
    "    def preprocess_text(text):\n",
    "        return \" \".join(token.lemma_.lower() for token in nlp(text) if not token.is_punct and not token.is_stop)\n",
    "\n",
    "    skill_gap_text = \" \".join(skill_gap)\n",
    "    # Vectorize the text\n",
    "\n",
    "    skill_gap_vec = tfidf_vectorizer.transform([skill_gap_text])\n",
    "    # Calculate cosine similarity\n",
    "    cosine_similarities = cosine_similarity(skill_gap_vec, tfidf_matrix).flatten()\n",
    "    df_c_cleaned[\"cosine_score\"]=cosine_similarities\n",
    "    return df_c_cleaned\n",
    "\n",
    "\n",
    "def select_relevant_course( skill_gap):\n",
    "    # Define the course_prediction function\n",
    "    df_c_cleaned = pd.read_csv(\"/Users/nyzy/Library/CloudStorage/GoogleDrive-nitinmali999@gmail.com/.shortcut-targets-by-id/1yEbTjc1DwwTDd2CB86Il6F-3DhFUn8pU/Data Mining/data/processed_datasets/course_cleaned.csv\")\n",
    "    df_c_cleaned=df_c_cleaned.rename(columns={\"Unnamed: 0\":\"course_number\"})\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df_c_cleaned[\"full_description\"])\n",
    "    # Apply the scoring function to each course\n",
    "    #df_c_cleaned['course_score'] = df_c_cleaned.apply(calculate_course_score, axis=1, skill_gap=skill_gap)\n",
    "    df_c_cleaned = calculate_similarity_score(skill_gap,df_c_cleaned)\n",
    "    # Sort courses based on the calculated score\n",
    "    #df_c_cleaned = df_c_cleaned.sort_values(by='course_score', ascending=False)\n",
    "    df_c_cleaned = df_c_cleaned.sort_values(by='cosine_score', ascending=False)\n",
    "    # Select the top course if available\n",
    "    top_course = df_c_cleaned[[\"course_display_name\",\"full_description\"]].iloc[0] if not df_c_cleaned.empty else None\n",
    "    top_10_course_number = df_c_cleaned[\"course_number\"].iloc[0:10].tolist()\n",
    "    top_10_course_number_score = {x:round(y,3) for x,y in zip(df_c_cleaned[\"course_number\"].iloc[0:10].tolist(),df_c_cleaned[\"cosine_score\"].iloc[0:10].tolist())}\n",
    "    df_c_cleaned[[\"course_title\",'skills_tagged','title','course_number']]\n",
    "    top_10_title = set(df_c_cleaned[\"title\"].iloc[0:10].tolist())\n",
    "    top_10_course_title = set(df_c_cleaned[\"course_title\"].iloc[0:10].tolist())\n",
    "    all_skills_learnt = set(each for each in df_c_cleaned[\"course_title\"].iloc[0:10].tolist())\n",
    "    return top_10_title,all_skills_learnt,top_10_course_title\n",
    "\n",
    "#top_course,top_10_course_number_score,top_10_course_number = select_relevant_course(df_c_cleaned,['python', 'power bi', 'sql'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/17/gws30jys63j9xx5l0mwr5r4r0000gq/T/ipykernel_72876/1938645940.py:34: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  user_embedding = np.hstack((embeddings_dict_user[each] for each in feature_columns))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "dict_keys(['Current Job', 'Next Job', 'Current Skills'])\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "predicted Job:  data engineer\n",
      "Predicted Skills:  python,  sql,  computer science,  database design,  data quality,  data analysis,  data collection,  data management,  data mining\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "dict_keys(['Current Job', 'Next Job', 'Current Skills'])\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "predicted Job:  senior data engineer\n",
      "Predicted Skills:  python,  sql,  computer science,  azure blob storage,  data pipelines,  data integration,  analytics,  apache spark,  azure data factory,  databricks,  data engineering\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "dict_keys(['Current Job', 'Next Job', 'Current Skills'])\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted Job:  data architect\n",
      "Predicted Skills:  ci cd,  data modeling,  sql,  data strategy,  data architecture,  business analysis,  business analysis,  data quality,  data governance,  analytics,  data management,  pl sql\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "dict_keys(['Current Job', 'Next Job', 'Current Skills'])\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "predicted Job:  data manager\n",
      "Predicted Skills:  quantitative analysis,  sql,  data access,  computer science,  statistical analysis,  data driven decision making,  business requirements,  analytical techniques\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "dict_keys(['Current Job', 'Next Job', 'Current Skills'])\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted Job:  director of analytics\n",
      "Predicted Skills:  analytics,  project management,  data science\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "dict_keys(['Current Job', 'Next Job', 'Current Skills'])\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted Job:  chief data officer\n",
      "Predicted Skills:  predictive analytics,  data modeling,  data strategy,  data strategy,  problem solving,  data quality,  data governance,  data governance,  analytics,  business requirements,  data management,  business intelligence,  cloud storage,  data literacy,  data engineering,  big data,  business performance management\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Job Title</th>\n",
       "      <th>Predicted Skills</th>\n",
       "      <th>top_10_predicted_course_category</th>\n",
       "      <th>all_skills_learnt</th>\n",
       "      <th>top_10_predicted_course_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data engineer</td>\n",
       "      <td>python,  sql,  computer science,  database design,  data quality,  data analysis,  data collection,  data management,  data mining</td>\n",
       "      <td>{data science machine learning data analytics, data mining, improving data quality data analytics machine learning, intro data data science, introduction data science, getting started data management, python data science learn data science scratch, datascience machine learning nlp python r bigdata pyspark, data collection beginners, data science python complete guide}</td>\n",
       "      <td>{data quality management, data mining, database management, data science}</td>\n",
       "      <td>{data quality management, data mining, database management, data science}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>senior data engineer</td>\n",
       "      <td>python,  sql,  computer science,  azure blob storage,  data pipelines,  data integration,  analytics,  apache spark,  azure data factory,  databricks,  data engineering</td>\n",
       "      <td>{azure cloud azure databricks apache spark machine learning, azure data engineer workshop weekend, microsoft azure databricks data engineering, machine learning, real world azure data engineer project end end, python sdk azure bootcamp, azure databricks build data engineering ai ml pipeline, azure data factory data engineering cloud, azure databricks spark sql python, apache spark master big data pyspark databricks}</td>\n",
       "      <td>{azure synapse analytics, azure data factory, undefined, apache spark, databricks, microsoft azure}</td>\n",
       "      <td>{azure synapse analytics, azure data factory, undefined, apache spark, databricks, microsoft azure}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data architect</td>\n",
       "      <td>ci cd,  data modeling,  sql,  data strategy,  data architecture,  business analysis,  business analysis,  data quality,  data governance,  analytics,  data management,  pl sql</td>\n",
       "      <td>{data science machine learning data analytics, data scientist sql tableau ml dl, python data analytics beginner advanced, python sql, introduction data science, getting started data management, sql, complete sql bootcamp data analysis level, sql data visualization complete bootcamp}</td>\n",
       "      <td>{oracle sql, data science, database management, big data, data analysis, sql}</td>\n",
       "      <td>{oracle sql, data science, database management, big data, data analysis, sql}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data manager</td>\n",
       "      <td>quantitative analysis,  sql,  data access,  computer science,  statistical analysis,  data driven decision making,  business requirements,  analytical techniques</td>\n",
       "      <td>{statistics data analytics, data science machine learning python, data science machine learning data analytics, data analyst python beginners, python sql, introduction data science, data science interview questions answers, r data analysis statistics data science, master data analysis pandas, data science r}</td>\n",
       "      <td>{sql, undefined, data science, data analysis}</td>\n",
       "      <td>{sql, undefined, data science, data analysis}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>director of analytics</td>\n",
       "      <td>analytics,  project management,  data science</td>\n",
       "      <td>{complete data science project management course, data analytics python projects hindi, statistics data science business analytics python, introduction data science, getting started data management, data analytics python, practical guide alteryx data science analytics, introduction data science python module, data science complete beginners, cdmp metadata specialist exam questions practitioner master}</td>\n",
       "      <td>{data mining, data science, database management, data analysis, automation, undefined}</td>\n",
       "      <td>{data mining, data science, database management, data analysis, automation, undefined}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chief data officer</td>\n",
       "      <td>predictive analytics,  data modeling,  data strategy,  data strategy,  problem solving,  data quality,  data governance,  data governance,  analytics,  business requirements,  data management,  business intelligence,  cloud storage,  data literacy,  data engineering,  big data,  business performance management</td>\n",
       "      <td>{x data management governance security ethics masterclass, python data analytics beginner advanced, data science fundamentals, probability statistics data science, intro data data science, introduction data science, getting started data management, big data, cdmp metadata specialist exam questions practitioner master, data analytics crash course}</td>\n",
       "      <td>{data science, data quality management, big data, database management, data analysis, undefined}</td>\n",
       "      <td>{data science, data quality management, big data, database management, data analysis, undefined}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Predicted Job Title  \\\n",
       "0          data engineer   \n",
       "1   senior data engineer   \n",
       "2         data architect   \n",
       "3           data manager   \n",
       "4  director of analytics   \n",
       "5     chief data officer   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                          Predicted Skills  \\\n",
       "0                                                                                                                                                                                       python,  sql,  computer science,  database design,  data quality,  data analysis,  data collection,  data management,  data mining   \n",
       "1                                                                                                                                                 python,  sql,  computer science,  azure blob storage,  data pipelines,  data integration,  analytics,  apache spark,  azure data factory,  databricks,  data engineering   \n",
       "2                                                                                                                                          ci cd,  data modeling,  sql,  data strategy,  data architecture,  business analysis,  business analysis,  data quality,  data governance,  analytics,  data management,  pl sql   \n",
       "3                                                                                                                                                        quantitative analysis,  sql,  data access,  computer science,  statistical analysis,  data driven decision making,  business requirements,  analytical techniques   \n",
       "4                                                                                                                                                                                                                                                                            analytics,  project management,  data science   \n",
       "5  predictive analytics,  data modeling,  data strategy,  data strategy,  problem solving,  data quality,  data governance,  data governance,  analytics,  business requirements,  data management,  business intelligence,  cloud storage,  data literacy,  data engineering,  big data,  business performance management   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                      top_10_predicted_course_category  \\\n",
       "0                                                   {data science machine learning data analytics, data mining, improving data quality data analytics machine learning, intro data data science, introduction data science, getting started data management, python data science learn data science scratch, datascience machine learning nlp python r bigdata pyspark, data collection beginners, data science python complete guide}   \n",
       "1  {azure cloud azure databricks apache spark machine learning, azure data engineer workshop weekend, microsoft azure databricks data engineering, machine learning, real world azure data engineer project end end, python sdk azure bootcamp, azure databricks build data engineering ai ml pipeline, azure data factory data engineering cloud, azure databricks spark sql python, apache spark master big data pyspark databricks}   \n",
       "2                                                                                                                                          {data science machine learning data analytics, data scientist sql tableau ml dl, python data analytics beginner advanced, python sql, introduction data science, getting started data management, sql, complete sql bootcamp data analysis level, sql data visualization complete bootcamp}   \n",
       "3                                                                                                                {statistics data analytics, data science machine learning python, data science machine learning data analytics, data analyst python beginners, python sql, introduction data science, data science interview questions answers, r data analysis statistics data science, master data analysis pandas, data science r}   \n",
       "4                 {complete data science project management course, data analytics python projects hindi, statistics data science business analytics python, introduction data science, getting started data management, data analytics python, practical guide alteryx data science analytics, introduction data science python module, data science complete beginners, cdmp metadata specialist exam questions practitioner master}   \n",
       "5                                                                         {x data management governance security ethics masterclass, python data analytics beginner advanced, data science fundamentals, probability statistics data science, intro data data science, introduction data science, getting started data management, big data, cdmp metadata specialist exam questions practitioner master, data analytics crash course}   \n",
       "\n",
       "                                                                                     all_skills_learnt  \\\n",
       "0                            {data quality management, data mining, database management, data science}   \n",
       "1  {azure synapse analytics, azure data factory, undefined, apache spark, databricks, microsoft azure}   \n",
       "2                        {oracle sql, data science, database management, big data, data analysis, sql}   \n",
       "3                                                        {sql, undefined, data science, data analysis}   \n",
       "4               {data mining, data science, database management, data analysis, automation, undefined}   \n",
       "5     {data science, data quality management, big data, database management, data analysis, undefined}   \n",
       "\n",
       "                                                                         top_10_predicted_course_title  \n",
       "0                            {data quality management, data mining, database management, data science}  \n",
       "1  {azure synapse analytics, azure data factory, undefined, apache spark, databricks, microsoft azure}  \n",
       "2                        {oracle sql, data science, database management, big data, data analysis, sql}  \n",
       "3                                                        {sql, undefined, data science, data analysis}  \n",
       "4               {data mining, data science, database management, data analysis, automation, undefined}  \n",
       "5     {data science, data quality management, big data, database management, data analysis, undefined}  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_job,final_job = \"data analyst\",\"big data engineer\"\n",
    "current_skills,next_skills=\"\",\"\"\n",
    "predictions_dictionary = {}\n",
    "df_j = pd.read_csv(\"/Users/nyzy/Library/CloudStorage/GoogleDrive-nitinmali999@gmail.com/.shortcut-targets-by-id/1yEbTjc1DwwTDd2CB86Il6F-3DhFUn8pU/Data Mining/data/processed_datasets/processed_datasets_v2/original_data/jobs.csv\")\n",
    "i=0\n",
    "while current_job!=final_job and i<=5:\n",
    "    df_user = df_j[df_j[\"Current Job\"]==current_job]\n",
    "    df_user = df_user.sample(n=1)\n",
    "    #print(len(df_user))\n",
    "    current_job = predict_job(df_user)\n",
    "    i+=1\n",
    "    current_skills = predict_skills(df_user)\n",
    "    print(\"predicted Job: \",current_job)\n",
    "    print(\"Predicted Skills: \",current_skills)\n",
    "    predictions_dictionary[current_job]=current_skills\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "def course_prediction(skill_gap):\n",
    "    df_c_cleaned = pd.read_csv(\"/Users/nyzy/Library/CloudStorage/GoogleDrive-nitinmali999@gmail.com/.shortcut-targets-by-id/1yEbTjc1DwwTDd2CB86Il6F-3DhFUn8pU/Data Mining/data/processed_datasets/course_cleaned.csv\")\n",
    "    df_c_cleaned=df_c_cleaned.rename(columns={\"Unnamed: 0\":\"course_number\"})\n",
    "    top_course, top_10_course_number_score, top_10_course_number = select_relevant_course( skill_gap)\n",
    "    return (top_course, top_10_course_number_score, top_10_course_number)\n",
    "\n",
    "predictions_df = pd.DataFrame(list(predictions_dictionary.items()), columns=['Predicted Job Title', 'Predicted Skills'])\n",
    "\n",
    "\n",
    "\n",
    "# Apply the function and create a DataFrame from the results\n",
    "course_predictions = predictions_df[\"Predicted Skills\"].apply(lambda x: course_prediction(x.split(\",\"))).tolist()\n",
    "courses_df = pd.DataFrame(course_predictions, columns=[\"top_10_predicted_course_category\", \"all_skills_learnt\",\"top_10_predicted_course_title\"])\n",
    "\n",
    "# Concatenate with the original DataFrame\n",
    "predictions_df = pd.concat([predictions_df, courses_df], axis=1)\n",
    "predictions_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "Job_progression_dictionary_file_path = \"/Users/nyzy/Library/CloudStorage/GoogleDrive-nitinmali999@gmail.com/.shortcut-targets-by-id/1yEbTjc1DwwTDd2CB86Il6F-3DhFUn8pU/Data Mining/data/processed_datasets/job_progression_dictionary.json\"\n",
    "\n",
    "with open(Job_progression_dictionary_file_path, 'r') as json_file:\n",
    "    sorted_full_job_progression_dict_lower = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ai architect': ['ai project manager', 'head of ai', 'chief ai officer'],\n",
       " 'ai developer': ['senior ai developer',\n",
       "  'ai architect',\n",
       "  'ai project manager',\n",
       "  'head of ai',\n",
       "  'chief ai officer'],\n",
       " 'ai project manager': ['head of ai', 'chief ai officer'],\n",
       " 'big data architect': ['head of big data',\n",
       "  'director of data engineering',\n",
       "  'chief information officer'],\n",
       " 'big data engineer': ['senior big data engineer',\n",
       "  'big data architect',\n",
       "  'head of big data',\n",
       "  'director of data engineering',\n",
       "  'chief information officer'],\n",
       " 'business analysis manager': ['business intelligence analyst',\n",
       "  'director of business analysis',\n",
       "  'chief strategy officer',\n",
       "  'data analyst',\n",
       "  'data scientist'],\n",
       " 'business analyst': ['senior business analyst',\n",
       "  'business analysis manager',\n",
       "  'business intelligence analyst',\n",
       "  'director of business analysis',\n",
       "  'chief strategy officer',\n",
       "  'data analyst',\n",
       "  'data scientist'],\n",
       " 'business intelligence analyst': ['senior business intelligence analyst',\n",
       "  'business intelligence manager',\n",
       "  'director of business intelligence',\n",
       "  'vice president of business intelligence',\n",
       "  'chief intelligence officer'],\n",
       " 'business intelligence manager': ['director of business intelligence',\n",
       "  'vice president of business intelligence',\n",
       "  'chief intelligence officer'],\n",
       " 'chief ai officer': [],\n",
       " 'chief data officer': [],\n",
       " 'chief data scientist': [],\n",
       " 'chief information officer': [],\n",
       " 'chief intelligence officer': [],\n",
       " 'chief product officer': ['big data engineer',\n",
       "  'senior big data engineer',\n",
       "  'big data architect',\n",
       "  'head of big data',\n",
       "  'director of data engineering',\n",
       "  'chief information officer'],\n",
       " 'chief science officer': [],\n",
       " 'chief strategy officer': [],\n",
       " 'chief technology officer': [],\n",
       " 'data analyst': ['data engineer',\n",
       "  'senior data engineer',\n",
       "  'lead data engineer',\n",
       "  'data architect',\n",
       "  'senior data architect',\n",
       "  'enterprise architect',\n",
       "  'product analyst',\n",
       "  'data product manager',\n",
       "  'senior data product manager',\n",
       "  'director of product management',\n",
       "  'vice president of product',\n",
       "  'chief product officer',\n",
       "  'big data engineer',\n",
       "  'senior big data engineer',\n",
       "  'big data architect',\n",
       "  'head of big data',\n",
       "  'director of data engineering',\n",
       "  'chief information officer',\n",
       "  'machine learning engineer'],\n",
       " 'data architect': ['data manager',\n",
       "  'director of analytics',\n",
       "  'chief data officer'],\n",
       " 'data engineer': ['senior data engineer',\n",
       "  'lead data engineer',\n",
       "  'data architect',\n",
       "  'data manager',\n",
       "  'director of analytics',\n",
       "  'chief data officer'],\n",
       " 'data engineering manager': ['director of data engineering',\n",
       "  'chief technology officer'],\n",
       " 'data manager': ['director of analytics', 'chief data officer'],\n",
       " 'data pipeline architect': ['data engineering manager',\n",
       "  'director of data engineering',\n",
       "  'chief technology officer'],\n",
       " 'data product manager': ['senior data product manager',\n",
       "  'director of product management',\n",
       "  'vice president of product',\n",
       "  'chief product officer',\n",
       "  'big data engineer',\n",
       "  'senior big data engineer',\n",
       "  'big data architect',\n",
       "  'head of big data',\n",
       "  'director of data engineering',\n",
       "  'chief information officer'],\n",
       " 'data science manager': ['director of data science',\n",
       "  'vice president of data science',\n",
       "  'chief data scientist'],\n",
       " 'data scientist': ['senior data scientist',\n",
       "  'lead data scientist',\n",
       "  'principal data scientist',\n",
       "  'data science manager',\n",
       "  'director of data science',\n",
       "  'vice president of data science',\n",
       "  'chief data scientist'],\n",
       " 'database administrator': ['senior database administrator',\n",
       "  'database manager',\n",
       "  'data architect',\n",
       "  'director of database management',\n",
       "  'chief information officer'],\n",
       " 'database manager': ['data architect',\n",
       "  'director of database management',\n",
       "  'chief information officer'],\n",
       " 'director of analytics': ['chief data officer'],\n",
       " 'director of business analysis': ['chief strategy officer'],\n",
       " 'director of business intelligence': ['vice president of business intelligence',\n",
       "  'chief intelligence officer'],\n",
       " 'director of data engineering': ['chief technology officer'],\n",
       " 'director of data science': ['vice president of data science',\n",
       "  'chief data scientist'],\n",
       " 'director of database management': ['chief information officer'],\n",
       " 'director of product management': ['vice president of product',\n",
       "  'chief product officer',\n",
       "  'big data engineer',\n",
       "  'senior big data engineer',\n",
       "  'big data architect',\n",
       "  'head of big data',\n",
       "  'director of data engineering',\n",
       "  'chief information officer'],\n",
       " 'director of quantitative research': [],\n",
       " 'director of research': ['chief science officer'],\n",
       " 'enterprise architect': ['product analyst',\n",
       "  'data product manager',\n",
       "  'senior data product manager',\n",
       "  'director of product management',\n",
       "  'vice president of product',\n",
       "  'chief product officer',\n",
       "  'big data engineer',\n",
       "  'senior big data engineer',\n",
       "  'big data architect',\n",
       "  'head of big data',\n",
       "  'director of data engineering',\n",
       "  'chief information officer'],\n",
       " 'head of ai': ['chief ai officer'],\n",
       " 'head of big data': ['director of data engineering',\n",
       "  'chief information officer'],\n",
       " 'head of machine learning': ['chief ai officer'],\n",
       " 'junior ai developer': ['ai developer',\n",
       "  'senior ai developer',\n",
       "  'ai architect',\n",
       "  'ai project manager',\n",
       "  'head of ai',\n",
       "  'chief ai officer',\n",
       "  'machine learning engineer',\n",
       "  'data engineer'],\n",
       " 'junior business analyst': ['business analyst',\n",
       "  'senior business analyst',\n",
       "  'business analysis manager',\n",
       "  'business intelligence analyst',\n",
       "  'director of business analysis',\n",
       "  'chief strategy officer',\n",
       "  'data analyst',\n",
       "  'data scientist'],\n",
       " 'junior data analyst': ['data analyst',\n",
       "  'senior data analyst',\n",
       "  'data engineer',\n",
       "  'senior data engineer',\n",
       "  'lead data engineer',\n",
       "  'data architect',\n",
       "  'data manager',\n",
       "  'director of analytics',\n",
       "  'chief data officer',\n",
       "  'business intelligence analyst',\n",
       "  'machine learning engineer',\n",
       "  'big data engineer'],\n",
       " 'junior data engineer': ['data engineer',\n",
       "  'senior data engineer',\n",
       "  'data pipeline architect',\n",
       "  'data engineering manager',\n",
       "  'director of data engineering',\n",
       "  'chief technology officer',\n",
       "  'machine learning engineer',\n",
       "  'big data engineer'],\n",
       " 'junior data scientist': ['data scientist',\n",
       "  'senior data scientist',\n",
       "  'lead data scientist',\n",
       "  'principal data scientist',\n",
       "  'data science manager',\n",
       "  'director of data science',\n",
       "  'vice president of data science',\n",
       "  'chief data scientist',\n",
       "  'data engineer',\n",
       "  'ai developer'],\n",
       " 'junior database administrator': ['database administrator',\n",
       "  'senior database administrator',\n",
       "  'database manager',\n",
       "  'data architect',\n",
       "  'director of database management',\n",
       "  'chief information officer'],\n",
       " 'junior statistician': ['statistician',\n",
       "  'senior statistician',\n",
       "  'quantitative analyst',\n",
       "  'senior quantitative analyst',\n",
       "  'quantitative research manager',\n",
       "  'director of quantitative research',\n",
       "  'data analyst',\n",
       "  'data scientist'],\n",
       " 'lead data engineer': ['data architect',\n",
       "  'data manager',\n",
       "  'director of analytics',\n",
       "  'chief data officer'],\n",
       " 'lead data scientist': ['principal data scientist',\n",
       "  'data science manager',\n",
       "  'director of data science',\n",
       "  'vice president of data science',\n",
       "  'chief data scientist'],\n",
       " 'machine learning architect': ['machine learning manager',\n",
       "  'head of machine learning',\n",
       "  'chief ai officer'],\n",
       " 'machine learning engineer': ['senior machine learning engineer',\n",
       "  'machine learning architect',\n",
       "  'machine learning manager',\n",
       "  'head of machine learning',\n",
       "  'chief ai officer'],\n",
       " 'machine learning manager': ['head of machine learning', 'chief ai officer'],\n",
       " 'principal data scientist': ['data science manager',\n",
       "  'director of data science',\n",
       "  'vice president of data science',\n",
       "  'chief data scientist'],\n",
       " 'principal scientist': ['director of research', 'chief science officer'],\n",
       " 'product analyst': ['data product manager',\n",
       "  'senior data product manager',\n",
       "  'director of product management',\n",
       "  'vice president of product',\n",
       "  'chief product officer',\n",
       "  'big data engineer',\n",
       "  'senior big data engineer',\n",
       "  'big data architect',\n",
       "  'head of big data',\n",
       "  'director of data engineering',\n",
       "  'chief information officer'],\n",
       " 'quantitative analyst': ['senior quantitative analyst',\n",
       "  'quantitative research manager',\n",
       "  'director of quantitative research'],\n",
       " 'quantitative research manager': ['director of quantitative research'],\n",
       " 'research analyst': ['research scientist',\n",
       "  'senior research scientist',\n",
       "  'principal scientist',\n",
       "  'director of research',\n",
       "  'chief science officer'],\n",
       " 'research assistant': ['research analyst',\n",
       "  'research scientist',\n",
       "  'senior research scientist',\n",
       "  'principal scientist',\n",
       "  'director of research',\n",
       "  'chief science officer',\n",
       "  'data scientist',\n",
       "  'statistician'],\n",
       " 'research scientist': ['senior research scientist',\n",
       "  'principal scientist',\n",
       "  'director of research',\n",
       "  'chief science officer'],\n",
       " 'senior ai developer': ['ai architect',\n",
       "  'ai project manager',\n",
       "  'head of ai',\n",
       "  'chief ai officer'],\n",
       " 'senior big data engineer': ['big data architect',\n",
       "  'head of big data',\n",
       "  'director of data engineering',\n",
       "  'chief information officer'],\n",
       " 'senior business analyst': ['business analysis manager',\n",
       "  'business intelligence analyst',\n",
       "  'director of business analysis',\n",
       "  'chief strategy officer',\n",
       "  'data analyst',\n",
       "  'data scientist'],\n",
       " 'senior business intelligence analyst': ['business intelligence manager',\n",
       "  'director of business intelligence',\n",
       "  'vice president of business intelligence',\n",
       "  'chief intelligence officer'],\n",
       " 'senior data analyst': ['data engineer',\n",
       "  'senior data engineer',\n",
       "  'lead data engineer',\n",
       "  'data architect',\n",
       "  'data manager',\n",
       "  'director of analytics',\n",
       "  'chief data officer',\n",
       "  'machine learning engineer',\n",
       "  'big data engineer'],\n",
       " 'senior data architect': ['enterprise architect',\n",
       "  'product analyst',\n",
       "  'data product manager',\n",
       "  'senior data product manager',\n",
       "  'director of product management',\n",
       "  'vice president of product',\n",
       "  'chief product officer',\n",
       "  'big data engineer',\n",
       "  'senior big data engineer',\n",
       "  'big data architect',\n",
       "  'head of big data',\n",
       "  'director of data engineering',\n",
       "  'chief information officer'],\n",
       " 'senior data engineer': ['lead data engineer',\n",
       "  'data architect',\n",
       "  'data manager',\n",
       "  'director of analytics',\n",
       "  'chief data officer'],\n",
       " 'senior data product manager': ['director of product management',\n",
       "  'vice president of product',\n",
       "  'chief product officer',\n",
       "  'big data engineer',\n",
       "  'senior big data engineer',\n",
       "  'big data architect',\n",
       "  'head of big data',\n",
       "  'director of data engineering',\n",
       "  'chief information officer'],\n",
       " 'senior data scientist': ['lead data scientist',\n",
       "  'principal data scientist',\n",
       "  'data science manager',\n",
       "  'director of data science',\n",
       "  'vice president of data science',\n",
       "  'chief data scientist'],\n",
       " 'senior database administrator': ['database manager',\n",
       "  'data architect',\n",
       "  'director of database management',\n",
       "  'chief information officer'],\n",
       " 'senior machine learning engineer': ['machine learning architect',\n",
       "  'machine learning manager',\n",
       "  'head of machine learning',\n",
       "  'chief ai officer'],\n",
       " 'senior quantitative analyst': ['quantitative research manager',\n",
       "  'director of quantitative research'],\n",
       " 'senior research scientist': ['principal scientist',\n",
       "  'director of research',\n",
       "  'chief science officer'],\n",
       " 'senior statistician': ['quantitative analyst',\n",
       "  'senior quantitative analyst',\n",
       "  'quantitative research manager',\n",
       "  'director of quantitative research'],\n",
       " 'statistician': ['senior statistician',\n",
       "  'quantitative analyst',\n",
       "  'senior quantitative analyst',\n",
       "  'quantitative research manager',\n",
       "  'director of quantitative research'],\n",
       " 'vice president of business intelligence': ['chief intelligence officer'],\n",
       " 'vice president of data science': ['chief data scientist'],\n",
       " 'vice president of product': ['chief product officer',\n",
       "  'big data engineer',\n",
       "  'senior big data engineer',\n",
       "  'big data architect',\n",
       "  'head of big data',\n",
       "  'director of data engineering',\n",
       "  'chief information officer']}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_full_job_progression_dict_lower"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75cbfe992e831883bebc34d351837a73fc44aae74ab7e2dffad989642b16aeb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
