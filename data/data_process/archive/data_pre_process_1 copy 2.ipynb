{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/nyzy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2023-11-11 18:53:37.851674: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None) \n",
    "from os import listdir\n",
    "import os\n",
    "import glob\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.scorer import Scorer\n",
    "import re\n",
    "import nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "job_path = \"/Users/nyzy/Library/CloudStorage/GoogleDrive-nitinmali999@gmail.com/.shortcut-targets-by-id/1yEbTjc1DwwTDd2CB86Il6F-3DhFUn8pU/Data Mining/data\"\n",
    "courses_path = \"/Users/nyzy/Library/CloudStorage/GoogleDrive-nitinmali999@gmail.com/.shortcut-targets-by-id/1yEbTjc1DwwTDd2CB86Il6F-3DhFUn8pU/Data Mining/courses_data\"\n",
    "skills_path = \"/Users/nyzy/Library/CloudStorage/GoogleDrive-nitinmali999@gmail.com/.shortcut-targets-by-id/1yEbTjc1DwwTDd2CB86Il6F-3DhFUn8pU/Data Mining/Datasets/skills_df_updated.csv\"\n",
    "data_path = \"/Users/nyzy/Library/CloudStorage/GoogleDrive-nitinmali999@gmail.com/.shortcut-targets-by-id/1yEbTjc1DwwTDd2CB86Il6F-3DhFUn8pU/Data Mining/data\"\n",
    "files_j= [f for f in listdir(job_path) if f.endswith(\".csv\")]\n",
    "df_j = pd.concat([pd.read_csv(os.path.join(job_path,f)) for f in files_j])\n",
    "\n",
    "files_c= [f for f in listdir(courses_path) if f.endswith(\".csv\")]\n",
    "df_c = pd.concat([pd.read_csv(os.path.join(courses_path,f)) for f in files_c])\n",
    "\n",
    "#files_s= [f for f in listdir(skills_path) if f.endswith(\".csv\")]\n",
    "df_s = pd.read_csv(skills_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/nyzy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/nyzy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/nyzy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Ensure you have the necessary NLTK tokens downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "# Initialize the lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocess_text_spacy(text):\n",
    "    # Use spaCy's pipeline for processing the passed text\n",
    "    doc = nlp(text)\n",
    "    preprocessed_text= []\n",
    "    # Return a preprocessed version of the text (for instance, lemmatized, lowercased, no stop words/punctuations)\n",
    "    for token in doc:\n",
    "        # Skip stop words and punctuation\n",
    "        if token.is_stop or token.is_punct or token.is_space:\n",
    "            continue\n",
    "        # Special case for 'data' to keep it in plural form\n",
    "        if token.lemma_ == 'datum':\n",
    "            preprocessed_text.append('data')\n",
    "        else:\n",
    "            preprocessed_text.append(token.text.lower())\n",
    "\n",
    "    return ' '.join(preprocessed_text)\n",
    "\n",
    "\n",
    "# Function to clean and lemmatize job title text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    #words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def clean_lem_stop(df,column_name):\n",
    "    df[column_name] = df[column_name].apply(preprocess_text_spacy)\n",
    "    df[column_name] = df[column_name].apply(clean_text)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean skills dataset \n",
    "\n",
    "skills = pd.DataFrame(df_s[df_s[\"Unnamed: 5\"].notna()][\"Unnamed: 5\"].unique())\n",
    "skills.columns=[\"skills\"]\n",
    "#skills[\"skills\"] = skills[\"skills\"].apply(preprocess_text_spacy)\n",
    "skills[\"skills\"] = skills[\"skills\"].apply(clean_text)\n",
    "skills_list = skills[\"skills\"].tolist()\n",
    "skills_list.append('python')\n",
    "skills_list.append('python programming')\n",
    "skills_list.append('statistical')\n",
    "skills_list.append(\"r programming\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['visualization',\n",
       " 'b testing',\n",
       " 'ansi c',\n",
       " 'api gateway',\n",
       " 'api management',\n",
       " 'apl programming language',\n",
       " 'asp net',\n",
       " 'asp net core',\n",
       " 'asp net core mvc',\n",
       " 'asp net extension ajax',\n",
       " 'asp net fundamental',\n",
       " 'asp net identity',\n",
       " 'asp net mvc',\n",
       " 'asp net mvc framework',\n",
       " 'asp net razor',\n",
       " 'asp net web api',\n",
       " 'awk programming language',\n",
       " 'aws amplify',\n",
       " 'aws app mesh',\n",
       " 'aws appsync',\n",
       " 'aws auto scaling',\n",
       " 'aws backup',\n",
       " 'aws batch',\n",
       " 'aws cli command line interface',\n",
       " 'aws cloud development kit cdk',\n",
       " 'aws cloudformation',\n",
       " 'aws cloudhsm',\n",
       " 'aws cloudtrail',\n",
       " 'aws codebuild',\n",
       " 'aws codecommit',\n",
       " 'aws codedeploy',\n",
       " 'aws codepipeline',\n",
       " 'aws cost management',\n",
       " 'aws directory service',\n",
       " 'aws elastic beanstalk',\n",
       " 'aws elastic mapreduce emr',\n",
       " 'aws fargate',\n",
       " 'aws glue',\n",
       " 'aws identity access management iam',\n",
       " 'aws inferentia',\n",
       " 'aws internet thing iot',\n",
       " 'aws key management service km',\n",
       " 'aws kinesis',\n",
       " 'aws lambda',\n",
       " 'aws opsworks',\n",
       " 'aws outpost',\n",
       " 'aws sdk',\n",
       " 'aws sagemaker',\n",
       " 'aws serverless',\n",
       " 'aws user pool',\n",
       " 'abstract class',\n",
       " 'abstract data type',\n",
       " 'acceptance testing',\n",
       " 'activepython python package',\n",
       " 'ad hoc analysis',\n",
       " 'ad hoc marketing',\n",
       " 'ad hoc reporting',\n",
       " 'ad hoc testing',\n",
       " 'ada programming support environment apse',\n",
       " 'adaboost adaptive boosting',\n",
       " 'adhoc query',\n",
       " 'aggregation analysis',\n",
       " 'agile management',\n",
       " 'agile methodology',\n",
       " 'agile project management',\n",
       " 'agile project',\n",
       " 'agile software development',\n",
       " 'agile testing',\n",
       " 'airflow',\n",
       " 'ajax net',\n",
       " 'alation data catalog',\n",
       " 'algebra',\n",
       " 'algebraic modeling language',\n",
       " 'algorithm analysis',\n",
       " 'algorithm design',\n",
       " 'algorithmic trading',\n",
       " 'algorithm',\n",
       " 'alteryx',\n",
       " 'amazon api gateway',\n",
       " 'amazon alexa',\n",
       " 'amazon appstore',\n",
       " 'amazon appstream',\n",
       " 'amazon athena',\n",
       " 'amazon aurora',\n",
       " 'amazon cloud directory',\n",
       " 'amazon cloud drive',\n",
       " 'amazon cloudsearch',\n",
       " 'amazon cloudwatch',\n",
       " 'amazon cloudfront',\n",
       " 'amazon cognito',\n",
       " 'amazon comprehend',\n",
       " 'amazon connect',\n",
       " 'amazon data pipeline',\n",
       " 'amazon documentdb',\n",
       " 'amazon dynamodb',\n",
       " 'amazon elasticache',\n",
       " 'amazon elastic block store',\n",
       " 'amazon elastic compute cloud',\n",
       " 'amazon elastic container registry',\n",
       " 'amazon elastic container service',\n",
       " 'amazon elastic file system',\n",
       " 'amazon elastic kubernetes service',\n",
       " 'amazon elasticsearch service',\n",
       " 'amazon flexible payment service',\n",
       " 'amazon forecast',\n",
       " 'amazon guardduty',\n",
       " 'amazon inspector',\n",
       " 'amazon lex',\n",
       " 'amazon lightsail',\n",
       " 'amazon linux amazon machine image ami',\n",
       " 'amazon lumberyard',\n",
       " 'amazon mq',\n",
       " 'amazon macie',\n",
       " 'amazon managed blockchain',\n",
       " 'amazon managed streaming apache kafka amazon msk',\n",
       " 'amazon marketplace',\n",
       " 'amazon mechanical turk',\n",
       " 'amazon neptune',\n",
       " 'amazon personalize',\n",
       " 'amazon polly',\n",
       " 'amazon product advertising api',\n",
       " 'amazon quantum ledger database qldb',\n",
       " 'amazon quicksight',\n",
       " 'amazon redshift',\n",
       " 'amazon rekognition',\n",
       " 'amazon relational database service',\n",
       " 'amazon route',\n",
       " 'amazon',\n",
       " 'amazon bucket',\n",
       " 'amazon glacier',\n",
       " 'amazon simple email service s',\n",
       " 'amazon simple notification service sn',\n",
       " 'amazon simple queue service',\n",
       " 'amazon simple workflow service swf',\n",
       " 'amazon simpledb',\n",
       " 'amazon textract',\n",
       " 'amazon timestream',\n",
       " 'amazon transcribe',\n",
       " 'amazon translate',\n",
       " 'amazon virtual private cloud vpc',\n",
       " 'amazon web service',\n",
       " 'amazon workspace',\n",
       " 'analysis variance anova',\n",
       " 'analytic application',\n",
       " 'analytical dashboard',\n",
       " 'analytical technique',\n",
       " 'analytical testing',\n",
       " 'analytics',\n",
       " 'analytics j javascript library',\n",
       " 'android software development',\n",
       " 'android studio',\n",
       " 'android testing',\n",
       " 'android ui',\n",
       " 'angelscript',\n",
       " 'angular web framework',\n",
       " 'angular cli',\n",
       " 'angular component',\n",
       " 'angular material',\n",
       " 'angular reactive form',\n",
       " 'angular ui',\n",
       " 'ansi sql',\n",
       " 'apache',\n",
       " 'apache accumulo',\n",
       " 'apache activemq',\n",
       " 'apache administration',\n",
       " 'apache airflow',\n",
       " 'apache ambari',\n",
       " 'apache ant',\n",
       " 'apache apex',\n",
       " 'apache archiva',\n",
       " 'apache atlas',\n",
       " 'apache avro',\n",
       " 'apache axis',\n",
       " 'apache beam',\n",
       " 'apache beehive',\n",
       " 'apache cxf',\n",
       " 'apache camel',\n",
       " 'apache cassandra',\n",
       " 'apache cloudstack',\n",
       " 'apache common ognl',\n",
       " 'apache cordova',\n",
       " 'apache derby',\n",
       " 'apache directory',\n",
       " 'apache drill',\n",
       " 'apache druid',\n",
       " 'apache felix',\n",
       " 'apache flex',\n",
       " 'apache flink',\n",
       " 'apache flume',\n",
       " 'apache fop',\n",
       " 'apache giraph',\n",
       " 'apache hbase',\n",
       " 'apache http server',\n",
       " 'apache hadoop',\n",
       " 'apache hive',\n",
       " 'apache ibatis',\n",
       " 'apache iceberg',\n",
       " 'apache ignite',\n",
       " 'apache impala',\n",
       " 'apache jmeter',\n",
       " 'apache jserv protocol',\n",
       " 'apache jackrabbit',\n",
       " 'apache kafka',\n",
       " 'apache karaf',\n",
       " 'apache lucene',\n",
       " 'apache lucene net',\n",
       " 'apache madlib',\n",
       " 'apache mxnet',\n",
       " 'apache mahout',\n",
       " 'apache maven',\n",
       " 'apache mesos',\n",
       " 'apache module',\n",
       " 'apache myfaces',\n",
       " 'apache nifi',\n",
       " 'apache oozie',\n",
       " 'apache opennlp',\n",
       " 'apache openoffice',\n",
       " 'apache openjpa',\n",
       " 'apache openoffice calc',\n",
       " 'apache pdfbox',\n",
       " 'apache poi',\n",
       " 'apache parquet',\n",
       " 'apache phoenix',\n",
       " 'apache pig',\n",
       " 'apache pulsar',\n",
       " 'apache ranger',\n",
       " 'apache singa',\n",
       " 'apache samza',\n",
       " 'apache servicemix',\n",
       " 'apache shiro',\n",
       " 'apache sling',\n",
       " 'apache solr',\n",
       " 'apache spark',\n",
       " 'apache storm',\n",
       " 'apache strut',\n",
       " 'apache subversion',\n",
       " 'apache thrift',\n",
       " 'apache tika',\n",
       " 'apache tile',\n",
       " 'apache tinkerpop',\n",
       " 'apache tomee',\n",
       " 'apache tomcat',\n",
       " 'apache torque',\n",
       " 'apache traffic server',\n",
       " 'apache turbine',\n",
       " 'apache velocity',\n",
       " 'apache wicket',\n",
       " 'apache yarn',\n",
       " 'apache zeppelin',\n",
       " 'apollo graphql',\n",
       " 'application data',\n",
       " 'application deployment',\n",
       " 'application design',\n",
       " 'application development',\n",
       " 'application development language',\n",
       " 'application development system online adso',\n",
       " 'application environment',\n",
       " 'application firewall',\n",
       " 'application foundation class',\n",
       " 'application framework',\n",
       " 'application integration architecture',\n",
       " 'application interface framework',\n",
       " 'application kit',\n",
       " 'application layer',\n",
       " 'application level gateway',\n",
       " 'application level multicast infrastructure almi',\n",
       " 'application lifecycle management',\n",
       " 'application lifecycle management alm software',\n",
       " 'application monitoring',\n",
       " 'application note',\n",
       " 'application packaging',\n",
       " 'application performance management',\n",
       " 'application planning',\n",
       " 'application portfolio management',\n",
       " 'application programming interface api',\n",
       " 'application release automation',\n",
       " 'application remediation',\n",
       " 'application restart',\n",
       " 'application retirement',\n",
       " 'application security',\n",
       " 'application security testing',\n",
       " 'application server',\n",
       " 'application service',\n",
       " 'application setting',\n",
       " 'application specific instruction set processor',\n",
       " 'application specific integrated circuit',\n",
       " 'application streaming',\n",
       " 'application virtualization',\n",
       " 'application xml',\n",
       " 'application level gateway',\n",
       " 'application specific information',\n",
       " 'application architecture',\n",
       " 'application artificial intelligence',\n",
       " 'applied behavior analysis',\n",
       " 'applied business technology',\n",
       " 'applied science',\n",
       " 'applied statistic',\n",
       " 'aqua data studio',\n",
       " 'arangodb',\n",
       " 'architect engineer contract administration support system',\n",
       " 'architecture flow diagram',\n",
       " 'argo cd',\n",
       " 'artificial general intelligence',\n",
       " 'artificial intelligence',\n",
       " 'artificial intelligence development',\n",
       " 'artificial intelligence markup language aiml',\n",
       " 'artificial intelligence system',\n",
       " 'artificial neural network',\n",
       " 'assembly language',\n",
       " 'assessment basic language learning skill',\n",
       " 'association management',\n",
       " 'association rule learning',\n",
       " 'asynchronous javascript',\n",
       " 'asynchronous javascript xml ajax',\n",
       " 'asynchronous learning',\n",
       " 'asynchronous module definition',\n",
       " 'asynchronous serial communication',\n",
       " 'asynchronous transfer mode atm',\n",
       " 'attention mechanism',\n",
       " 'autocad',\n",
       " 'autocad architecture',\n",
       " 'autocad civil',\n",
       " 'autocad dxf',\n",
       " 'autocad plant',\n",
       " 'autoencoders',\n",
       " 'automated code review',\n",
       " 'automated machine learning',\n",
       " 'automatic data processing equipment',\n",
       " 'automatic data processing software adp',\n",
       " 'autoregressive integrated moving average arima',\n",
       " 'autoregressive model',\n",
       " 'average cost method',\n",
       " 'azure api apps',\n",
       " 'azure api management',\n",
       " 'azure active directory',\n",
       " 'azure application insight',\n",
       " 'azure automation',\n",
       " 'azure batch',\n",
       " 'azure blob storage',\n",
       " 'azure blueprint',\n",
       " 'azure cloud service',\n",
       " 'azure cognitive service',\n",
       " 'azure command line interface azure cli',\n",
       " 'azure content delivery network azure cdn',\n",
       " 'azure cosmos db',\n",
       " 'azure cost management',\n",
       " 'azure data catalog',\n",
       " 'azure data explorer kusto',\n",
       " 'azure data factory',\n",
       " 'azure data lake',\n",
       " 'azure databricks',\n",
       " 'azure devops',\n",
       " 'azure firewall',\n",
       " 'azure internet thing iot',\n",
       " 'azure kubernetes service',\n",
       " 'azure load balancer',\n",
       " 'azure logic apps',\n",
       " 'azure mfa',\n",
       " 'azure machine learning',\n",
       " 'azure monitor',\n",
       " 'azure pipeline',\n",
       " 'azure policy',\n",
       " 'azure security',\n",
       " 'azure sentinel',\n",
       " 'azure service bus',\n",
       " 'azure service fabric',\n",
       " 'azure web apps',\n",
       " 'b tree file system btrfs',\n",
       " 'bert nlp model',\n",
       " 'bgfs algorithm',\n",
       " 'end software engineering',\n",
       " 'backbone j javascript library',\n",
       " 'backpropagation',\n",
       " 'batch message processing',\n",
       " 'batch processing',\n",
       " 'batch production',\n",
       " 'bayes classifier',\n",
       " 'bayes estimator',\n",
       " 'bayesian inference',\n",
       " 'bayesian modeling',\n",
       " 'bayesian network',\n",
       " 'bayesian probability',\n",
       " 'bayesian statistic',\n",
       " 'beautifulsoup',\n",
       " 'behavioral analytics',\n",
       " 'behavioral segmentation',\n",
       " 'big data',\n",
       " 'big data analytics',\n",
       " 'big ip',\n",
       " 'big notation',\n",
       " 'bigmachines query language bmql',\n",
       " 'bigquery',\n",
       " 'bigtable',\n",
       " 'binary search algorithm',\n",
       " 'binary search tree',\n",
       " 'binary space partitioning',\n",
       " 'binary system',\n",
       " 'binary tree',\n",
       " 'bit ly',\n",
       " 'bitbucket',\n",
       " 'blockchain',\n",
       " 'blockchain indexing',\n",
       " 'blockchain security',\n",
       " 'bokeh',\n",
       " 'boltzmann machine',\n",
       " 'boolean expression',\n",
       " 'boolean network',\n",
       " 'boolean search',\n",
       " 'boost c library',\n",
       " 'bootstrap end framework',\n",
       " 'bootstrap protocol',\n",
       " 'bootstrapping',\n",
       " 'build automation',\n",
       " 'build event',\n",
       " 'build management',\n",
       " 'build pipeline',\n",
       " 'build process',\n",
       " 'build time',\n",
       " 'build tool',\n",
       " 'build v buy analysis',\n",
       " 'building information modeling',\n",
       " 'business analysis',\n",
       " 'business analysis body knowledge babok',\n",
       " 'business analytics',\n",
       " 'business architecture',\n",
       " 'business case analysis',\n",
       " 'business communication',\n",
       " 'business computer system',\n",
       " 'business development',\n",
       " 'business integration software',\n",
       " 'business intelligence',\n",
       " 'business intelligence architecture',\n",
       " 'business intelligence data modeling',\n",
       " 'business intelligence development',\n",
       " 'business intelligence development studio',\n",
       " 'business intelligence reporting',\n",
       " 'business intelligence testing',\n",
       " 'business intelligence tool',\n",
       " 'business performance management',\n",
       " 'business reporting',\n",
       " 'business requirement',\n",
       " 'business requirement documentation',\n",
       " 'c programming language',\n",
       " 'c compiler',\n",
       " 'c data type c programming language',\n",
       " 'c dynamic memory allocation',\n",
       " 'c file input output',\n",
       " 'c graphic',\n",
       " 'c mathematical function c standard library',\n",
       " 'c preprocessor',\n",
       " 'c sharp software',\n",
       " 'c sharp syntax',\n",
       " 'c shell',\n",
       " 'c standard library',\n",
       " 'c programming language',\n",
       " 'c fundamental',\n",
       " 'c programming language',\n",
       " 'c concept',\n",
       " 'c fundamental',\n",
       " 'c module',\n",
       " 'c server page',\n",
       " 'c cli',\n",
       " 'c',\n",
       " 'c based programming language',\n",
       " 'c treeace',\n",
       " 'c c standard library',\n",
       " 'c family',\n",
       " 'c j javascript library',\n",
       " 'cgi scripting',\n",
       " 'chi squared automatic interaction detection chaid',\n",
       " 'ci cd',\n",
       " 'cpython python package',\n",
       " 'cs animation',\n",
       " 'cs code',\n",
       " 'cs flex box layout',\n",
       " 'cs framework',\n",
       " 'cs grid',\n",
       " 'calculus',\n",
       " 'candidate key',\n",
       " 'canva software',\n",
       " 'cascading style sheet cs',\n",
       " 'chart j javascript library',\n",
       " 'chatgpt',\n",
       " 'chatbot',\n",
       " 'chi squared test',\n",
       " 'class diagram',\n",
       " 'class hierarchy',\n",
       " 'client server application language c al',\n",
       " 'cloud application',\n",
       " 'cloud automation',\n",
       " 'cloud collaboration',\n",
       " 'cloud computing',\n",
       " 'cloud computing architecture',\n",
       " 'cloud data management interface',\n",
       " 'cloud database',\n",
       " 'cloud development',\n",
       " 'cloud engineering',\n",
       " 'cloud infrastructure',\n",
       " 'cloud infrastructure management interface cimi',\n",
       " 'cloud management',\n",
       " 'cloud management platform',\n",
       " 'cloud migration',\n",
       " 'cloud operation',\n",
       " 'cloud penetration testing',\n",
       " 'cloud platform system',\n",
       " 'cloud storage',\n",
       " 'cloud strategy',\n",
       " 'cloud technology',\n",
       " 'cluster analysis',\n",
       " 'code editor',\n",
       " 'code enforcement',\n",
       " 'code formatting',\n",
       " 'code generation',\n",
       " 'code injection',\n",
       " 'code insight',\n",
       " 'code inspection',\n",
       " 'code migration',\n",
       " 'code federal regulation',\n",
       " 'code project open licensing',\n",
       " 'code refactoring',\n",
       " 'code reuse',\n",
       " 'code review',\n",
       " 'code sharing',\n",
       " 'code signing',\n",
       " 'code snippet',\n",
       " 'code structure',\n",
       " 'code testing',\n",
       " 'codebase',\n",
       " 'cognitive processing',\n",
       " 'collaborative filtering',\n",
       " 'command data handling',\n",
       " 'common gateway interface',\n",
       " 'compiler theory',\n",
       " 'compiler',\n",
       " 'computational design',\n",
       " 'computational intelligence',\n",
       " 'computational science engineering',\n",
       " 'computer data storage',\n",
       " 'computer design',\n",
       " 'computer display',\n",
       " 'computer engineering',\n",
       " 'computer programming',\n",
       " 'computer science',\n",
       " 'conditional expression',\n",
       " 'confusion matrix',\n",
       " 'continuous integration',\n",
       " 'conversational ai',\n",
       " 'convex optimization',\n",
       " 'convolutional neural network',\n",
       " 'couchdb',\n",
       " 'counterintelligence',\n",
       " 'course catalog',\n",
       " 'course development',\n",
       " 'create react app',\n",
       " 'cross functional integration',\n",
       " 'cross functional project management',\n",
       " 'cross functional team leadership',\n",
       " 'crypto mining',\n",
       " 'crypto',\n",
       " 'cryptocurrency',\n",
       " 'customer analysis',\n",
       " 'customer analytics',\n",
       " 'customer data integration',\n",
       " 'customer data management',\n",
       " 'cyber security management',\n",
       " 'cython',\n",
       " 'j javascript library',\n",
       " 'databus programming language',\n",
       " 'db sql',\n",
       " 'dfsm',\n",
       " 'dashboard',\n",
       " 'data abstraction',\n",
       " 'data access',\n",
       " 'data access object dao pattern',\n",
       " 'data acquisition',\n",
       " 'data administration',\n",
       " 'data analysis',\n",
       " 'data analysis display dadisp',\n",
       " 'data analysis expression dax',\n",
       " 'data annotation',\n",
       " 'data architecture',\n",
       " 'data archive',\n",
       " 'data archiving service',\n",
       " 'data service daas',\n",
       " 'data auditing',\n",
       " 'data base query language',\n",
       " 'data binding',\n",
       " 'data blending',\n",
       " 'data buffer',\n",
       " 'data build tool',\n",
       " 'data cabling',\n",
       " 'data caching',\n",
       " 'data capture',\n",
       " 'data center bridging',\n",
       " 'data center hardware',\n",
       " 'data center infrastructure efficiency',\n",
       " 'data center infrastructure management cim',\n",
       " 'data center unified computing system implementation dcuci',\n",
       " 'data center',\n",
       " 'data class',\n",
       " 'data classification',\n",
       " 'data cleansing',\n",
       " 'data collection',\n",
       " 'data comparison',\n",
       " 'data compression',\n",
       " 'data conditioning',\n",
       " 'data consistency',\n",
       " 'data control',\n",
       " 'data control language',\n",
       " 'data conversion',\n",
       " 'data corruption',\n",
       " 'data cube',\n",
       " 'data curation',\n",
       " 'data definition language',\n",
       " 'data definition specification',\n",
       " 'data dictionary',\n",
       " 'data direct network',\n",
       " 'data discovery',\n",
       " 'data display debugger',\n",
       " 'data distribution service',\n",
       " 'data domain',\n",
       " 'data driven instruction',\n",
       " 'data duplication management',\n",
       " 'data element',\n",
       " 'data encoding',\n",
       " 'data encryption',\n",
       " 'data encryption standard',\n",
       " 'data engineering',\n",
       " 'data engineering scripting language',\n",
       " 'data entry',\n",
       " 'data erasure',\n",
       " 'data ethic',\n",
       " 'data exchange',\n",
       " 'data exploitation',\n",
       " 'data explorer',\n",
       " 'data extraction',\n",
       " 'data facility data set service',\n",
       " 'data facility storage management',\n",
       " 'data farming',\n",
       " 'data feed',\n",
       " 'data file',\n",
       " 'data flow diagram',\n",
       " 'data format description language',\n",
       " 'data frame',\n",
       " 'data fusion',\n",
       " 'data general aviion computer',\n",
       " 'data governance',\n",
       " 'data grid',\n",
       " 'data hiding encapsulation',\n",
       " 'data highway plus',\n",
       " 'data hub',\n",
       " 'data import export',\n",
       " 'data infrastructure',\n",
       " 'data ingestion',\n",
       " 'data integration',\n",
       " 'data integrity',\n",
       " 'data intelligence',\n",
       " 'data interface',\n",
       " 'data item description',\n",
       " 'data lake',\n",
       " 'data language interface',\n",
       " 'data layer',\n",
       " 'data library',\n",
       " 'data link',\n",
       " 'data link connection identifier',\n",
       " 'data link control',\n",
       " 'data link layer',\n",
       " 'data literacy',\n",
       " 'data localization',\n",
       " 'data loss prevention',\n",
       " 'data maintenance',\n",
       " 'data management',\n",
       " 'data management plan',\n",
       " 'data management platform',\n",
       " 'data manipulation',\n",
       " 'data manipulation language',\n",
       " 'data mapper pattern',\n",
       " 'data mapping',\n",
       " 'data mart',\n",
       " 'data masking',\n",
       " 'data migration',\n",
       " 'data mining',\n",
       " 'data mining method',\n",
       " 'data mining query language dmql',\n",
       " 'data modeling',\n",
       " 'data monetization',\n",
       " 'data normalization',\n",
       " 'data ontap server appliance',\n",
       " 'data palette',\n",
       " 'data partitioning',\n",
       " 'data pipeline management',\n",
       " 'data pipeline',\n",
       " 'data plane development kit dpdk',\n",
       " 'data policy development',\n",
       " 'data preprocessing',\n",
       " 'data presentation',\n",
       " 'data privacy law',\n",
       " 'data processing',\n",
       " 'data processing system',\n",
       " 'data processing unit',\n",
       " 'data profiling',\n",
       " 'data protection planning',\n",
       " 'data protection strategy',\n",
       " 'data quality',\n",
       " 'data quality assessment',\n",
       " 'data radio channel',\n",
       " 'data recording',\n",
       " 'data recovery',\n",
       " 'data recovery software',\n",
       " 'data reduction',\n",
       " 'data redundancy',\n",
       " 'data reference model',\n",
       " 'data remanence',\n",
       " 'data retention',\n",
       " 'data retrieval',\n",
       " 'data room',\n",
       " 'data science',\n",
       " 'data scraping',\n",
       " 'data security',\n",
       " 'data selection',\n",
       " 'data server interface',\n",
       " 'data sharing',\n",
       " 'data smoothing',\n",
       " 'data storage',\n",
       " 'data storage device',\n",
       " 'data store',\n",
       " 'data storytelling',\n",
       " 'data strategy',\n",
       " 'data stream management system',\n",
       " 'data streaming',\n",
       " 'data striping',\n",
       " 'data structure alignment',\n",
       " 'data structure',\n",
       " 'data synchronization',\n",
       " 'data synthesis',\n",
       " 'data system',\n",
       " 'data targeting',\n",
       " 'data taxonomy',\n",
       " 'data terminal equipment',\n",
       " 'data transfer object',\n",
       " 'data transformation',\n",
       " 'data transformation service',\n",
       " 'data transmission',\n",
       " 'data transport utility',\n",
       " 'data transposition',\n",
       " 'data validation',\n",
       " 'data vault',\n",
       " 'data verification',\n",
       " 'data virtualization',\n",
       " 'data visualization',\n",
       " 'data warehouse appliance',\n",
       " 'data warehouse architecture',\n",
       " 'data warehouse system',\n",
       " 'data warehousing',\n",
       " 'data warehousing business intelligence dwbi',\n",
       " 'data wrangling',\n",
       " 'data centric testing',\n",
       " 'data driven decision making',\n",
       " 'data driven manufacturing',\n",
       " 'data driven testing',\n",
       " 'data flow analysis',\n",
       " 'data link switching',\n",
       " 'data structured language',\n",
       " 'dataadapters ado net',\n",
       " 'database markup language',\n",
       " 'databasic',\n",
       " 'datacad',\n",
       " 'dataflex',\n",
       " 'dataflux',\n",
       " 'datahub software',\n",
       " 'datanucleus',\n",
       " 'datastax enterprise',\n",
       " 'datastax enterprise graph',\n",
       " 'datatransfer workbench sap',\n",
       " 'databags',\n",
       " 'database abstraction layer',\n",
       " 'database activity monitoring',\n",
       " 'database administration',\n",
       " 'database analysis',\n",
       " 'database application',\n",
       " 'database architecture',\n",
       " 'database service dbaas',\n",
       " 'database audit',\n",
       " 'database availability group',\n",
       " 'database cloning',\n",
       " 'database cluster',\n",
       " 'database comparison',\n",
       " 'database connection',\n",
       " 'database consistency',\n",
       " 'database console command dbcc',\n",
       " 'database consolidation',\n",
       " 'database conversion',\n",
       " 'database cursor',\n",
       " 'database deployment management',\n",
       " 'database design',\n",
       " 'database development',\n",
       " 'database diagram',\n",
       " 'database directive',\n",
       " 'database dump',\n",
       " 'database encryption',\n",
       " 'database engine tuning advisor',\n",
       " 'database engine',\n",
       " 'database',\n",
       " 'database independent',\n",
       " 'database index',\n",
       " 'database life cycle management',\n",
       " 'database management',\n",
       " 'database management system',\n",
       " 'database marketing',\n",
       " 'database mirroring',\n",
       " 'database modeling',\n",
       " 'database normalization',\n",
       " 'database partitioning',\n",
       " 'database performance analyzer',\n",
       " 'database permission',\n",
       " 'database programmer toolkits',\n",
       " 'database programming',\n",
       " 'database publishing',\n",
       " 'database query',\n",
       " 'database query tool',\n",
       " 'database reporting software',\n",
       " 'database scanner',\n",
       " 'database schema',\n",
       " 'database search engine',\n",
       " 'database security',\n",
       " 'database server',\n",
       " 'database software',\n",
       " 'database storage structure',\n",
       " 'database system',\n",
       " 'database testing',\n",
       " 'database theory',\n",
       " 'database transaction',\n",
       " 'database trigger',\n",
       " 'database tuning',\n",
       " 'database upgrade',\n",
       " 'database virtualization',\n",
       " 'databricks',\n",
       " 'datacap',\n",
       " 'datacards',\n",
       " 'datacom db',\n",
       " 'datadog',\n",
       " 'datafeed',\n",
       " 'datafield',\n",
       " 'dataflow',\n",
       " 'dataflow architecture',\n",
       " 'dataframe',\n",
       " 'datagram',\n",
       " 'datagram congestion control protocol',\n",
       " 'datagram transport layer security',\n",
       " 'datakit',\n",
       " 'datalog',\n",
       " 'datamaps',\n",
       " 'datamodel',\n",
       " 'datanet',\n",
       " 'dataportability',\n",
       " 'datapump',\n",
       " 'dataset',\n",
       " 'datasheets',\n",
       " 'dataspaces',\n",
       " 'datastax',\n",
       " 'datatable',\n",
       " 'dataweave',\n",
       " 'datawindow',\n",
       " 'date manipulation',\n",
       " 'datediff',\n",
       " 'datomic',\n",
       " 'daughterboard',\n",
       " 'dbvisualizer',\n",
       " 'dbeaver',\n",
       " 'dbscan',\n",
       " 'dc j javascript library',\n",
       " 'decision model',\n",
       " 'decision science',\n",
       " 'decision support operation maintenance',\n",
       " 'decision support system',\n",
       " 'decision table',\n",
       " 'decision theory',\n",
       " 'decision tree learning',\n",
       " 'decision matrix method',\n",
       " 'deep learning',\n",
       " 'deep learning method',\n",
       " 'descriptive statistic',\n",
       " 'dev testing',\n",
       " 'dev c',\n",
       " 'devexpress',\n",
       " 'devops',\n",
       " 'differential calculus',\n",
       " 'digital data',\n",
       " 'digital data communication message protocol',\n",
       " 'digital data storage',\n",
       " 'digital data system',\n",
       " 'dimension table',\n",
       " 'dimensionality reduction',\n",
       " 'disk partitioning',\n",
       " 'distance learning',\n",
       " 'distributed computing',\n",
       " 'distributed database',\n",
       " 'distributed file system',\n",
       " 'distributed programming',\n",
       " 'docker engine',\n",
       " 'dot product',\n",
       " 'dropbox api',\n",
       " 'dust j javascript library',\n",
       " 'dynamic application security testing dast',\n",
       " 'dynamic data',\n",
       " 'dynamic program analysis',\n",
       " 'dynamic programming',\n",
       " 'ecmascript c programming language family',\n",
       " 'emc cloud computing',\n",
       " 'exec scripting language',\n",
       " 'economic policy analysis',\n",
       " 'edge computing',\n",
       " 'educational data mining',\n",
       " 'eigen c library',\n",
       " 'elasticity computing',\n",
       " 'electronic system level design verification',\n",
       " 'elixir programming language',\n",
       " 'eltron programming language',\n",
       " 'email processing',\n",
       " 'embedded c',\n",
       " 'embedded c',\n",
       " 'embedded code',\n",
       " 'embedded database',\n",
       " 'embedded domain specific language',\n",
       " 'embedded firmware',\n",
       " 'embedded http server',\n",
       " 'embedded intelligence',\n",
       " 'embedded java',\n",
       " 'embedded operating system',\n",
       " 'embedded sql',\n",
       " 'embedded software',\n",
       " 'embedded system',\n",
       " 'ember j javascript library',\n",
       " 'emulator high level language application program interface ehllapi',\n",
       " 'encrypted key exchange',\n",
       " 'encrypting file system',\n",
       " 'encryption',\n",
       " 'encryption software',\n",
       " 'environmental data analysis',\n",
       " 'environmental data management',\n",
       " 'enzyme javascript testing utility',\n",
       " 'error analysis numerical analysis',\n",
       " 'espresso android testing framework',\n",
       " 'espresso java',\n",
       " 'evolutionary programming',\n",
       " 'exception handling',\n",
       " 'expense forecasting',\n",
       " 'experience api xapi',\n",
       " 'express j javascript library',\n",
       " 'ext j',\n",
       " 'ext net',\n",
       " 'extendscript',\n",
       " 'extended file system',\n",
       " 'extract transform load etl',\n",
       " 'f programming language',\n",
       " 'foil programming language',\n",
       " 'facebook api',\n",
       " 'facebook analytics',\n",
       " 'facebook graph api',\n",
       " 'facebook query language',\n",
       " 'factset analytics software',\n",
       " 'famo javascript framework',\n",
       " 'feature engineering',\n",
       " 'feature extraction',\n",
       " 'file handling',\n",
       " 'file transfer protocol ftp',\n",
       " 'financial data management',\n",
       " 'financial forecasting',\n",
       " 'financial information exchange fix protocol',\n",
       " 'flask web framework',\n",
       " 'flux react j',\n",
       " 'foglight database software',\n",
       " 'forth programming language',\n",
       " 'fortran programming language',\n",
       " 'framer j javascript library',\n",
       " 'frisby j javascript library',\n",
       " 'end software engineering',\n",
       " 'end design',\n",
       " 'end engineering',\n",
       " 'g programming language',\n",
       " 'g code',\n",
       " 'g standard',\n",
       " 'g standard',\n",
       " 'g standard',\n",
       " 'g standard',\n",
       " 'g standard',\n",
       " 'g standard',\n",
       " 'g standard',\n",
       " 'g protocol',\n",
       " 'g standard',\n",
       " 'g standard',\n",
       " 'g protocol',\n",
       " 'g standard',\n",
       " 'g standard',\n",
       " 'gnu c library',\n",
       " 'gpu optimization',\n",
       " 'gatsby j javascript library',\n",
       " 'generic java',\n",
       " 'generic java',\n",
       " 'git version control system',\n",
       " ...]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_j = df_j[:100]\n",
    "df_c = df_c[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_job_df(df):\n",
    "    df = clean_lem_stop(df,\"title\")\n",
    "    df = clean_lem_stop(df,\"jobDescription\")\n",
    "    job_descriptions = df_j[\"jobDescription\"].tolist()\n",
    "    return df,job_descriptions\n",
    "\n",
    "df_j_cleaned,job_descriptions = clean_job_df(df_j)\n",
    "\n",
    "columns_of_interest = ['company',\n",
    " 'companyRating',\n",
    " 'companyReviewCount',\n",
    " 'displayTitle',\n",
    " 'employerAssistEnabled',\n",
    " 'employerResponsive',\n",
    " 'extractedSalary',\n",
    " 'featuredEmployer',\n",
    " 'featuredEmployerCandidate',\n",
    " 'formattedLocation',\n",
    " 'formattedRelativeTime',\n",
    " 'highVolumeHiringModel',\n",
    " 'hiringEventJob',\n",
    " 'indeedApplyEnabled',\n",
    " 'indeedApplyable',\n",
    " 'isJobVisited',\n",
    " 'isMobileThirdPartyApplyable',\n",
    " 'isNoResumeJob',\n",
    " 'isSubsidiaryJob',\n",
    " 'jobCardRequirementsModel',\n",
    " 'jobLocationCity',\n",
    " 'jobLocationState',\n",
    " 'locationCount',\n",
    " 'newJob',\n",
    " 'normTitle',\n",
    " 'openInterviewsInterviewsOnTheSpot',\n",
    " 'openInterviewsJob',\n",
    " 'openInterviewsOffersOnTheSpot',\n",
    " 'openInterviewsPhoneJob',\n",
    " 'overrideIndeedApplyText',\n",
    " 'remoteLocation',\n",
    " 'resumeMatch',\n",
    " 'salarySnippet',\n",
    " 'showAttainabilityBadge',\n",
    " 'showCommutePromo',\n",
    " 'showEarlyApply',\n",
    " 'showJobType',\n",
    " 'showRelativeDate',\n",
    " 'showSponsoredLabel',\n",
    " 'showStrongerAppliedLabel',\n",
    " 'smartFillEnabled',\n",
    " 'smbD2iEnabled',\n",
    " 'snippet',\n",
    " 'sponsored',\n",
    " 'title',\n",
    " 'truncatedCompany',\n",
    " 'urgentlyHiring',\n",
    " 'vjFeaturedEmployerCandidate',\n",
    " 'jobDescription']\n",
    "\n",
    "\n",
    "import ast \n",
    "import numpy as np\n",
    "def salary_to_dict(row):\n",
    "    if pd.isna(row):\n",
    "        # Return a dictionary with NaN values if the row is NaN\n",
    "        return {'max': np.nan, 'min': np.nan, 'type': np.nan}\n",
    "    elif isinstance(row, dict):\n",
    "        # Return the row as is if it's already a dictionary\n",
    "        return row\n",
    "    else:\n",
    "        # If the row is a string representation of a dictionary (assumed if not NaN or dict),\n",
    "        # safely evaluate it to a dictionary here\n",
    "        # Note: Be cautious with `eval`. Here it's mentioned for potential string to dict conversion.\n",
    "        # In a secure context, confirm the string format and consider `ast.literal_eval` instead.\n",
    "        try:\n",
    "            # Convert string to dictionary safely\n",
    "            dict_row = eval(row)\n",
    "            return dict_row if isinstance(dict_row, dict) else {'max': np.nan, 'min': np.nan, 'type': np.nan}\n",
    "        except:\n",
    "            # In case of error during eval, return NaN values\n",
    "            return {'max': np.nan, 'min': np.nan, 'type': np.nan}\n",
    "\n",
    "# Apply the function to each row of the 'extractedSalary' column\n",
    "salary_dicts = df_j_cleaned['extractedSalary'].apply(salary_to_dict)\n",
    "# Now that we have a series of dictionaries, use `json_normalize` to create a DataFrame\n",
    "salary_df = pd.json_normalize(salary_dicts)\n",
    "\n",
    "# Concatenate the new DataFrame with the original one\n",
    "df_j_cleaned = pd.concat([df_j_cleaned.drop('extractedSalary', axis=1).reset_index(), salary_df], axis=1)\n",
    "\n",
    "#df[\"extractedSalary\"]=df[\"extractedSalary\"].astype(str)\n",
    "#df[\"extractedSalary\"]=df['extractedSalary'].apply(ast.literal_eval)\n",
    "\n",
    "import ast \n",
    "import numpy as np\n",
    "def salary_snippet_to_dict(row):\n",
    "    if pd.isna(row):\n",
    "        # Return a dictionary with NaN values if the row is NaN\n",
    "        return {'currency': np.nan, 'salaryTextFormatted': np.nan, 'source': np.nan,'text':np.nan}\n",
    "    elif isinstance(row, dict):\n",
    "        # Return the row as is if it's already a dictionary\n",
    "        return row\n",
    "    else:\n",
    "        # If the row is a string representation of a dictionary (assumed if not NaN or dict),\n",
    "        # safely evaluate it to a dictionary here\n",
    "        # Note: Be cautious with `eval`. Here it's mentioned for potential string to dict conversion.\n",
    "        # In a secure context, confirm the string format and consider `ast.literal_eval` instead.\n",
    "        try:\n",
    "            # Convert string to dictionary safely\n",
    "            dict_row = eval(row)\n",
    "            return dict_row if isinstance(dict_row, dict) else {'max': np.nan, 'min': np.nan, 'type': np.nan}\n",
    "        except:\n",
    "            # In case of error during eval, return NaN values\n",
    "            return {'currency': np.nan, 'salaryTextFormatted': np.nan, 'source': np.nan,'text':np.nan}\n",
    "\n",
    "# Apply the function to each row of the 'extractedSalary' column\n",
    "salary_snippet_dicts = df_j_cleaned['salarySnippet'].apply(salary_snippet_to_dict)\n",
    "# Now that we have a series of dictionaries, use `json_normalize` to create a DataFrame\n",
    "salary_snippet_df = pd.json_normalize(salary_snippet_dicts)\n",
    "\n",
    "# Concatenate the new DataFrame with the original one\n",
    "df_j_cleaned = pd.concat([df_j_cleaned.drop('salarySnippet', axis=1).reset_index(), salary_snippet_df], axis=1)\n",
    "\n",
    "#df[\"extractedSalary\"]=df[\"extractedSalary\"].astype(str)\n",
    "#df[\"extractedSalary\"]=df['extractedSalary'].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#phrase matcher model for skills\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "def phrase_matcher_model(description,skills_list):\n",
    "    nlp = spacy.load(\"en_core_web_md\")  # Load the model\n",
    "    matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")  # Create the matcher object\n",
    "\n",
    "    # Assuming 'skills_list' is a list of skills, and 'job_descriptions' is a list containing job descriptions\n",
    "\n",
    "    # Add patterns to the matcher. Patterns are made by converting each skill string into a Doc object\n",
    "    patterns = [nlp.make_doc(skill) for skill in skills_list]\n",
    "    matcher.add(\"Skills\", patterns)\n",
    "\n",
    "    # Process the job description to create a Spacy Doc\n",
    "    doc = nlp(description)\n",
    "\n",
    "    # Match the patterns to the doc\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    # Create Span objects for the matched sequences\n",
    "    spans = [Span(doc, start, end, label=\"SKILL\") for match_id, start, end in matches]\n",
    "\n",
    "    # Filter the spans to remove overlaps\n",
    "    filtered_spans = filter_spans(spans)\n",
    "\n",
    "    # Now you can create new entities in the doc using the filtered spans\n",
    "    doc.ents = filtered_spans  # Overwrite or append to doc.ents with the non-overlapping skill entities\n",
    "    entities_extracted = []\n",
    "    # Print the entities in the document\n",
    "    for ent in doc.ents:\n",
    "        entities_extracted.append(ent.text)\n",
    "    '''\n",
    "    for each in matches:\n",
    "        #print(each)\n",
    "        if each.lower_ == \"statistical\":\n",
    "            for skills_identify in skills_list:\n",
    "                if each.lower_ in skills_identify:\n",
    "                    #print(skills_identify)\n",
    "                    entities_extracted.append(skills_identify)\n",
    "    '''\n",
    "    return set(entities_extracted)\n",
    "\n",
    "df_j_cleaned[\"skills_tagged\"]=df_j_cleaned[\"jobDescription\"].apply(lambda x:phrase_matcher_model(x,skills_list))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AI Architect': ['AI Project Manager', 'Head of AI', 'Chief AI Officer'],\n",
       " 'AI Developer': ['Senior AI Developer',\n",
       "  'AI Architect',\n",
       "  'AI Project Manager',\n",
       "  'Head of AI',\n",
       "  'Chief AI Officer'],\n",
       " 'AI Project Manager': ['Head of AI', 'Chief AI Officer'],\n",
       " 'Big Data Architect': ['Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Big Data Engineer': ['Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Business Analysis Manager': ['Business Intelligence Analyst',\n",
       "  'Director of Business Analysis',\n",
       "  'Chief Strategy Officer',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist'],\n",
       " 'Business Analyst': ['Senior Business Analyst',\n",
       "  'Business Analysis Manager',\n",
       "  'Business Intelligence Analyst',\n",
       "  'Director of Business Analysis',\n",
       "  'Chief Strategy Officer',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist'],\n",
       " 'Business Intelligence Analyst': ['Senior Business Intelligence Analyst',\n",
       "  'Business Intelligence Manager',\n",
       "  'Director of Business Intelligence',\n",
       "  'Vice President of Business Intelligence',\n",
       "  'Chief Intelligence Officer'],\n",
       " 'Business Intelligence Manager': ['Director of Business Intelligence',\n",
       "  'Vice President of Business Intelligence',\n",
       "  'Chief Intelligence Officer'],\n",
       " 'Chief AI Officer': [],\n",
       " 'Chief Data Officer': [],\n",
       " 'Chief Data Scientist': [],\n",
       " 'Chief Information Officer (CIO)': [],\n",
       " 'Chief Intelligence Officer': [],\n",
       " 'Chief Product Officer': ['Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Chief Science Officer': [],\n",
       " 'Chief Strategy Officer': [],\n",
       " 'Chief Technology Officer (CTO)': [],\n",
       " 'Data Analyst': ['Data Engineer',\n",
       "  'Senior Data Engineer',\n",
       "  'Lead Data Engineer',\n",
       "  'Data Architect',\n",
       "  'Senior Data Architect',\n",
       "  'Enterprise Architect',\n",
       "  'Product Analyst',\n",
       "  'Data Product Manager',\n",
       "  'Senior Data Product Manager',\n",
       "  'Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)',\n",
       "  'Machine Learning Engineer'],\n",
       " 'Data Architect': ['Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer'],\n",
       " 'Data Engineer': ['Senior Data Engineer',\n",
       "  'Lead Data Engineer',\n",
       "  'Data Architect',\n",
       "  'Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer'],\n",
       " 'Data Engineering Manager': ['Director of Data Engineering',\n",
       "  'Chief Technology Officer (CTO)'],\n",
       " 'Data Manager': ['Director of Analytics', 'Chief Data Officer'],\n",
       " 'Data Pipeline Architect': ['Data Engineering Manager',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Technology Officer (CTO)'],\n",
       " 'Data Product Manager': ['Senior Data Product Manager',\n",
       "  'Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Data Science Manager': ['Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Data Scientist': ['Senior Data Scientist',\n",
       "  'Lead Data Scientist',\n",
       "  'Principal Data Scientist',\n",
       "  'Data Science Manager',\n",
       "  'Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Database Manager': ['Data Architect',\n",
       "  'Director of Database Management',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Director of Analytics': ['Chief Data Officer'],\n",
       " 'Director of Business Analysis': ['Chief Strategy Officer'],\n",
       " 'Director of Business Intelligence': ['Vice President of Business Intelligence',\n",
       "  'Chief Intelligence Officer'],\n",
       " 'Director of Data Engineering': ['Chief Technology Officer (CTO)'],\n",
       " 'Director of Data Science': ['Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Director of Database Management': ['Chief Information Officer (CIO)'],\n",
       " 'Director of Product Management': ['Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Director of Quantitative Research': [],\n",
       " 'Director of Research': ['Chief Science Officer'],\n",
       " 'Enterprise Architect': ['Product Analyst',\n",
       "  'Data Product Manager',\n",
       "  'Senior Data Product Manager',\n",
       "  'Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Head of AI': ['Chief AI Officer'],\n",
       " 'Head of Big Data': ['Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Head of Machine Learning': ['Chief AI Officer'],\n",
       " 'Junior AI Developer': ['AI Developer',\n",
       "  'Senior AI Developer',\n",
       "  'AI Architect',\n",
       "  'AI Project Manager',\n",
       "  'Head of AI',\n",
       "  'Chief AI Officer',\n",
       "  'Machine Learning Engineer',\n",
       "  'Data Engineer'],\n",
       " 'Junior Business Analyst': ['Business Analyst',\n",
       "  'Senior Business Analyst',\n",
       "  'Business Analysis Manager',\n",
       "  'Business Intelligence Analyst',\n",
       "  'Director of Business Analysis',\n",
       "  'Chief Strategy Officer',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist'],\n",
       " 'Junior DBA': ['Mid-level DBA',\n",
       "  'Senior DBA',\n",
       "  'Database Manager',\n",
       "  'Data Architect',\n",
       "  'Director of Database Management',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Junior Data Analyst': ['Data Analyst',\n",
       "  'Senior Data Analyst',\n",
       "  'Data Engineer',\n",
       "  'Senior Data Engineer',\n",
       "  'Lead Data Engineer',\n",
       "  'Data Architect',\n",
       "  'Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer',\n",
       "  'Business Intelligence Analyst',\n",
       "  'Machine Learning Engineer',\n",
       "  'Big Data Engineer'],\n",
       " 'Junior Data Engineer': ['Data Engineer',\n",
       "  'Senior Data Engineer',\n",
       "  'Data Pipeline Architect',\n",
       "  'Data Engineering Manager',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Technology Officer (CTO)',\n",
       "  'Machine Learning Engineer',\n",
       "  'Big Data Engineer'],\n",
       " 'Junior Data Scientist': ['Data Scientist',\n",
       "  'Senior Data Scientist',\n",
       "  'Lead Data Scientist',\n",
       "  'Principal Data Scientist',\n",
       "  'Data Science Manager',\n",
       "  'Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist',\n",
       "  'Data Engineer',\n",
       "  'AI Developer'],\n",
       " 'Junior Statistician': ['Statistician',\n",
       "  'Senior Statistician',\n",
       "  'Quantitative Analyst',\n",
       "  'Senior Quantitative Analyst',\n",
       "  'Quantitative Research Manager',\n",
       "  'Director of Quantitative Research',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist'],\n",
       " 'Lead Data Engineer': ['Data Architect',\n",
       "  'Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer'],\n",
       " 'Lead Data Scientist': ['Principal Data Scientist',\n",
       "  'Data Science Manager',\n",
       "  'Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Machine Learning Architect': ['Machine Learning Manager',\n",
       "  'Head of Machine Learning',\n",
       "  'Chief AI Officer'],\n",
       " 'Machine Learning Engineer': ['Senior Machine Learning Engineer',\n",
       "  'Machine Learning Architect',\n",
       "  'Machine Learning Manager',\n",
       "  'Head of Machine Learning',\n",
       "  'Chief AI Officer'],\n",
       " 'Machine Learning Manager': ['Head of Machine Learning', 'Chief AI Officer'],\n",
       " 'Mid-level DBA': ['Senior DBA',\n",
       "  'Database Manager',\n",
       "  'Data Architect',\n",
       "  'Director of Database Management',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Principal Data Scientist': ['Data Science Manager',\n",
       "  'Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Principal Scientist': ['Director of Research', 'Chief Science Officer'],\n",
       " 'Product Analyst': ['Data Product Manager',\n",
       "  'Senior Data Product Manager',\n",
       "  'Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Quantitative Analyst': ['Senior Quantitative Analyst',\n",
       "  'Quantitative Research Manager',\n",
       "  'Director of Quantitative Research'],\n",
       " 'Quantitative Research Manager': ['Director of Quantitative Research'],\n",
       " 'Research Analyst': ['Research Scientist',\n",
       "  'Senior Research Scientist',\n",
       "  'Principal Scientist',\n",
       "  'Director of Research',\n",
       "  'Chief Science Officer'],\n",
       " 'Research Assistant': ['Research Analyst',\n",
       "  'Research Scientist',\n",
       "  'Senior Research Scientist',\n",
       "  'Principal Scientist',\n",
       "  'Director of Research',\n",
       "  'Chief Science Officer',\n",
       "  'Data Scientist',\n",
       "  'Statistician'],\n",
       " 'Research Scientist': ['Senior Research Scientist',\n",
       "  'Principal Scientist',\n",
       "  'Director of Research',\n",
       "  'Chief Science Officer'],\n",
       " 'Senior AI Developer': ['AI Architect',\n",
       "  'AI Project Manager',\n",
       "  'Head of AI',\n",
       "  'Chief AI Officer'],\n",
       " 'Senior Big Data Engineer': ['Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Senior Business Analyst': ['Business Analysis Manager',\n",
       "  'Business Intelligence Analyst',\n",
       "  'Director of Business Analysis',\n",
       "  'Chief Strategy Officer',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist'],\n",
       " 'Senior Business Intelligence Analyst': ['Business Intelligence Manager',\n",
       "  'Director of Business Intelligence',\n",
       "  'Vice President of Business Intelligence',\n",
       "  'Chief Intelligence Officer'],\n",
       " 'Senior DBA': ['Database Manager',\n",
       "  'Data Architect',\n",
       "  'Director of Database Management',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Senior Data Analyst': ['Data Engineer',\n",
       "  'Senior Data Engineer',\n",
       "  'Lead Data Engineer',\n",
       "  'Data Architect',\n",
       "  'Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer',\n",
       "  'Machine Learning Engineer',\n",
       "  'Big Data Engineer'],\n",
       " 'Senior Data Architect': ['Enterprise Architect',\n",
       "  'Product Analyst',\n",
       "  'Data Product Manager',\n",
       "  'Senior Data Product Manager',\n",
       "  'Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Senior Data Engineer': ['Lead Data Engineer',\n",
       "  'Data Architect',\n",
       "  'Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer'],\n",
       " 'Senior Data Product Manager': ['Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Senior Data Scientist': ['Lead Data Scientist',\n",
       "  'Principal Data Scientist',\n",
       "  'Data Science Manager',\n",
       "  'Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Senior Machine Learning Engineer': ['Machine Learning Architect',\n",
       "  'Machine Learning Manager',\n",
       "  'Head of Machine Learning',\n",
       "  'Chief AI Officer'],\n",
       " 'Senior Quantitative Analyst': ['Quantitative Research Manager',\n",
       "  'Director of Quantitative Research'],\n",
       " 'Senior Research Scientist': ['Principal Scientist',\n",
       "  'Director of Research',\n",
       "  'Chief Science Officer'],\n",
       " 'Senior Statistician': ['Quantitative Analyst',\n",
       "  'Senior Quantitative Analyst',\n",
       "  'Quantitative Research Manager',\n",
       "  'Director of Quantitative Research'],\n",
       " 'Statistician': ['Senior Statistician',\n",
       "  'Quantitative Analyst',\n",
       "  'Senior Quantitative Analyst',\n",
       "  'Quantitative Research Manager',\n",
       "  'Director of Quantitative Research'],\n",
       " 'Vice President of Business Intelligence': ['Chief Intelligence Officer'],\n",
       " 'Vice President of Data Science': ['Chief Data Scientist'],\n",
       " 'Vice President of Product': ['Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)']}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#job progression dictionary\n",
    "# Define the original dictionary provided by the user\n",
    "\n",
    "Job_progression_dictionary =  {\n",
    "\"Junior Data Analyst\" : [\"Data Analyst\", \"Senior Data Analyst\", \"Data Engineer\", \"Senior Data Engineer\", \"Lead Data Engineer\", \"Data Architect\", \"Data Manager\", \"Director of Analytics\", \"Chief Data Officer\"],\n",
    "\"Junior Data Scientist\" : [\"Data Scientist\", \"Senior Data Scientist\", \"Lead Data Scientist\", \"Principal Data Scientist\", \"Data Science Manager\", \"Director of Data Science\", \"Vice President of Data Science\", \"Chief Data Scientist\"],\n",
    "\"Junior Data Engineer\" : [\"Data Engineer\", \"Senior Data Engineer\", \"Data Pipeline Architect\", \"Data Engineering Manager\", \"Director of Data Engineering\", \"Chief Technology Officer (CTO)\"],\n",
    "\"Business Intelligence Analyst\" : [\"Senior Business Intelligence Analyst\", \"Business Intelligence Manager\", \"Director of Business Intelligence\", \"Vice President of Business Intelligence\", \"Chief Intelligence Officer\"],\n",
    "\"Machine Learning Engineer\" : [\"Senior Machine Learning Engineer\", \"Machine Learning Architect\", \"Machine Learning Manager\", \"Head of Machine Learning\", \"Chief AI Officer\"],\n",
    "\"Data Analyst\" : [\"Data Engineer\", \"Senior Data Engineer\", \"Data Architect\", \"Senior Data Architect\", \"Enterprise Architect\", \"Chief Technology Officer (CTO)\"],\n",
    "\"Data Analyst\" : [\"Big Data Engineer\", \"Senior Big Data Engineer\", \"Big Data Architect\", \"Head of Big Data\", \"Director of Data Engineering\", \"Chief Information Officer (CIO)\"],\n",
    "\"Junior AI Developer\" : [\"AI Developer\", \"Senior AI Developer\", \"AI Architect\", \"AI Project Manager\", \"Head of AI\", \"Chief AI Officer\"],\n",
    "\"Junior DBA\" : [\"Mid-level DBA\", \"Senior DBA\", \"Database Manager\", \"Data Architect\", \"Director of Database Management\", \"Chief Information Officer (CIO)\"],\n",
    "\"Junior Statistician\" : [\"Statistician\" , \"Senior Statistician\", \"Quantitative Analyst\", \"Senior Quantitative Analyst\", \"Quantitative Research Manager\", \"Director of Quantitative Research\"],\n",
    "\"Junior Business Analyst\" : [\"Business Analyst\", \"Senior Business Analyst\", \"Business Analysis Manager\", \"Business Intelligence Analyst\", \"Director of Business Analysis\", \"Chief Strategy Officer\"],\n",
    "\"Research Assistant\" : [\"Research Analyst\", \"Research Scientist\", \"Senior Research Scientist\", \"Principal Scientist\", \"Director of Research\", \"Chief Science Officer\"],\n",
    "\"Data Analyst\" : [\"Product Analyst\", \"Data Product Manager\", \"Senior Data Product Manager\", \"Director of Product Management\", \"Vice President of Product\", \"Chief Product Officer\"]\n",
    "}\n",
    "\n",
    "original_dict = {\n",
    "    \"Junior Data Analyst\": [\"Data Analyst\", \"Senior Data Analyst\", \"Data Engineer\", \"Senior Data Engineer\", \n",
    "                            \"Lead Data Engineer\", \"Data Architect\", \"Data Manager\", \"Director of Analytics\", \n",
    "                            \"Chief Data Officer\"],\n",
    "    \"Junior Data Scientist\": [\"Data Scientist\", \"Senior Data Scientist\", \"Lead Data Scientist\", \n",
    "                              \"Principal Data Scientist\", \"Data Science Manager\", \"Director of Data Science\", \n",
    "                              \"Vice President of Data Science\", \"Chief Data Scientist\"],\n",
    "    \"Junior Data Engineer\": [\"Data Engineer\", \"Senior Data Engineer\", \"Data Pipeline Architect\", \n",
    "                             \"Data Engineering Manager\", \"Director of Data Engineering\", \"Chief Technology Officer (CTO)\"],\n",
    "    \"Business Intelligence Analyst\": [\"Senior Business Intelligence Analyst\", \"Business Intelligence Manager\", \n",
    "                                      \"Director of Business Intelligence\", \"Vice President of Business Intelligence\", \n",
    "                                      \"Chief Intelligence Officer\"],\n",
    "    \"Machine Learning Engineer\": [\"Senior Machine Learning Engineer\", \"Machine Learning Architect\", \n",
    "                                  \"Machine Learning Manager\", \"Head of Machine Learning\", \"Chief AI Officer\"],\n",
    "    \"Junior AI Developer\": [\"AI Developer\", \"Senior AI Developer\", \"AI Architect\", \"AI Project Manager\", \n",
    "                            \"Head of AI\", \"Chief AI Officer\"],\n",
    "    \"Junior DBA\": [\"Mid-level DBA\", \"Senior DBA\", \"Database Manager\", \"Data Architect\", \"Director of Database Management\", \n",
    "                   \"Chief Information Officer (CIO)\"],\n",
    "    \"Junior Statistician\": [\"Statistician\", \"Senior Statistician\", \"Quantitative Analyst\", \"Senior Quantitative Analyst\", \n",
    "                            \"Quantitative Research Manager\", \"Director of Quantitative Research\"],\n",
    "    \"Junior Business Analyst\": [\"Business Analyst\", \"Senior Business Analyst\", \"Business Analysis Manager\", \n",
    "                                \"Business Intelligence Analyst\", \"Director of Business Analysis\", \"Chief Strategy Officer\"],\n",
    "    \"Research Assistant\": [\"Research Analyst\", \"Research Scientist\", \"Senior Research Scientist\", \"Principal Scientist\", \n",
    "                           \"Director of Research\", \"Chief Science Officer\"],\n",
    "    # Multiple entries for Data Analyst have been combined to include all unique progressions\n",
    "    \"Data Analyst\": [\"Data Engineer\", \"Senior Data Engineer\", \"Lead Data Engineer\", \"Data Architect\", \n",
    "                     \"Senior Data Architect\", \"Enterprise Architect\", \"Product Analyst\", \"Data Product Manager\", \n",
    "                     \"Senior Data Product Manager\", \"Director of Product Management\", \"Vice President of Product\", \n",
    "                     \"Chief Product Officer\", \"Big Data Engineer\", \"Senior Big Data Engineer\", \"Big Data Architect\", \n",
    "                     \"Head of Big Data\", \"Director of Data Engineering\", \"Chief Information Officer (CIO)\"]\n",
    "}\n",
    "\n",
    "# Define lateral moves for the given roles\n",
    "lateral_moves = {\n",
    "    \"Data Analyst\": [\"Business Intelligence Analyst\", \"Machine Learning Engineer\"],\n",
    "    \"Data Scientist\": [\"Data Engineer\", \"AI Developer\"],\n",
    "    \"Data Engineer\": [\"Machine Learning Engineer\", \"Big Data Engineer\"],\n",
    "    \"Business Intelligence Analyst\": [\"Data Analyst\", \"Data Scientist\"],\n",
    "    \"Machine Learning Engineer\": [\"Data Scientist\", \"AI Developer\"],\n",
    "    \"AI Developer\": [\"Machine Learning Engineer\", \"Data Engineer\"],\n",
    "    \"DBA\": [\"Data Engineer\", \"Data Analyst\"],\n",
    "    \"Statistician\": [\"Data Analyst\", \"Data Scientist\"],\n",
    "    \"Business Analyst\": [\"Data Analyst\", \"Business Intelligence Analyst\"],\n",
    "    \"Research Analyst\": [\"Data Scientist\", \"Statistician\"]\n",
    "}\n",
    "\n",
    "# Since we want to include lateral moves for each value in the original dictionary, \n",
    "# we will create a function that merges the direct progressions and lateral moves into one list.\n",
    "\n",
    "# Function to merge progression and lateral moves\n",
    "def merge_progression_and_lateral_moves(direct_progression, lateral_move_titles):\n",
    "    # Start with direct progression\n",
    "    full_progression = direct_progression.copy()\n",
    "    \n",
    "    # Add lateral moves for each title in the direct progression if they exist\n",
    "    for title in direct_progression:\n",
    "        lateral_titles = lateral_moves.get(title, [])\n",
    "        for lateral_title in lateral_titles:\n",
    "            if lateral_title not in full_progression:  # Avoid duplicates\n",
    "                full_progression.append(lateral_title)\n",
    "    \n",
    "    return full_progression\n",
    "\n",
    "# Function to build a full job progression dictionary for each title\n",
    "def build_full_progression_dict(original_dict, lateral_moves):\n",
    "    full_progression_dict = {}\n",
    "    \n",
    "    # Iterate over each starting job title\n",
    "    for start_title, progression in original_dict.items():\n",
    "        # Get the full progression for the starting title\n",
    "        full_progression = merge_progression_and_lateral_moves(progression, lateral_moves)\n",
    "        \n",
    "        # Add the full progression to the dictionary for the starting title\n",
    "        full_progression_dict[start_title] = full_progression\n",
    "        \n",
    "        # Now iterate over each job within the progression to build their own progression paths\n",
    "        for i, title in enumerate(progression):\n",
    "            if title not in full_progression_dict:  # Only add if it doesn't already exist to avoid overwriting\n",
    "                # Get the progression for this title (which is the rest of the list after this title)\n",
    "                next_progression = merge_progression_and_lateral_moves(progression[i + 1:], lateral_moves)\n",
    "                full_progression_dict[title] = next_progression\n",
    "    \n",
    "    return full_progression_dict\n",
    "\n",
    "# Building the full job progression dictionary\n",
    "full_job_progression_dict = build_full_progression_dict(original_dict, lateral_moves)\n",
    "\n",
    "# Sorting the dictionary for better readability\n",
    "sorted_full_job_progression_dict = {k: full_job_progression_dict[k] for k in sorted(full_job_progression_dict)}\n",
    "\n",
    "\n",
    "unique_job_title_full = set()\n",
    "for key,value in Job_progression_dictionary.items():\n",
    "    unique_job_title_full.add(key)\n",
    "    for each in value:\n",
    "        unique_job_title_full.add(each)\n",
    "\n",
    "\n",
    "unique_job_title = set()\n",
    "for key,value in sorted_full_job_progression_dict.items():\n",
    "    unique_job_title.add(key)\n",
    "    for each in value:\n",
    "        unique_job_title.add(each)\n",
    "\n",
    "unique_job_title.difference(unique_job_title_full)\n",
    "\n",
    "sorted_full_job_progression_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean title\n",
    "import re\n",
    "import numpy as np\n",
    "from fuzzywuzzy import process\n",
    "#base_job_titles = list(sorted_full_job_progression_dict.keys())  # Add any other base titles as necessary\n",
    "#scraped_titles = df_j_cleaned[\"displayTitle\"].unique().tolist()\n",
    "\n",
    "# Function to normalize job titles\n",
    "def normalize_title(title):\n",
    "    # Lowercase and remove non-alphanumeric characters, replace with spaces\n",
    "    title = re.sub(r'[^a-z0-9]', ' ', title.lower())\n",
    "    # Remove extra whitespace\n",
    "    title = re.sub(r'\\s+', ' ', title).strip()\n",
    "\n",
    "        # Remove common prefixes/suffixes\n",
    "    #title = re.sub(r'\\b(senior|junior|associate|expert|technical|lead|l\\d+)\\b', '', title)\n",
    "    title = re.sub(r'\\b(sr|senior|expert|technical|lead|l\\d+)\\b', 'Senior', title)\n",
    "    title = re.sub(r'\\b(III|6|5|4|3|l\\d+)\\b', 'Senior', title)\n",
    "    # Replace specific terms with standardized equivalents\n",
    "    title = re.sub(r'\\b(sr\\.?|senior)\\b', 'senior', title)  # Replace 'sr' or 'senior' with 'senior'\n",
    "    title = re.sub(r'\\b(jr\\.?|junior)\\b', 'junior', title) \n",
    "\n",
    "    # Convert to lower case and remove special characters\n",
    "    title = re.sub(r'[^a-z\\s]', '', title.lower())\n",
    "\n",
    "    # Strip extra whitespace\n",
    "    title = re.sub(r'\\s+', ' ', title).strip()\n",
    "    return title\n",
    "\n",
    "# Create a set of base job titles from your job progression dictionary\n",
    "base_job_titles = set()\n",
    "for titles_list in sorted_full_job_progression_dict.values():\n",
    "    for title in titles_list:\n",
    "        base_job_titles.add(normalize_title(title))  # Add the normalized base title\n",
    "\n",
    "\n",
    "\n",
    "# Function to find the best matching title from the base job titles\n",
    "def match_title_to_base(scraped_title, base_job_titles):\n",
    "    # Normalize the scraped job title\n",
    "    normalized_title = normalize_title(scraped_title)\n",
    "    # Check if the normalized title exactly matches one of the base job titles\n",
    "    if normalized_title in base_job_titles:\n",
    "        return normalized_title  # Return the matching base title\n",
    "    \n",
    "    # Partial match checking - longer base titles are checked first to match more specific job titles\n",
    "    sorted_base_titles = sorted(base_job_titles, key=len, reverse=True)\n",
    "    for base_title in sorted_base_titles:\n",
    "        if base_title in normalized_title:\n",
    "            if \"senior\" in normalized_title and \"senior\" not in base_title:\n",
    "                return \"senior \"+base_title\n",
    "            if \"junior\" in normalized_title and \"junior\" not in base_title:\n",
    "                return \"junior \"+base_title\n",
    "            return base_title\n",
    "    \n",
    "    return \"unmatched\"  # Return \"unmatched\" or some default value if no match is found\n",
    "\n",
    "# Define a function to match job titles using fuzzy string matching\n",
    "def fuzzy_match_title(scraped_title, base_job_titles, threshold=90):\n",
    "    # Use the process function to find the closest match above a certain score threshold\n",
    "    best_match, score = process.extractOne(scraped_title, base_job_titles)\n",
    "    # Only accept the match if the score is above the threshold\n",
    "    return best_match if score >= threshold else \"unmatched\"\n",
    "\n",
    "'''\n",
    "# Match each scraped title to a base title\n",
    "matched_titles = {title: match_title_to_base(title, base_job_titles) for title in scraped_titles}\n",
    "matched_titles_fuzzy = {}\n",
    "for title in [normalize_title(each) for each in scraped_titles]:\n",
    "    matched_titles_fuzzy[title] = fuzzy_match_title(title, base_job_titles)\n",
    "\n",
    "def fill_best_value(matched_titles_fuzzy,matched_titles):\n",
    "    for k,v in matched_titles_fuzzy:\n",
    "        if v==None:\n",
    "            matched_titles_fuzzy[k]= matched_titles[k]\n",
    "\n",
    "    for k,v in matched_titles_fuzzy:\n",
    "        if v==None:\n",
    "            matched_titles_fuzzy[k]= matched_titles[k]\n",
    "'''\n",
    "\n",
    "\n",
    "df_j_cleaned[\"title\"] = df_j_cleaned[\"title\"].apply(lambda x: fuzzy_match_title(x,base_job_titles))\n",
    "df_j_cleaned[\"title\"] = df_j_cleaned[\"title\"].apply(lambda x: match_title_to_base(x,base_job_titles))\n",
    "df_j_cleaned[\"displayTitle\"] = df_j_cleaned[\"displayTitle\"].apply(lambda x: fuzzy_match_title(x,base_job_titles))\n",
    "df_j_cleaned[\"displayTitle\"] = df_j_cleaned[\"displayTitle\"].apply(lambda x: match_title_to_base(x,base_job_titles))\n",
    "\n",
    "df_j_cleaned[\"title\"] = df_j_cleaned[\"title\"].apply(lambda x: match_title_to_base(x,base_job_titles))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_most_important = ['company', 'truncatedCompany',\n",
    " 'companyRating',\n",
    " 'companyReviewCount',\n",
    " 'displayTitle',\n",
    "  'title',\n",
    " 'normTitle',\n",
    " 'min',\n",
    " 'max',\n",
    " 'type',\n",
    " 'snippet',\n",
    " 'jobDescription','skills_tagged']\n",
    "\n",
    "df_j_cleaned = df_j_cleaned[columns_most_important]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean course data \n",
    "def clean_course_df(df):\n",
    "    df[\"full_description\"] = df[\"description\"]+df[\"what_you_will_learn_data\"]+df[\"objectives\"]\n",
    "    df = clean_lem_stop(df,\"full_description\")\n",
    "    course_description = df[\"full_description\"].tolist()\n",
    "    return df,course_description\n",
    "\n",
    "df_c_cleaned,course_descriptions = clean_course_df(df_c)\n",
    "\n",
    "df_c_cleaned[\"skills_tagged\"] = df_c_cleaned[\"full_description\"].apply(lambda x:phrase_matcher_model(x,skills_list))\n",
    "\n",
    "\n",
    "df_c_cleaned.columns.tolist()\n",
    "\n",
    "course_columns_imp = [\n",
    " 'title',\n",
    " 'url',\n",
    " 'price_detail',\n",
    " 'description',\n",
    " 'headline',\n",
    " 'num_subscribers',\n",
    " 'rating',\n",
    " 'num_reviews',\n",
    " 'num_quizzes',\n",
    " 'num_lectures',\n",
    " 'num_curriculum_items',\n",
    " 'requirements_data',\n",
    " 'what_you_will_learn_data',\n",
    " 'labels',\n",
    " 'target_audiences',\n",
    " 'estimated_content_length',\n",
    " 'content_info',\n",
    " 'instructional_level',\n",
    " 'objectives',\n",
    " 'full_description',\n",
    " 'skills_tagged']\n",
    "\n",
    "df_c_cleaned = df_c_cleaned[course_columns_imp]\n",
    "\n",
    "\n",
    "def  course_price_detail(x):\n",
    "    cou_dict = ast.literal_eval(x)\n",
    "    return cou_dict[\"amount\"]\n",
    "\n",
    "def  category_primary(x):\n",
    "    cou_dict = ast.literal_eval(x)\n",
    "    return cou_dict[\"url\"]\n",
    "\n",
    "def  labels_return_title(x):\n",
    "    cou_dict = ast.literal_eval(x)\n",
    "    return cou_dict[0][\"title\"]\n",
    "\n",
    "\n",
    "def  labels_return_url(x):\n",
    "    cou_dict = ast.literal_eval(x)\n",
    "    return cou_dict[0][\"url\"]\n",
    "\n",
    "\n",
    "def  labels_return_display_name(x):\n",
    "    cou_dict = ast.literal_eval(x)\n",
    "    return cou_dict[0][\"display_name\"]\n",
    "\n",
    "df_c_cleaned[\"price\"] = df_c_cleaned[\"price_detail\"].apply(lambda x: course_price_detail(x))\n",
    "df_c_cleaned[\"requirements_data\"] = df_c_cleaned[\"requirements_data\"].apply(lambda x:ast.literal_eval(x)[0])\n",
    "df_c_cleaned[\"course_title\"]=df_c_cleaned[\"labels\"].apply(lambda x:labels_return_title(x))\n",
    "df_c_cleaned[\"course_url\"] =df_c_cleaned[\"labels\"].apply(lambda x:labels_return_url(x))\n",
    "df_c_cleaned[\"course_display_name\"] =df_c_cleaned[\"labels\"].apply(lambda x:labels_return_display_name(x))\n",
    "df_c_cleaned[\"objectives\"] =df_c_cleaned[\"objectives\"].apply(lambda x:ast.literal_eval(x)[0])\n",
    "del df_c_cleaned[\"labels\"]\n",
    "df_c_cleaned[\"what_you_will_learn_data\"] = df_c_cleaned[\"what_you_will_learn_data\"].apply(lambda x:ast.literal_eval(x)[0])\n",
    "df_c_cleaned[\"target_audiences\"] = df_c_cleaned[\"target_audiences\"].apply(lambda x:ast.literal_eval(x)[0])\n",
    "del df_c_cleaned[\"price_detail\"]\n",
    "clean_course_columns =[\"title\",\n",
    "\"description\",\n",
    "\"headline\",\n",
    "\"requirements_data\",\n",
    "\"what_you_will_learn_data\",\n",
    "\"target_audiences\",\n",
    "\"objectives\",\n",
    "\"full_description\",\n",
    "\"course_title\",\n",
    "\"course_display_name\"]\n",
    "for clean_column in clean_course_columns:\n",
    "    df_c_cleaned = clean_lem_stop(df_c_cleaned,clean_column)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = set()\n",
    "for i,each in enumerate(df_c_cleaned[\"skills_tagged\"]):\n",
    "    if len(each)==0:\n",
    "        print(i)\n",
    "    for each_v in each:\n",
    "        xs.add(each_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>price_detail</th>\n",
       "      <th>description</th>\n",
       "      <th>headline</th>\n",
       "      <th>num_subscribers</th>\n",
       "      <th>rating</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>num_quizzes</th>\n",
       "      <th>num_lectures</th>\n",
       "      <th>num_curriculum_items</th>\n",
       "      <th>requirements_data</th>\n",
       "      <th>what_you_will_learn_data</th>\n",
       "      <th>target_audiences</th>\n",
       "      <th>estimated_content_length</th>\n",
       "      <th>content_info</th>\n",
       "      <th>instructional_level</th>\n",
       "      <th>objectives</th>\n",
       "      <th>full_description</th>\n",
       "      <th>skills_tagged</th>\n",
       "      <th>price</th>\n",
       "      <th>course_title</th>\n",
       "      <th>course_url</th>\n",
       "      <th>course_display_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data science course complete data science boot...</td>\n",
       "      <td>https://www.udemy.com/course/the-data-science-...</td>\n",
       "      <td>{'amount': 109.99, 'currency': 'USD', 'price_s...</td>\n",
       "      <td>p strong problem strong p p data scientist bes...</td>\n",
       "      <td>complete data science training mathematics sta...</td>\n",
       "      <td>634583</td>\n",
       "      <td>4.594564</td>\n",
       "      <td>131509</td>\n",
       "      <td>281</td>\n",
       "      <td>518</td>\n",
       "      <td>799</td>\n",
       "      <td>prior experience required start basics</td>\n",
       "      <td>course provides entire toolbox need data scien...</td>\n",
       "      <td>course want data scientist want learn field</td>\n",
       "      <td>1906</td>\n",
       "      <td>32 total hours</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>course provides entire toolbox need data scien...</td>\n",
       "      <td>p strong problem strong p p data scientist bes...</td>\n",
       "      <td>{python programming language, statistical anal...</td>\n",
       "      <td>109.99</td>\n",
       "      <td>data science</td>\n",
       "      <td>https://www.udemy.com/topic/data-science/</td>\n",
       "      <td>data science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r programming z r data science real exercises</td>\n",
       "      <td>https://www.udemy.com/course/r-programming/</td>\n",
       "      <td>{'amount': 94.99, 'currency': 'USD', 'price_st...</td>\n",
       "      <td>p learn r programming p p lots r courses lectu...</td>\n",
       "      <td>learn programming r r studio data analytics da...</td>\n",
       "      <td>261248</td>\n",
       "      <td>4.662838</td>\n",
       "      <td>51993</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>94</td>\n",
       "      <td>prior knowledge experience needed passion succ...</td>\n",
       "      <td>learn program r good level</td>\n",
       "      <td>course want learn program r</td>\n",
       "      <td>638</td>\n",
       "      <td>10.5 total hours</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>learn program r good level</td>\n",
       "      <td>p learn r programming p p lots r courses lectu...</td>\n",
       "      <td>{statistical}</td>\n",
       "      <td>94.99</td>\n",
       "      <td>data mining</td>\n",
       "      <td>https://www.udemy.com/topic/data-mining/</td>\n",
       "      <td>data mining</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "2  data science course complete data science boot...   \n",
       "3      r programming z r data science real exercises   \n",
       "\n",
       "                                                 url  \\\n",
       "2  https://www.udemy.com/course/the-data-science-...   \n",
       "3        https://www.udemy.com/course/r-programming/   \n",
       "\n",
       "                                        price_detail  \\\n",
       "2  {'amount': 109.99, 'currency': 'USD', 'price_s...   \n",
       "3  {'amount': 94.99, 'currency': 'USD', 'price_st...   \n",
       "\n",
       "                                         description  \\\n",
       "2  p strong problem strong p p data scientist bes...   \n",
       "3  p learn r programming p p lots r courses lectu...   \n",
       "\n",
       "                                            headline  num_subscribers  \\\n",
       "2  complete data science training mathematics sta...           634583   \n",
       "3  learn programming r r studio data analytics da...           261248   \n",
       "\n",
       "     rating  num_reviews  num_quizzes  num_lectures  num_curriculum_items  \\\n",
       "2  4.594564       131509          281           518                   799   \n",
       "3  4.662838        51993            5            89                    94   \n",
       "\n",
       "                                   requirements_data  \\\n",
       "2             prior experience required start basics   \n",
       "3  prior knowledge experience needed passion succ...   \n",
       "\n",
       "                            what_you_will_learn_data  \\\n",
       "2  course provides entire toolbox need data scien...   \n",
       "3                         learn program r good level   \n",
       "\n",
       "                              target_audiences  estimated_content_length  \\\n",
       "2  course want data scientist want learn field                      1906   \n",
       "3                  course want learn program r                       638   \n",
       "\n",
       "       content_info instructional_level  \\\n",
       "2    32 total hours          All Levels   \n",
       "3  10.5 total hours          All Levels   \n",
       "\n",
       "                                          objectives  \\\n",
       "2  course provides entire toolbox need data scien...   \n",
       "3                         learn program r good level   \n",
       "\n",
       "                                    full_description  \\\n",
       "2  p strong problem strong p p data scientist bes...   \n",
       "3  p learn r programming p p lots r courses lectu...   \n",
       "\n",
       "                                       skills_tagged   price  course_title  \\\n",
       "2  {python programming language, statistical anal...  109.99  data science   \n",
       "3                                      {statistical}   94.99   data mining   \n",
       "\n",
       "                                  course_url course_display_name  \n",
       "2  https://www.udemy.com/topic/data-science/        data science  \n",
       "3   https://www.udemy.com/topic/data-mining/         data mining  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c_cleaned[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>truncatedCompany</th>\n",
       "      <th>companyRating</th>\n",
       "      <th>companyReviewCount</th>\n",
       "      <th>displayTitle</th>\n",
       "      <th>title</th>\n",
       "      <th>normTitle</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>type</th>\n",
       "      <th>snippet</th>\n",
       "      <th>jobDescription</th>\n",
       "      <th>skills_tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CGI Group, Inc.</td>\n",
       "      <td>CGI Group, Inc.</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>Technical Lead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technical Lead - AWS Data Engineer (Python) - ...</td>\n",
       "      <td>technical lead aws data engineer python remote...</td>\n",
       "      <td>{computer science, bitbucket, c, big data, dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Walmart Advanced Systems &amp; Robotics</td>\n",
       "      <td>Walmart Advanced Systems &amp; Robotics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>data engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Walmart Advanced Systems &amp;amp; Robotics is a f...</td>\n",
       "      <td>walmart advanced system amp robotics fast grow...</td>\n",
       "      <td>{data integration, computer science, test data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               company                     truncatedCompany  \\\n",
       "2                      CGI Group, Inc.                      CGI Group, Inc.   \n",
       "3  Walmart Advanced Systems & Robotics  Walmart Advanced Systems & Robotics   \n",
       "\n",
       "   companyRating  companyReviewCount   displayTitle          title  \\\n",
       "2            3.6              3570.0  data engineer  data engineer   \n",
       "3            NaN                 NaN  data engineer  data engineer   \n",
       "\n",
       "        normTitle  min  max type  \\\n",
       "2  Technical Lead  NaN  NaN  NaN   \n",
       "3   Data Engineer  NaN  NaN  NaN   \n",
       "\n",
       "                                             snippet  \\\n",
       "2  Technical Lead - AWS Data Engineer (Python) - ...   \n",
       "3  Walmart Advanced Systems &amp; Robotics is a f...   \n",
       "\n",
       "                                      jobDescription  \\\n",
       "2  technical lead aws data engineer python remote...   \n",
       "3  walmart advanced system amp robotics fast grow...   \n",
       "\n",
       "                                       skills_tagged  \n",
       "2  {computer science, bitbucket, c, big data, dev...  \n",
       "3  {data integration, computer science, test data...  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_j_cleaned[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AI Architect': ['AI Project Manager', 'Head of AI', 'Chief AI Officer'],\n",
       " 'AI Developer': ['Senior AI Developer',\n",
       "  'AI Architect',\n",
       "  'AI Project Manager',\n",
       "  'Head of AI',\n",
       "  'Chief AI Officer'],\n",
       " 'AI Project Manager': ['Head of AI', 'Chief AI Officer'],\n",
       " 'Big Data Architect': ['Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Big Data Engineer': ['Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Business Analysis Manager': ['Business Intelligence Analyst',\n",
       "  'Director of Business Analysis',\n",
       "  'Chief Strategy Officer',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist'],\n",
       " 'Business Analyst': ['Senior Business Analyst',\n",
       "  'Business Analysis Manager',\n",
       "  'Business Intelligence Analyst',\n",
       "  'Director of Business Analysis',\n",
       "  'Chief Strategy Officer',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist'],\n",
       " 'Business Intelligence Analyst': ['Senior Business Intelligence Analyst',\n",
       "  'Business Intelligence Manager',\n",
       "  'Director of Business Intelligence',\n",
       "  'Vice President of Business Intelligence',\n",
       "  'Chief Intelligence Officer'],\n",
       " 'Business Intelligence Manager': ['Director of Business Intelligence',\n",
       "  'Vice President of Business Intelligence',\n",
       "  'Chief Intelligence Officer'],\n",
       " 'Chief AI Officer': [],\n",
       " 'Chief Data Officer': [],\n",
       " 'Chief Data Scientist': [],\n",
       " 'Chief Information Officer (CIO)': [],\n",
       " 'Chief Intelligence Officer': [],\n",
       " 'Chief Product Officer': ['Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Chief Science Officer': [],\n",
       " 'Chief Strategy Officer': [],\n",
       " 'Chief Technology Officer (CTO)': [],\n",
       " 'Data Analyst': ['Data Engineer',\n",
       "  'Senior Data Engineer',\n",
       "  'Lead Data Engineer',\n",
       "  'Data Architect',\n",
       "  'Senior Data Architect',\n",
       "  'Enterprise Architect',\n",
       "  'Product Analyst',\n",
       "  'Data Product Manager',\n",
       "  'Senior Data Product Manager',\n",
       "  'Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)',\n",
       "  'Machine Learning Engineer'],\n",
       " 'Data Architect': ['Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer'],\n",
       " 'Data Engineer': ['Senior Data Engineer',\n",
       "  'Lead Data Engineer',\n",
       "  'Data Architect',\n",
       "  'Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer'],\n",
       " 'Data Engineering Manager': ['Director of Data Engineering',\n",
       "  'Chief Technology Officer (CTO)'],\n",
       " 'Data Manager': ['Director of Analytics', 'Chief Data Officer'],\n",
       " 'Data Pipeline Architect': ['Data Engineering Manager',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Technology Officer (CTO)'],\n",
       " 'Data Product Manager': ['Senior Data Product Manager',\n",
       "  'Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Data Science Manager': ['Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Data Scientist': ['Senior Data Scientist',\n",
       "  'Lead Data Scientist',\n",
       "  'Principal Data Scientist',\n",
       "  'Data Science Manager',\n",
       "  'Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Database Manager': ['Data Architect',\n",
       "  'Director of Database Management',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Director of Analytics': ['Chief Data Officer'],\n",
       " 'Director of Business Analysis': ['Chief Strategy Officer'],\n",
       " 'Director of Business Intelligence': ['Vice President of Business Intelligence',\n",
       "  'Chief Intelligence Officer'],\n",
       " 'Director of Data Engineering': ['Chief Technology Officer (CTO)'],\n",
       " 'Director of Data Science': ['Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Director of Database Management': ['Chief Information Officer (CIO)'],\n",
       " 'Director of Product Management': ['Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Director of Quantitative Research': [],\n",
       " 'Director of Research': ['Chief Science Officer'],\n",
       " 'Enterprise Architect': ['Product Analyst',\n",
       "  'Data Product Manager',\n",
       "  'Senior Data Product Manager',\n",
       "  'Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Head of AI': ['Chief AI Officer'],\n",
       " 'Head of Big Data': ['Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Head of Machine Learning': ['Chief AI Officer'],\n",
       " 'Junior AI Developer': ['AI Developer',\n",
       "  'Senior AI Developer',\n",
       "  'AI Architect',\n",
       "  'AI Project Manager',\n",
       "  'Head of AI',\n",
       "  'Chief AI Officer',\n",
       "  'Machine Learning Engineer',\n",
       "  'Data Engineer'],\n",
       " 'Junior Business Analyst': ['Business Analyst',\n",
       "  'Senior Business Analyst',\n",
       "  'Business Analysis Manager',\n",
       "  'Business Intelligence Analyst',\n",
       "  'Director of Business Analysis',\n",
       "  'Chief Strategy Officer',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist'],\n",
       " 'Junior DBA': ['Mid-level DBA',\n",
       "  'Senior DBA',\n",
       "  'Database Manager',\n",
       "  'Data Architect',\n",
       "  'Director of Database Management',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Junior Data Analyst': ['Data Analyst',\n",
       "  'Senior Data Analyst',\n",
       "  'Data Engineer',\n",
       "  'Senior Data Engineer',\n",
       "  'Lead Data Engineer',\n",
       "  'Data Architect',\n",
       "  'Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer',\n",
       "  'Business Intelligence Analyst',\n",
       "  'Machine Learning Engineer',\n",
       "  'Big Data Engineer'],\n",
       " 'Junior Data Engineer': ['Data Engineer',\n",
       "  'Senior Data Engineer',\n",
       "  'Data Pipeline Architect',\n",
       "  'Data Engineering Manager',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Technology Officer (CTO)',\n",
       "  'Machine Learning Engineer',\n",
       "  'Big Data Engineer'],\n",
       " 'Junior Data Scientist': ['Data Scientist',\n",
       "  'Senior Data Scientist',\n",
       "  'Lead Data Scientist',\n",
       "  'Principal Data Scientist',\n",
       "  'Data Science Manager',\n",
       "  'Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist',\n",
       "  'Data Engineer',\n",
       "  'AI Developer'],\n",
       " 'Junior Statistician': ['Statistician',\n",
       "  'Senior Statistician',\n",
       "  'Quantitative Analyst',\n",
       "  'Senior Quantitative Analyst',\n",
       "  'Quantitative Research Manager',\n",
       "  'Director of Quantitative Research',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist'],\n",
       " 'Lead Data Engineer': ['Data Architect',\n",
       "  'Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer'],\n",
       " 'Lead Data Scientist': ['Principal Data Scientist',\n",
       "  'Data Science Manager',\n",
       "  'Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Machine Learning Architect': ['Machine Learning Manager',\n",
       "  'Head of Machine Learning',\n",
       "  'Chief AI Officer'],\n",
       " 'Machine Learning Engineer': ['Senior Machine Learning Engineer',\n",
       "  'Machine Learning Architect',\n",
       "  'Machine Learning Manager',\n",
       "  'Head of Machine Learning',\n",
       "  'Chief AI Officer'],\n",
       " 'Machine Learning Manager': ['Head of Machine Learning', 'Chief AI Officer'],\n",
       " 'Mid-level DBA': ['Senior DBA',\n",
       "  'Database Manager',\n",
       "  'Data Architect',\n",
       "  'Director of Database Management',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Principal Data Scientist': ['Data Science Manager',\n",
       "  'Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Principal Scientist': ['Director of Research', 'Chief Science Officer'],\n",
       " 'Product Analyst': ['Data Product Manager',\n",
       "  'Senior Data Product Manager',\n",
       "  'Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Quantitative Analyst': ['Senior Quantitative Analyst',\n",
       "  'Quantitative Research Manager',\n",
       "  'Director of Quantitative Research'],\n",
       " 'Quantitative Research Manager': ['Director of Quantitative Research'],\n",
       " 'Research Analyst': ['Research Scientist',\n",
       "  'Senior Research Scientist',\n",
       "  'Principal Scientist',\n",
       "  'Director of Research',\n",
       "  'Chief Science Officer'],\n",
       " 'Research Assistant': ['Research Analyst',\n",
       "  'Research Scientist',\n",
       "  'Senior Research Scientist',\n",
       "  'Principal Scientist',\n",
       "  'Director of Research',\n",
       "  'Chief Science Officer',\n",
       "  'Data Scientist',\n",
       "  'Statistician'],\n",
       " 'Research Scientist': ['Senior Research Scientist',\n",
       "  'Principal Scientist',\n",
       "  'Director of Research',\n",
       "  'Chief Science Officer'],\n",
       " 'Senior AI Developer': ['AI Architect',\n",
       "  'AI Project Manager',\n",
       "  'Head of AI',\n",
       "  'Chief AI Officer'],\n",
       " 'Senior Big Data Engineer': ['Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Senior Business Analyst': ['Business Analysis Manager',\n",
       "  'Business Intelligence Analyst',\n",
       "  'Director of Business Analysis',\n",
       "  'Chief Strategy Officer',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist'],\n",
       " 'Senior Business Intelligence Analyst': ['Business Intelligence Manager',\n",
       "  'Director of Business Intelligence',\n",
       "  'Vice President of Business Intelligence',\n",
       "  'Chief Intelligence Officer'],\n",
       " 'Senior DBA': ['Database Manager',\n",
       "  'Data Architect',\n",
       "  'Director of Database Management',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Senior Data Analyst': ['Data Engineer',\n",
       "  'Senior Data Engineer',\n",
       "  'Lead Data Engineer',\n",
       "  'Data Architect',\n",
       "  'Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer',\n",
       "  'Machine Learning Engineer',\n",
       "  'Big Data Engineer'],\n",
       " 'Senior Data Architect': ['Enterprise Architect',\n",
       "  'Product Analyst',\n",
       "  'Data Product Manager',\n",
       "  'Senior Data Product Manager',\n",
       "  'Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Senior Data Engineer': ['Lead Data Engineer',\n",
       "  'Data Architect',\n",
       "  'Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer'],\n",
       " 'Senior Data Product Manager': ['Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Senior Data Scientist': ['Lead Data Scientist',\n",
       "  'Principal Data Scientist',\n",
       "  'Data Science Manager',\n",
       "  'Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Senior Machine Learning Engineer': ['Machine Learning Architect',\n",
       "  'Machine Learning Manager',\n",
       "  'Head of Machine Learning',\n",
       "  'Chief AI Officer'],\n",
       " 'Senior Quantitative Analyst': ['Quantitative Research Manager',\n",
       "  'Director of Quantitative Research'],\n",
       " 'Senior Research Scientist': ['Principal Scientist',\n",
       "  'Director of Research',\n",
       "  'Chief Science Officer'],\n",
       " 'Senior Statistician': ['Quantitative Analyst',\n",
       "  'Senior Quantitative Analyst',\n",
       "  'Quantitative Research Manager',\n",
       "  'Director of Quantitative Research'],\n",
       " 'Statistician': ['Senior Statistician',\n",
       "  'Quantitative Analyst',\n",
       "  'Senior Quantitative Analyst',\n",
       "  'Quantitative Research Manager',\n",
       "  'Director of Quantitative Research'],\n",
       " 'Vice President of Business Intelligence': ['Chief Intelligence Officer'],\n",
       " 'Vice President of Data Science': ['Chief Data Scientist'],\n",
       " 'Vice President of Product': ['Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)']}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_full_job_progression_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job_path': ['Data Engineer', 'Senior Data Engineer', 'Senior Data Engineer'], 'courses_taken': [], 'skills': set()}\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic user data\n",
    "def generate_synthetic_data(df_j_cleaned, df_c_cleaned, skills_df, num_samples=1000):\n",
    "    synthetic_data = []\n",
    "    for _ in range(num_samples):\n",
    "        current_job, current_skills = \"Data Engineer\", df_j_cleaned[df_j_cleaned[\"title\"]==\"data engineer\"][\"skills_tagged\"].values[0]\n",
    "        # Select a job to progress to that requires at least one additional skill\n",
    "        next_job, next_skills = \"Senior Data Engineer\", df_j_cleaned[df_j_cleaned[\"title\"]==\"senior data engineer\"][\"skills_tagged\"].values[0]\n",
    "        '''\n",
    "        while set(next_skills).issubset(current_skills):\n",
    "            next_job, next_skills = select_random_job(jobs_df)\n",
    "        '''\n",
    "        # Find the skill gap\n",
    "        skill_gap = list(set(next_skills) - set(current_skills))\n",
    "        \n",
    "        # Find a course that teaches one of the skills in the gap\n",
    "        course = select_relevant_course(courses_df, skill_gap)\n",
    "        if course is not None:\n",
    "            course_name = course.Course.values[0]\n",
    "            course_skills = course.Skills_Taught.values[0]\n",
    "        else:\n",
    "            # If no single course covers the gap, select a random one for this synthetic example\n",
    "            course_name = \"Random Course\"\n",
    "            course_skills = \"Random Skill\"\n",
    "        \n",
    "        # Append to the synthetic data list\n",
    "        synthetic_data.append({\n",
    "            'Current Job': current_job,\n",
    "            'Next Job': next_job,\n",
    "            'Current Skills': current_skills,\n",
    "            'Next Skills': next_skills,\n",
    "            'Skill Gap': skill_gap,\n",
    "            'Course Taken': course_name,\n",
    "            'Course Skills': course_skills\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analytics',\n",
       " 'c',\n",
       " 'data engineering',\n",
       " 'data infrastructure',\n",
       " 'data manipulation',\n",
       " 'data modeling',\n",
       " 'data visualization',\n",
       " 'predictive modeling',\n",
       " 'problem solving',\n",
       " 'python',\n",
       " 'sql',\n",
       " 'statistical analysis'}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_j_cleaned[df_j_cleaned[\"title\"]==\"data engineer\"][\"skills_tagged\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cloud infrastructure',\n",
       " 'computer science',\n",
       " 'devops',\n",
       " 'data governance',\n",
       " 'data acquisition',\n",
       " 'java',\n",
       " 'dataset',\n",
       " 'ci cd']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_job, current_skills = \"Data Engineer\", df_j_cleaned[df_j_cleaned[\"title\"]==\"data engineer\"][\"skills_tagged\"].values[0]\n",
    "# Select a job to progress to that requires at least one additional skill\n",
    "next_job, next_skills = \"Senior Data Engineer\", df_j_cleaned[df_j_cleaned[\"title\"]==\"senior data engineer\"][\"skills_tagged\"].values[0]\n",
    "'''\n",
    "while set(next_skills).issubset(current_skills):\n",
    "    next_job, next_skills = select_random_job(jobs_df)\n",
    "'''\n",
    "# Find the skill gap\n",
    "skill_gap = list(set(next_skills) - set(current_skills))\n",
    "skill_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_course(df_c_cleaned, required_skills):\n",
    "    relevant_courses = df_c_cleaned[df_c_cleaned['skills_tagged'].apply(lambda x: any(skill in x for skill in required_skills))]\n",
    "    if not relevant_courses.empty:\n",
    "        return relevant_courses.sample()\n",
    "    return None\n",
    "\n",
    "select_relevant_course(df_c_cleaned,skill_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set a DataFrame with multiple columns to the single column course_score",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/17/gws30jys63j9xx5l0mwr5r4r0000gq/T/ipykernel_8402/2760272060.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_course_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcourse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskill_gap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_skill_match\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_subscribers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_rating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Calculate the proportion of skill gap covered by course\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/17/gws30jys63j9xx5l0mwr5r4r0000gq/T/ipykernel_8402/2760272060.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df_c_cleaned, skill_gap)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_relevant_course\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_c_cleaned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskill_gap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Apply the scoring function to each course\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdf_c_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'course_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_c_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_course_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskill_gap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskill_gap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Sort courses based on the calculated score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdf_c_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_c_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'course_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3966\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3967\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3968\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3970\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3971\u001b[0m         elif (\n\u001b[1;32m   3972\u001b[0m             \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3973\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marraylike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4122\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4125\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   4126\u001b[0m                 \u001b[0;34m\"Cannot set a DataFrame with multiple columns to the single \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4127\u001b[0m                 \u001b[0;34mf\"column {key}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4128\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set a DataFrame with multiple columns to the single column course_score"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_course_score(course, skill_gap, weight_skill_match=1, weight_subscribers=0.001, weight_rating=0.5):\n",
    "    # Calculate the proportion of skill gap covered by course\n",
    "    skills_matched = sum(skill in course['skills_tagged'] for skill in skill_gap)\n",
    "    skill_match_score = skills_matched / len(skill_gap) if skill_gap else 0\n",
    "\n",
    "    # Factor in course popularity and rating\n",
    "    subscriber_score = course['num_subscribers'] * weight_subscribers if 'num_subscribers' in course else 0\n",
    "    rating_score = course['rating'] * weight_rating if 'rating' in course else 0\n",
    "\n",
    "    # Calculate total score\n",
    "    total_score = (skill_match_score * weight_skill_match) + subscriber_score + rating_score\n",
    "    return total_score\n",
    "\n",
    "def select_relevant_course(df_c_cleaned, skill_gap):\n",
    "    # Apply the scoring function to each course\n",
    "    df_c_cleaned['course_score'] = df_c_cleaned.apply(calculate_course_score, axis=1, skill_gap=skill_gap)\n",
    "\n",
    "    # Sort courses based on the calculated score\n",
    "    df_c_cleaned = df_c_cleaned.sort_values(by='course_score', ascending=False)\n",
    "\n",
    "    # Select the top course if available\n",
    "    top_course = df_c_cleaned.iloc[0] if not df_c_cleaned.empty else None\n",
    "    return top_course\n",
    "\n",
    "# Assuming df_c_cleaned is your cleaned courses dataframe and skill_gap is a list of skills that user lacks\n",
    "df_c_cleaned = pd.DataFrame({\n",
    "    # your courses dataframe content\n",
    "})\n",
    "\n",
    "\n",
    "# Select the most relevant course based on the skill gap\n",
    "relevant_course = select_relevant_course(df_c_cleaned, skill_gap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c_cleaned.apply(calculate_course_score, axis=1, skill_gap=skill_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_gap\n",
    "\n",
    "skills_matched = sum(skill in df_c_cleaned['skills_tagged'] for skill in skill_gap)\n",
    "skill_match_score = skills_matched / len(skill_gap) if skill_gap else 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_match_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_course_overlap(course_skills, skill_gap):\n",
    "    # Calculate the number of skills in the gap that the course covers\n",
    "    overlap = len(course_skills.intersection(skill_gap))\n",
    "    # Calculate the proportion of the skill gap covered\n",
    "    if skill_gap:\n",
    "        coverage = overlap / len(skill_gap)\n",
    "    else:\n",
    "        coverage = 0\n",
    "    return overlap, coverage\n",
    "\n",
    "df_c_cleaned['overlap'], df_c_cleaned['coverage'] = zip(*df_c_cleaned['skills_tagged'].apply(calculate_course_overlap, skill_gap=set(skill_gap)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     1\n",
       "     ..\n",
       "35    0\n",
       "36    0\n",
       "37    0\n",
       "38    0\n",
       "39    0\n",
       "Name: overlap, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c_cleaned[\"overlap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_course(df_c_cleaned, skill_gap, weight_coverage=1, weight_subscribers=0.001, weight_rating=0.5):\n",
    "    # Add a new column for the overlap score\n",
    "    df_c_cleaned['overlap'], df_c_cleaned['coverage'] = zip(*df_c_cleaned['skills_tagged'].apply(\n",
    "        calculate_course_overlap, skill_gap=set(skill_gap)))\n",
    "\n",
    "\n",
    "    # Find the best course by sorting by course score\n",
    "    best_course = df_c_cleaned.sort_values(by='course_score', ascending=False).head(1)\n",
    "\n",
    "    return best_course\n",
    "    \n",
    "# Select the most relevant course for a given skill gap\n",
    "best_course = select_relevant_course(df_c_cleaned, skill_gap)\n",
    "\n",
    "best_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['machine learning z ai python r chatgpt bonus',\n",
       "       'python data science machine learning bootcamp',\n",
       "       'data science course complete data science bootcamp',\n",
       "       'r programming z r data science real exercises',\n",
       "       'deep learning z neural networks ai chatgpt bonus',\n",
       "       'statistics data science business analysis',\n",
       "       'data science z hands exercises chatgpt bonus',\n",
       "       'artificial intelligence z build ai incl chatgpt',\n",
       "       'machine learning data science generative ai python',\n",
       "       'python z python data science real exercises',\n",
       "       'spark python big data pyspark', 'data analysis pandas python',\n",
       "       'complete machine learning data science bootcamp',\n",
       "       'apache spark scala hands big data',\n",
       "       'complete guide tensorflow deep learning python',\n",
       "       'data science machine learning bootcamp r',\n",
       "       'taming big data apache spark python hands',\n",
       "       'nlp natural language processing python',\n",
       "       'introduction machine learning data science',\n",
       "       'python machine learning data science masterclass',\n",
       "       'data science natural language processing nlp python',\n",
       "       'statistics business analytics data science z',\n",
       "       'tensorflow deep learning artificial intelligence',\n",
       "       'artificial intelligence reinforcement learning python',\n",
       "       'dp azure data fundamentals exam prep day',\n",
       "       'data science deep learning neural networks python',\n",
       "       'tensorflow developer certificate zero mastery',\n",
       "       'r programming advanced analytics r data science',\n",
       "       'interactive python dashboards plotly dash',\n",
       "       'natural language processing deep learning python',\n",
       "       'complete tensorflow keras deep learning bootcamp',\n",
       "       'apache spark spark programming python beginners',\n",
       "       'complete machine learning course python',\n",
       "       'bayesian machine learning python b testing',\n",
       "       'machine learning absolute beginners level',\n",
       "       'deep learning computer vision z ai chatgpt bonuses',\n",
       "       'probability statistics business data science',\n",
       "       'deep learning advanced natural language processing rnns',\n",
       "       'deep learning prerequisites linear regression python',\n",
       "       'intro data science quickstart guide ai chatgpt bonus',\n",
       "       'deep learning advanced computer vision gans ssd',\n",
       "       'complete data science machine learning bootcamp',\n",
       "       'statistics data analysis excel',\n",
       "       'deep learning convolutional neural networks python',\n",
       "       'machine learning deep learning python r',\n",
       "       'scala spark big data machine learning',\n",
       "       'artificial intelligence machine learning business',\n",
       "       'mathematical foundations machine learning',\n",
       "       'advanced ai deep reinforcement learning python',\n",
       "       'sql database design z learn ms sql server postgresql',\n",
       "       'deployment machine learning models',\n",
       "       'cluster analysis unsupervised machine learning python',\n",
       "       'r programming statistics data science',\n",
       "       'deep learning recurrent neural networks python',\n",
       "       'data integration guide', 'pytorch deep learning python bootcamp',\n",
       "       'deep learning prerequisites logistic regression python',\n",
       "       'python machine learning financial analysis',\n",
       "       'complete self driving car course applied deep learning',\n",
       "       'artificial intelligence business chatgpt bonus'], dtype=object)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c_cleaned[\"title\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>headline</th>\n",
       "      <th>num_subscribers</th>\n",
       "      <th>rating</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>num_quizzes</th>\n",
       "      <th>num_lectures</th>\n",
       "      <th>num_curriculum_items</th>\n",
       "      <th>requirements_data</th>\n",
       "      <th>what_you_will_learn_data</th>\n",
       "      <th>target_audiences</th>\n",
       "      <th>estimated_content_length</th>\n",
       "      <th>content_info</th>\n",
       "      <th>instructional_level</th>\n",
       "      <th>objectives</th>\n",
       "      <th>full_description</th>\n",
       "      <th>skills_tagged</th>\n",
       "      <th>price</th>\n",
       "      <th>course_title</th>\n",
       "      <th>course_url</th>\n",
       "      <th>course_display_name</th>\n",
       "      <th>overlap</th>\n",
       "      <th>coverage</th>\n",
       "      <th>course_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>machine learning z ai python r chatgpt bonus</td>\n",
       "      <td>https://www.udemy.com/course/machinelearning/</td>\n",
       "      <td>p interested field machine learning nbsp cours...</td>\n",
       "      <td>learn create machine learning algorithms pytho...</td>\n",
       "      <td>993456</td>\n",
       "      <td>4.513425</td>\n",
       "      <td>176950</td>\n",
       "      <td>39</td>\n",
       "      <td>468</td>\n",
       "      <td>507</td>\n",
       "      <td>high school mathematics level</td>\n",
       "      <td>master machine learning python r</td>\n",
       "      <td>interested machine learning</td>\n",
       "      <td>2559</td>\n",
       "      <td>42.5 total hours</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>master machine learning python r</td>\n",
       "      <td>p interested field machine learning nbsp cours...</td>\n",
       "      <td>{multiple linear regression, data science, dee...</td>\n",
       "      <td>109.99</td>\n",
       "      <td>data science</td>\n",
       "      <td>https://www.udemy.com/topic/data-science/</td>\n",
       "      <td>data science</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>995.712713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title  \\\n",
       "0  machine learning z ai python r chatgpt bonus   \n",
       "\n",
       "                                             url  \\\n",
       "0  https://www.udemy.com/course/machinelearning/   \n",
       "\n",
       "                                         description  \\\n",
       "0  p interested field machine learning nbsp cours...   \n",
       "\n",
       "                                            headline  num_subscribers  \\\n",
       "0  learn create machine learning algorithms pytho...           993456   \n",
       "\n",
       "     rating  num_reviews  num_quizzes  num_lectures  num_curriculum_items  \\\n",
       "0  4.513425       176950           39           468                   507   \n",
       "\n",
       "               requirements_data          what_you_will_learn_data  \\\n",
       "0  high school mathematics level  master machine learning python r   \n",
       "\n",
       "              target_audiences  estimated_content_length      content_info  \\\n",
       "0  interested machine learning                      2559  42.5 total hours   \n",
       "\n",
       "  instructional_level                        objectives  \\\n",
       "0          All Levels  master machine learning python r   \n",
       "\n",
       "                                    full_description  \\\n",
       "0  p interested field machine learning nbsp cours...   \n",
       "\n",
       "                                       skills_tagged   price  course_title  \\\n",
       "0  {multiple linear regression, data science, dee...  109.99  data science   \n",
       "\n",
       "                                  course_url course_display_name  overlap  \\\n",
       "0  https://www.udemy.com/topic/data-science/        data science        0   \n",
       "\n",
       "   coverage  course_score  \n",
       "0       0.0    995.712713  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 {'deep learning', 'algorithms', 'deep learning methods', 'python', 'analytics', 'autoencoders', 'dataset', 'probability', 'artificial intelligence', 'amazon', 'convolutional neural networks', 'artificial neural networks'}\n",
      "13 {'big data', 'apache', 'mapreduce', 'cloud computing', 'apache spark', 'sql', 'dataset', 'data analysis', 'amazon', 'python'}\n",
      "18 {'computer science', 'data science', 'algorithms', 'big data', 'machine learning algorithms', 'data analysis', 'artificial intelligence', 'python', 'data mining'}\n",
      "40 {'deep learning', 'data science', 'algorithms', 'python', 'machine learning algorithms', 'resnet', 'dataset', 'convolutional neural networks'}\n",
      "43 {'deep learning', 'data science', 'sentiment analysis', 'algorithms', 'data preprocessing', 'dataset', 'probability', 'python'}\n",
      "50 {'jupyter notebook', 'airflow', 'continuous integration', 'ci cd', 'python'}\n",
      "4 {'deep learning', 'algorithms', 'deep learning methods', 'python', 'analytics', 'autoencoders', 'dataset', 'probability', 'artificial intelligence', 'amazon', 'convolutional neural networks', 'artificial neural networks'}\n",
      "13 {'big data', 'apache', 'mapreduce', 'cloud computing', 'apache spark', 'sql', 'dataset', 'data analysis', 'amazon', 'python'}\n",
      "18 {'computer science', 'data science', 'algorithms', 'big data', 'machine learning algorithms', 'data analysis', 'artificial intelligence', 'python', 'data mining'}\n"
     ]
    }
   ],
   "source": [
    "for k,row in df_c_cleaned[df_c_cleaned[\"overlap\"]==1].iterrows():\n",
    "    print(k,row[\"skills_tagged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cloud infrastructure',\n",
       " 'computer science',\n",
       " 'devops',\n",
       " 'data governance',\n",
       " 'data acquisition',\n",
       " 'java',\n",
       " 'dataset',\n",
       " 'ci cd']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>headline</th>\n",
       "      <th>num_subscribers</th>\n",
       "      <th>rating</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>num_quizzes</th>\n",
       "      <th>num_lectures</th>\n",
       "      <th>num_curriculum_items</th>\n",
       "      <th>requirements_data</th>\n",
       "      <th>what_you_will_learn_data</th>\n",
       "      <th>target_audiences</th>\n",
       "      <th>estimated_content_length</th>\n",
       "      <th>content_info</th>\n",
       "      <th>instructional_level</th>\n",
       "      <th>objectives</th>\n",
       "      <th>full_description</th>\n",
       "      <th>skills_tagged</th>\n",
       "      <th>price</th>\n",
       "      <th>course_title</th>\n",
       "      <th>course_url</th>\n",
       "      <th>course_display_name</th>\n",
       "      <th>overlap</th>\n",
       "      <th>coverage</th>\n",
       "      <th>course_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>machine learning z ai python r chatgpt bonus</td>\n",
       "      <td>https://www.udemy.com/course/machinelearning/</td>\n",
       "      <td>p interested field machine learning nbsp cours...</td>\n",
       "      <td>learn create machine learning algorithms pytho...</td>\n",
       "      <td>993456</td>\n",
       "      <td>4.513425</td>\n",
       "      <td>176950</td>\n",
       "      <td>39</td>\n",
       "      <td>468</td>\n",
       "      <td>507</td>\n",
       "      <td>high school mathematics level</td>\n",
       "      <td>master machine learning python r</td>\n",
       "      <td>interested machine learning</td>\n",
       "      <td>2559</td>\n",
       "      <td>42.5 total hours</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>master machine learning python r</td>\n",
       "      <td>p interested field machine learning nbsp cours...</td>\n",
       "      <td>{multiple linear regression, data science, dee...</td>\n",
       "      <td>109.99</td>\n",
       "      <td>data science</td>\n",
       "      <td>https://www.udemy.com/topic/data-science/</td>\n",
       "      <td>data science</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>995.712713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>python data science machine learning bootcamp</td>\n",
       "      <td>https://www.udemy.com/course/python-for-data-s...</td>\n",
       "      <td>p ready start path data scientist p p comprehe...</td>\n",
       "      <td>learn use numpy pandas seaborn matplotlib plot...</td>\n",
       "      <td>674125</td>\n",
       "      <td>4.588927</td>\n",
       "      <td>136746</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>programming experience</td>\n",
       "      <td>use python data science machine learning</td>\n",
       "      <td>course meant people programming experience</td>\n",
       "      <td>1494</td>\n",
       "      <td>25 total hours</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>use python data science machine learning</td>\n",
       "      <td>p ready start path data scientist p p comprehe...</td>\n",
       "      <td>{data science, deep learning, big data, machin...</td>\n",
       "      <td>99.99</td>\n",
       "      <td>data science</td>\n",
       "      <td>https://www.udemy.com/topic/data-science/</td>\n",
       "      <td>data science</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>676.419464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data science course complete data science boot...</td>\n",
       "      <td>https://www.udemy.com/course/the-data-science-...</td>\n",
       "      <td>p strong problem strong p p data scientist bes...</td>\n",
       "      <td>complete data science training mathematics sta...</td>\n",
       "      <td>634583</td>\n",
       "      <td>4.594564</td>\n",
       "      <td>131509</td>\n",
       "      <td>281</td>\n",
       "      <td>518</td>\n",
       "      <td>799</td>\n",
       "      <td>prior experience required start basics</td>\n",
       "      <td>course provides entire toolbox need data scien...</td>\n",
       "      <td>course want data scientist want learn field</td>\n",
       "      <td>1906</td>\n",
       "      <td>32 total hours</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>course provides entire toolbox need data scien...</td>\n",
       "      <td>p strong problem strong p p data scientist bes...</td>\n",
       "      <td>{python programming language, statistical anal...</td>\n",
       "      <td>109.99</td>\n",
       "      <td>data science</td>\n",
       "      <td>https://www.udemy.com/topic/data-science/</td>\n",
       "      <td>data science</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>636.880282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r programming z r data science real exercises</td>\n",
       "      <td>https://www.udemy.com/course/r-programming/</td>\n",
       "      <td>p learn r programming p p lots r courses lectu...</td>\n",
       "      <td>learn programming r r studio data analytics da...</td>\n",
       "      <td>261248</td>\n",
       "      <td>4.662838</td>\n",
       "      <td>51993</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>94</td>\n",
       "      <td>prior knowledge experience needed passion succ...</td>\n",
       "      <td>learn program r good level</td>\n",
       "      <td>course want learn program r</td>\n",
       "      <td>638</td>\n",
       "      <td>10.5 total hours</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>learn program r good level</td>\n",
       "      <td>p learn r programming p p lots r courses lectu...</td>\n",
       "      <td>{statistical}</td>\n",
       "      <td>94.99</td>\n",
       "      <td>data mining</td>\n",
       "      <td>https://www.udemy.com/topic/data-mining/</td>\n",
       "      <td>data mining</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>263.579419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deep learning z neural networks ai chatgpt bonus</td>\n",
       "      <td>https://www.udemy.com/course/deeplearning/</td>\n",
       "      <td>p seen kickstarter p p artificial intelligence...</td>\n",
       "      <td>learn create deep learning algorithms python m...</td>\n",
       "      <td>366900</td>\n",
       "      <td>4.501419</td>\n",
       "      <td>44403</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>230</td>\n",
       "      <td>high school mathematics level</td>\n",
       "      <td>understand intuition artificial neural networks</td>\n",
       "      <td>interested deep learning</td>\n",
       "      <td>1367</td>\n",
       "      <td>23 total hours</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>understand intuition artificial neural networks</td>\n",
       "      <td>p seen kickstarter p p artificial intelligence...</td>\n",
       "      <td>{deep learning, algorithms, deep learning meth...</td>\n",
       "      <td>99.99</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>https://www.udemy.com/topic/deep-learning/</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>369.275710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>deep learning computer vision z ai chatgpt bon...</td>\n",
       "      <td>https://www.udemy.com/course/computer-vision-a-z/</td>\n",
       "      <td>p definitely heard ai deep learning ask positi...</td>\n",
       "      <td>wizard latest computer vision tools exist dete...</td>\n",
       "      <td>47716</td>\n",
       "      <td>4.196091</td>\n",
       "      <td>6515</td>\n",
       "      <td>6</td>\n",
       "      <td>95</td>\n",
       "      <td>101</td>\n",
       "      <td>high school maths</td>\n",
       "      <td>toolbox powerful computer vision models</td>\n",
       "      <td>interested computer vision artificial intellig...</td>\n",
       "      <td>668</td>\n",
       "      <td>11 total hours</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>toolbox powerful computer vision models</td>\n",
       "      <td>p definitely heard ai deep learning ask positi...</td>\n",
       "      <td>{artificial intelligence, deep learning}</td>\n",
       "      <td>84.99</td>\n",
       "      <td>artificial intelligence</td>\n",
       "      <td>https://www.udemy.com/topic/artificial-intelli...</td>\n",
       "      <td>artificial intelligence</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>49.814045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>probability statistics business data science</td>\n",
       "      <td>https://www.udemy.com/course/probability-and-s...</td>\n",
       "      <td>p welcome probability statistics business data...</td>\n",
       "      <td>learn apply probability statistics real data s...</td>\n",
       "      <td>33842</td>\n",
       "      <td>4.670479</td>\n",
       "      <td>6475</td>\n",
       "      <td>17</td>\n",
       "      <td>53</td>\n",
       "      <td>70</td>\n",
       "      <td>paper pencil notes</td>\n",
       "      <td>understand basics probability</td>\n",
       "      <td>interested learning apply probability statisti...</td>\n",
       "      <td>314</td>\n",
       "      <td>5 total hours</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>understand basics probability</td>\n",
       "      <td>p welcome probability statistics business data...</td>\n",
       "      <td>{data science, probability statistics, statist...</td>\n",
       "      <td>94.99</td>\n",
       "      <td>math</td>\n",
       "      <td>https://www.udemy.com/topic/math/</td>\n",
       "      <td>math</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>36.177239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>deep learning advanced natural language proces...</td>\n",
       "      <td>https://www.udemy.com/course/deep-learning-adv...</td>\n",
       "      <td>p hard believe year released course strong dee...</td>\n",
       "      <td>natural language processing nlp sequence seque...</td>\n",
       "      <td>32639</td>\n",
       "      <td>4.625027</td>\n",
       "      <td>6292</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>understand deep learning</td>\n",
       "      <td>build text classification system spam detectio...</td>\n",
       "      <td>students machine learning deep learning artifi...</td>\n",
       "      <td>496</td>\n",
       "      <td>8.5 total hours</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>build text classification system spam detectio...</td>\n",
       "      <td>p hard believe year released course strong dee...</td>\n",
       "      <td>{deep learning, data science, algorithms, sent...</td>\n",
       "      <td>109.99</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>https://www.udemy.com/topic/deep-learning/</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>34.951513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>deep learning prerequisites linear regression ...</td>\n",
       "      <td>https://www.udemy.com/course/data-science-line...</td>\n",
       "      <td>p course teaches popular technique strong mach...</td>\n",
       "      <td>data science machine learning artificial intel...</td>\n",
       "      <td>33210</td>\n",
       "      <td>4.644806</td>\n",
       "      <td>6181</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>61</td>\n",
       "      <td>derivative calculus</td>\n",
       "      <td>derive solve linear regression model apply app...</td>\n",
       "      <td>people interested data science machine learnin...</td>\n",
       "      <td>380</td>\n",
       "      <td>6.5 total hours</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>derive solve linear regression model apply app...</td>\n",
       "      <td>p course teaches popular technique strong mach...</td>\n",
       "      <td>{calculus, data science, deep learning, machin...</td>\n",
       "      <td>119.99</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>https://www.udemy.com/topic/deep-learning/</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>35.532403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>intro data science quickstart guide ai chatgpt...</td>\n",
       "      <td>https://www.udemy.com/course/intro-to-data-sci...</td>\n",
       "      <td>p demand data scientists immense course learn ...</td>\n",
       "      <td>learn critical elements data science visualiza...</td>\n",
       "      <td>23341</td>\n",
       "      <td>4.544537</td>\n",
       "      <td>5923</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>passion build successful data science career</td>\n",
       "      <td>entire data science process</td>\n",
       "      <td>generally interested data science</td>\n",
       "      <td>316</td>\n",
       "      <td>5.5 total hours</td>\n",
       "      <td>Beginner Level</td>\n",
       "      <td>entire data science process</td>\n",
       "      <td>p demand data scientists immense course learn ...</td>\n",
       "      <td>{data science, machine learning algorithms, st...</td>\n",
       "      <td>69.99</td>\n",
       "      <td>data science</td>\n",
       "      <td>https://www.udemy.com/topic/data-science/</td>\n",
       "      <td>data science</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25.613269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0        machine learning z ai python r chatgpt bonus   \n",
       "1       python data science machine learning bootcamp   \n",
       "2   data science course complete data science boot...   \n",
       "3       r programming z r data science real exercises   \n",
       "4    deep learning z neural networks ai chatgpt bonus   \n",
       "..                                                ...   \n",
       "35  deep learning computer vision z ai chatgpt bon...   \n",
       "36       probability statistics business data science   \n",
       "37  deep learning advanced natural language proces...   \n",
       "38  deep learning prerequisites linear regression ...   \n",
       "39  intro data science quickstart guide ai chatgpt...   \n",
       "\n",
       "                                                  url  \\\n",
       "0       https://www.udemy.com/course/machinelearning/   \n",
       "1   https://www.udemy.com/course/python-for-data-s...   \n",
       "2   https://www.udemy.com/course/the-data-science-...   \n",
       "3         https://www.udemy.com/course/r-programming/   \n",
       "4          https://www.udemy.com/course/deeplearning/   \n",
       "..                                                ...   \n",
       "35  https://www.udemy.com/course/computer-vision-a-z/   \n",
       "36  https://www.udemy.com/course/probability-and-s...   \n",
       "37  https://www.udemy.com/course/deep-learning-adv...   \n",
       "38  https://www.udemy.com/course/data-science-line...   \n",
       "39  https://www.udemy.com/course/intro-to-data-sci...   \n",
       "\n",
       "                                          description  \\\n",
       "0   p interested field machine learning nbsp cours...   \n",
       "1   p ready start path data scientist p p comprehe...   \n",
       "2   p strong problem strong p p data scientist bes...   \n",
       "3   p learn r programming p p lots r courses lectu...   \n",
       "4   p seen kickstarter p p artificial intelligence...   \n",
       "..                                                ...   \n",
       "35  p definitely heard ai deep learning ask positi...   \n",
       "36  p welcome probability statistics business data...   \n",
       "37  p hard believe year released course strong dee...   \n",
       "38  p course teaches popular technique strong mach...   \n",
       "39  p demand data scientists immense course learn ...   \n",
       "\n",
       "                                             headline  num_subscribers  \\\n",
       "0   learn create machine learning algorithms pytho...           993456   \n",
       "1   learn use numpy pandas seaborn matplotlib plot...           674125   \n",
       "2   complete data science training mathematics sta...           634583   \n",
       "3   learn programming r r studio data analytics da...           261248   \n",
       "4   learn create deep learning algorithms python m...           366900   \n",
       "..                                                ...              ...   \n",
       "35  wizard latest computer vision tools exist dete...            47716   \n",
       "36  learn apply probability statistics real data s...            33842   \n",
       "37  natural language processing nlp sequence seque...            32639   \n",
       "38  data science machine learning artificial intel...            33210   \n",
       "39  learn critical elements data science visualiza...            23341   \n",
       "\n",
       "      rating  num_reviews  num_quizzes  num_lectures  num_curriculum_items  \\\n",
       "0   4.513425       176950           39           468                   507   \n",
       "1   4.588927       136746            1           184                   185   \n",
       "2   4.594564       131509          281           518                   799   \n",
       "3   4.662838        51993            5            89                    94   \n",
       "4   4.501419        44403            0           230                   230   \n",
       "..       ...          ...          ...           ...                   ...   \n",
       "35  4.196091         6515            6            95                   101   \n",
       "36  4.670479         6475           17            53                    70   \n",
       "37  4.625027         6292            0            67                    67   \n",
       "38  4.644806         6181            4            57                    61   \n",
       "39  4.544537         5923            0            48                    48   \n",
       "\n",
       "                                    requirements_data  \\\n",
       "0                       high school mathematics level   \n",
       "1                              programming experience   \n",
       "2              prior experience required start basics   \n",
       "3   prior knowledge experience needed passion succ...   \n",
       "4                       high school mathematics level   \n",
       "..                                                ...   \n",
       "35                                  high school maths   \n",
       "36                                 paper pencil notes   \n",
       "37                           understand deep learning   \n",
       "38                                derivative calculus   \n",
       "39       passion build successful data science career   \n",
       "\n",
       "                             what_you_will_learn_data  \\\n",
       "0                    master machine learning python r   \n",
       "1            use python data science machine learning   \n",
       "2   course provides entire toolbox need data scien...   \n",
       "3                          learn program r good level   \n",
       "4     understand intuition artificial neural networks   \n",
       "..                                                ...   \n",
       "35            toolbox powerful computer vision models   \n",
       "36                      understand basics probability   \n",
       "37  build text classification system spam detectio...   \n",
       "38  derive solve linear regression model apply app...   \n",
       "39                        entire data science process   \n",
       "\n",
       "                                     target_audiences  \\\n",
       "0                         interested machine learning   \n",
       "1          course meant people programming experience   \n",
       "2         course want data scientist want learn field   \n",
       "3                         course want learn program r   \n",
       "4                            interested deep learning   \n",
       "..                                                ...   \n",
       "35  interested computer vision artificial intellig...   \n",
       "36  interested learning apply probability statisti...   \n",
       "37  students machine learning deep learning artifi...   \n",
       "38  people interested data science machine learnin...   \n",
       "39                  generally interested data science   \n",
       "\n",
       "    estimated_content_length      content_info instructional_level  \\\n",
       "0                       2559  42.5 total hours          All Levels   \n",
       "1                       1494    25 total hours          All Levels   \n",
       "2                       1906    32 total hours          All Levels   \n",
       "3                        638  10.5 total hours          All Levels   \n",
       "4                       1367    23 total hours          All Levels   \n",
       "..                       ...               ...                 ...   \n",
       "35                       668    11 total hours          All Levels   \n",
       "36                       314     5 total hours          All Levels   \n",
       "37                       496   8.5 total hours          All Levels   \n",
       "38                       380   6.5 total hours          All Levels   \n",
       "39                       316   5.5 total hours      Beginner Level   \n",
       "\n",
       "                                           objectives  \\\n",
       "0                    master machine learning python r   \n",
       "1            use python data science machine learning   \n",
       "2   course provides entire toolbox need data scien...   \n",
       "3                          learn program r good level   \n",
       "4     understand intuition artificial neural networks   \n",
       "..                                                ...   \n",
       "35            toolbox powerful computer vision models   \n",
       "36                      understand basics probability   \n",
       "37  build text classification system spam detectio...   \n",
       "38  derive solve linear regression model apply app...   \n",
       "39                        entire data science process   \n",
       "\n",
       "                                     full_description  \\\n",
       "0   p interested field machine learning nbsp cours...   \n",
       "1   p ready start path data scientist p p comprehe...   \n",
       "2   p strong problem strong p p data scientist bes...   \n",
       "3   p learn r programming p p lots r courses lectu...   \n",
       "4   p seen kickstarter p p artificial intelligence...   \n",
       "..                                                ...   \n",
       "35  p definitely heard ai deep learning ask positi...   \n",
       "36  p welcome probability statistics business data...   \n",
       "37  p hard believe year released course strong dee...   \n",
       "38  p course teaches popular technique strong mach...   \n",
       "39  p demand data scientists immense course learn ...   \n",
       "\n",
       "                                        skills_tagged   price  \\\n",
       "0   {multiple linear regression, data science, dee...  109.99   \n",
       "1   {data science, deep learning, big data, machin...   99.99   \n",
       "2   {python programming language, statistical anal...  109.99   \n",
       "3                                       {statistical}   94.99   \n",
       "4   {deep learning, algorithms, deep learning meth...   99.99   \n",
       "..                                                ...     ...   \n",
       "35           {artificial intelligence, deep learning}   84.99   \n",
       "36  {data science, probability statistics, statist...   94.99   \n",
       "37  {deep learning, data science, algorithms, sent...  109.99   \n",
       "38  {calculus, data science, deep learning, machin...  119.99   \n",
       "39  {data science, machine learning algorithms, st...   69.99   \n",
       "\n",
       "               course_title  \\\n",
       "0              data science   \n",
       "1              data science   \n",
       "2              data science   \n",
       "3               data mining   \n",
       "4             deep learning   \n",
       "..                      ...   \n",
       "35  artificial intelligence   \n",
       "36                     math   \n",
       "37            deep learning   \n",
       "38            deep learning   \n",
       "39             data science   \n",
       "\n",
       "                                           course_url  \\\n",
       "0           https://www.udemy.com/topic/data-science/   \n",
       "1           https://www.udemy.com/topic/data-science/   \n",
       "2           https://www.udemy.com/topic/data-science/   \n",
       "3            https://www.udemy.com/topic/data-mining/   \n",
       "4          https://www.udemy.com/topic/deep-learning/   \n",
       "..                                                ...   \n",
       "35  https://www.udemy.com/topic/artificial-intelli...   \n",
       "36                  https://www.udemy.com/topic/math/   \n",
       "37         https://www.udemy.com/topic/deep-learning/   \n",
       "38         https://www.udemy.com/topic/deep-learning/   \n",
       "39          https://www.udemy.com/topic/data-science/   \n",
       "\n",
       "        course_display_name  overlap  coverage  course_score  \n",
       "0              data science        0     0.000    995.712713  \n",
       "1              data science        0     0.000    676.419464  \n",
       "2              data science        0     0.000    636.880282  \n",
       "3               data mining        0     0.000    263.579419  \n",
       "4             deep learning        1     0.125    369.275710  \n",
       "..                      ...      ...       ...           ...  \n",
       "35  artificial intelligence        0     0.000     49.814045  \n",
       "36                     math        0     0.000     36.177239  \n",
       "37            deep learning        0     0.000     34.951513  \n",
       "38            deep learning        0     0.000     35.532403  \n",
       "39             data science        0     0.000     25.613269  \n",
       "\n",
       "[100 rows x 26 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>headline</th>\n",
       "      <th>num_subscribers</th>\n",
       "      <th>rating</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>num_quizzes</th>\n",
       "      <th>num_lectures</th>\n",
       "      <th>num_curriculum_items</th>\n",
       "      <th>requirements_data</th>\n",
       "      <th>what_you_will_learn_data</th>\n",
       "      <th>target_audiences</th>\n",
       "      <th>estimated_content_length</th>\n",
       "      <th>content_info</th>\n",
       "      <th>instructional_level</th>\n",
       "      <th>objectives</th>\n",
       "      <th>full_description</th>\n",
       "      <th>skills_tagged</th>\n",
       "      <th>price</th>\n",
       "      <th>course_title</th>\n",
       "      <th>course_url</th>\n",
       "      <th>course_display_name</th>\n",
       "      <th>overlap</th>\n",
       "      <th>coverage</th>\n",
       "      <th>course_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deep learning z neural networks ai chatgpt bonus</td>\n",
       "      <td>https://www.udemy.com/course/deeplearning/</td>\n",
       "      <td>p seen kickstarter p p artificial intelligence...</td>\n",
       "      <td>learn create deep learning algorithms python m...</td>\n",
       "      <td>366900</td>\n",
       "      <td>4.501419</td>\n",
       "      <td>44403</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>230</td>\n",
       "      <td>high school mathematics level</td>\n",
       "      <td>understand intuition artificial neural networks</td>\n",
       "      <td>interested deep learning</td>\n",
       "      <td>1367</td>\n",
       "      <td>23 total hours</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>understand intuition artificial neural networks</td>\n",
       "      <td>p seen kickstarter p p artificial intelligence...</td>\n",
       "      <td>{deep learning, algorithms, deep learning meth...</td>\n",
       "      <td>99.99</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>https://www.udemy.com/topic/deep-learning/</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>369.275710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>apache spark scala hands big data</td>\n",
       "      <td>https://www.udemy.com/course/apache-spark-with...</td>\n",
       "      <td>p strong new completely updated recorded spark...</td>\n",
       "      <td>apache spark tutorial hands examples analyzing...</td>\n",
       "      <td>94162</td>\n",
       "      <td>4.632853</td>\n",
       "      <td>17262</td>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "      <td>79</td>\n",
       "      <td>prior programming scripting experience require...</td>\n",
       "      <td>develop distributed code scala programming lan...</td>\n",
       "      <td>software engineers want expand skills world bi...</td>\n",
       "      <td>538</td>\n",
       "      <td>9 total hours</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>develop distributed code scala programming lan...</td>\n",
       "      <td>p strong new completely updated recorded spark...</td>\n",
       "      <td>{big data, apache, mapreduce, cloud computing,...</td>\n",
       "      <td>94.99</td>\n",
       "      <td>apache spark</td>\n",
       "      <td>https://www.udemy.com/topic/apache-spark/</td>\n",
       "      <td>apache spark</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>96.603427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>introduction machine learning data science</td>\n",
       "      <td>https://www.udemy.com/course/machine-learning-...</td>\n",
       "      <td>p strong course recently updated nov strong p ...</td>\n",
       "      <td>primer machine learning data science revealed ...</td>\n",
       "      <td>62512</td>\n",
       "      <td>4.555354</td>\n",
       "      <td>13772</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>67</td>\n",
       "      <td>passion learn basic computer skills</td>\n",
       "      <td>genuinely understand computer science algorith...</td>\n",
       "      <td>load python start r need course introductory c...</td>\n",
       "      <td>333</td>\n",
       "      <td>5.5 total hours</td>\n",
       "      <td>Beginner Level</td>\n",
       "      <td>genuinely understand computer science algorith...</td>\n",
       "      <td>p strong course recently updated nov strong p ...</td>\n",
       "      <td>{computer science, data science, algorithms, b...</td>\n",
       "      <td>84.99</td>\n",
       "      <td>data science</td>\n",
       "      <td>https://www.udemy.com/topic/data-science/</td>\n",
       "      <td>data science</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>64.914677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>deep learning advanced computer vision gans ssd</td>\n",
       "      <td>https://www.udemy.com/course/advanced-computer...</td>\n",
       "      <td>p strong latest update strong instead ssd use ...</td>\n",
       "      <td>vgg resnet inception ssd retinanet neural styl...</td>\n",
       "      <td>36728</td>\n",
       "      <td>4.729925</td>\n",
       "      <td>5620</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>know build train use cnn library preferably py...</td>\n",
       "      <td>understand apply transfer learning</td>\n",
       "      <td>students professionals want knowledge computer...</td>\n",
       "      <td>941</td>\n",
       "      <td>15.5 total hours</td>\n",
       "      <td>Intermediate Level</td>\n",
       "      <td>understand apply transfer learning</td>\n",
       "      <td>p strong latest update strong instead ssd use ...</td>\n",
       "      <td>{deep learning, data science, algorithms, pyth...</td>\n",
       "      <td>119.99</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>https://www.udemy.com/topic/deep-learning/</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>39.217962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>deep learning convolutional neural networks py...</td>\n",
       "      <td>https://www.udemy.com/course/deep-learning-con...</td>\n",
       "      <td>p nbsp nbsp nbsp tensorflow python nbsp p p le...</td>\n",
       "      <td>tensorflow cnns computer vision natural langua...</td>\n",
       "      <td>37527</td>\n",
       "      <td>4.714412</td>\n",
       "      <td>5406</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>basic math taking derivatives matrix arithmeti...</td>\n",
       "      <td>understand convolution useful deep learning</td>\n",
       "      <td>students professionals interested deep learnin...</td>\n",
       "      <td>804</td>\n",
       "      <td>13.5 total hours</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>understand convolution useful deep learning</td>\n",
       "      <td>p nbsp nbsp nbsp tensorflow python nbsp p p le...</td>\n",
       "      <td>{deep learning, data science, sentiment analys...</td>\n",
       "      <td>109.99</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>https://www.udemy.com/topic/deep-learning/</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>40.009206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>deployment machine learning models</td>\n",
       "      <td>https://www.udemy.com/course/deployment-of-mac...</td>\n",
       "      <td>p welcome deployment machine learning models s...</td>\n",
       "      <td>learn integrate robust reliable machine learni...</td>\n",
       "      <td>33224</td>\n",
       "      <td>4.372408</td>\n",
       "      <td>4992</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>224</td>\n",
       "      <td>python installation</td>\n",
       "      <td>build machine learning model apis deploy model...</td>\n",
       "      <td>data scientists want deploy machine learning m...</td>\n",
       "      <td>627</td>\n",
       "      <td>10.5 total hours</td>\n",
       "      <td>Intermediate Level</td>\n",
       "      <td>build machine learning model apis deploy model...</td>\n",
       "      <td>p welcome deployment machine learning models s...</td>\n",
       "      <td>{jupyter notebook, airflow, continuous integra...</td>\n",
       "      <td>119.99</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>https://www.udemy.com/topic/machine-learning/</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>35.535204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deep learning z neural networks ai chatgpt bonus</td>\n",
       "      <td>https://www.udemy.com/course/deeplearning/</td>\n",
       "      <td>p seen kickstarter p p artificial intelligence...</td>\n",
       "      <td>learn create deep learning algorithms python m...</td>\n",
       "      <td>366900</td>\n",
       "      <td>4.501419</td>\n",
       "      <td>44403</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>230</td>\n",
       "      <td>high school mathematics level</td>\n",
       "      <td>understand intuition artificial neural networks</td>\n",
       "      <td>interested deep learning</td>\n",
       "      <td>1367</td>\n",
       "      <td>23 total hours</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>understand intuition artificial neural networks</td>\n",
       "      <td>p seen kickstarter p p artificial intelligence...</td>\n",
       "      <td>{deep learning, algorithms, deep learning meth...</td>\n",
       "      <td>94.99</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>https://www.udemy.com/topic/deep-learning/</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>369.275710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>apache spark scala hands big data</td>\n",
       "      <td>https://www.udemy.com/course/apache-spark-with...</td>\n",
       "      <td>p strong new completely updated recorded spark...</td>\n",
       "      <td>apache spark tutorial hands examples analyzing...</td>\n",
       "      <td>94162</td>\n",
       "      <td>4.632853</td>\n",
       "      <td>17262</td>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "      <td>79</td>\n",
       "      <td>prior programming scripting experience require...</td>\n",
       "      <td>develop distributed code scala programming lan...</td>\n",
       "      <td>software engineers want expand skills world bi...</td>\n",
       "      <td>538</td>\n",
       "      <td>9 total hours</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>develop distributed code scala programming lan...</td>\n",
       "      <td>p strong new completely updated recorded spark...</td>\n",
       "      <td>{big data, apache, mapreduce, cloud computing,...</td>\n",
       "      <td>94.99</td>\n",
       "      <td>apache spark</td>\n",
       "      <td>https://www.udemy.com/topic/apache-spark/</td>\n",
       "      <td>apache spark</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>96.603427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>introduction machine learning data science</td>\n",
       "      <td>https://www.udemy.com/course/machine-learning-...</td>\n",
       "      <td>p strong course recently updated nov strong p ...</td>\n",
       "      <td>primer machine learning data science revealed ...</td>\n",
       "      <td>62512</td>\n",
       "      <td>4.555354</td>\n",
       "      <td>13772</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>67</td>\n",
       "      <td>passion learn basic computer skills</td>\n",
       "      <td>genuinely understand computer science algorith...</td>\n",
       "      <td>load python start r need course introductory c...</td>\n",
       "      <td>333</td>\n",
       "      <td>5.5 total hours</td>\n",
       "      <td>Beginner Level</td>\n",
       "      <td>genuinely understand computer science algorith...</td>\n",
       "      <td>p strong course recently updated nov strong p ...</td>\n",
       "      <td>{computer science, data science, algorithms, b...</td>\n",
       "      <td>74.99</td>\n",
       "      <td>data science</td>\n",
       "      <td>https://www.udemy.com/topic/data-science/</td>\n",
       "      <td>data science</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>64.914677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "4    deep learning z neural networks ai chatgpt bonus   \n",
       "13                  apache spark scala hands big data   \n",
       "18         introduction machine learning data science   \n",
       "40    deep learning advanced computer vision gans ssd   \n",
       "43  deep learning convolutional neural networks py...   \n",
       "50                 deployment machine learning models   \n",
       "4    deep learning z neural networks ai chatgpt bonus   \n",
       "13                  apache spark scala hands big data   \n",
       "18         introduction machine learning data science   \n",
       "\n",
       "                                                  url  \\\n",
       "4          https://www.udemy.com/course/deeplearning/   \n",
       "13  https://www.udemy.com/course/apache-spark-with...   \n",
       "18  https://www.udemy.com/course/machine-learning-...   \n",
       "40  https://www.udemy.com/course/advanced-computer...   \n",
       "43  https://www.udemy.com/course/deep-learning-con...   \n",
       "50  https://www.udemy.com/course/deployment-of-mac...   \n",
       "4          https://www.udemy.com/course/deeplearning/   \n",
       "13  https://www.udemy.com/course/apache-spark-with...   \n",
       "18  https://www.udemy.com/course/machine-learning-...   \n",
       "\n",
       "                                          description  \\\n",
       "4   p seen kickstarter p p artificial intelligence...   \n",
       "13  p strong new completely updated recorded spark...   \n",
       "18  p strong course recently updated nov strong p ...   \n",
       "40  p strong latest update strong instead ssd use ...   \n",
       "43  p nbsp nbsp nbsp tensorflow python nbsp p p le...   \n",
       "50  p welcome deployment machine learning models s...   \n",
       "4   p seen kickstarter p p artificial intelligence...   \n",
       "13  p strong new completely updated recorded spark...   \n",
       "18  p strong course recently updated nov strong p ...   \n",
       "\n",
       "                                             headline  num_subscribers  \\\n",
       "4   learn create deep learning algorithms python m...           366900   \n",
       "13  apache spark tutorial hands examples analyzing...            94162   \n",
       "18  primer machine learning data science revealed ...            62512   \n",
       "40  vgg resnet inception ssd retinanet neural styl...            36728   \n",
       "43  tensorflow cnns computer vision natural langua...            37527   \n",
       "50  learn integrate robust reliable machine learni...            33224   \n",
       "4   learn create deep learning algorithms python m...           366900   \n",
       "13  apache spark tutorial hands examples analyzing...            94162   \n",
       "18  primer machine learning data science revealed ...            62512   \n",
       "\n",
       "      rating  num_reviews  num_quizzes  num_lectures  num_curriculum_items  \\\n",
       "4   4.501419        44403            0           230                   230   \n",
       "13  4.632853        17262            6            73                    79   \n",
       "18  4.555354        13772            3            64                    67   \n",
       "40  4.729925         5620            0           140                   140   \n",
       "43  4.714412         5406            0           117                   117   \n",
       "50  4.372408         4992            1           219                   224   \n",
       "4   4.501419        44403            0           230                   230   \n",
       "13  4.632853        17262            6            73                    79   \n",
       "18  4.555354        13772            3            64                    67   \n",
       "\n",
       "                                    requirements_data  \\\n",
       "4                       high school mathematics level   \n",
       "13  prior programming scripting experience require...   \n",
       "18                passion learn basic computer skills   \n",
       "40  know build train use cnn library preferably py...   \n",
       "43  basic math taking derivatives matrix arithmeti...   \n",
       "50                                python installation   \n",
       "4                       high school mathematics level   \n",
       "13  prior programming scripting experience require...   \n",
       "18                passion learn basic computer skills   \n",
       "\n",
       "                             what_you_will_learn_data  \\\n",
       "4     understand intuition artificial neural networks   \n",
       "13  develop distributed code scala programming lan...   \n",
       "18  genuinely understand computer science algorith...   \n",
       "40                 understand apply transfer learning   \n",
       "43        understand convolution useful deep learning   \n",
       "50  build machine learning model apis deploy model...   \n",
       "4     understand intuition artificial neural networks   \n",
       "13  develop distributed code scala programming lan...   \n",
       "18  genuinely understand computer science algorith...   \n",
       "\n",
       "                                     target_audiences  \\\n",
       "4                            interested deep learning   \n",
       "13  software engineers want expand skills world bi...   \n",
       "18  load python start r need course introductory c...   \n",
       "40  students professionals want knowledge computer...   \n",
       "43  students professionals interested deep learnin...   \n",
       "50  data scientists want deploy machine learning m...   \n",
       "4                            interested deep learning   \n",
       "13  software engineers want expand skills world bi...   \n",
       "18  load python start r need course introductory c...   \n",
       "\n",
       "    estimated_content_length      content_info instructional_level  \\\n",
       "4                       1367    23 total hours          All Levels   \n",
       "13                       538     9 total hours          All Levels   \n",
       "18                       333   5.5 total hours      Beginner Level   \n",
       "40                       941  15.5 total hours  Intermediate Level   \n",
       "43                       804  13.5 total hours          All Levels   \n",
       "50                       627  10.5 total hours  Intermediate Level   \n",
       "4                       1367    23 total hours          All Levels   \n",
       "13                       538     9 total hours          All Levels   \n",
       "18                       333   5.5 total hours      Beginner Level   \n",
       "\n",
       "                                           objectives  \\\n",
       "4     understand intuition artificial neural networks   \n",
       "13  develop distributed code scala programming lan...   \n",
       "18  genuinely understand computer science algorith...   \n",
       "40                 understand apply transfer learning   \n",
       "43        understand convolution useful deep learning   \n",
       "50  build machine learning model apis deploy model...   \n",
       "4     understand intuition artificial neural networks   \n",
       "13  develop distributed code scala programming lan...   \n",
       "18  genuinely understand computer science algorith...   \n",
       "\n",
       "                                     full_description  \\\n",
       "4   p seen kickstarter p p artificial intelligence...   \n",
       "13  p strong new completely updated recorded spark...   \n",
       "18  p strong course recently updated nov strong p ...   \n",
       "40  p strong latest update strong instead ssd use ...   \n",
       "43  p nbsp nbsp nbsp tensorflow python nbsp p p le...   \n",
       "50  p welcome deployment machine learning models s...   \n",
       "4   p seen kickstarter p p artificial intelligence...   \n",
       "13  p strong new completely updated recorded spark...   \n",
       "18  p strong course recently updated nov strong p ...   \n",
       "\n",
       "                                        skills_tagged   price  \\\n",
       "4   {deep learning, algorithms, deep learning meth...   99.99   \n",
       "13  {big data, apache, mapreduce, cloud computing,...   94.99   \n",
       "18  {computer science, data science, algorithms, b...   84.99   \n",
       "40  {deep learning, data science, algorithms, pyth...  119.99   \n",
       "43  {deep learning, data science, sentiment analys...  109.99   \n",
       "50  {jupyter notebook, airflow, continuous integra...  119.99   \n",
       "4   {deep learning, algorithms, deep learning meth...   94.99   \n",
       "13  {big data, apache, mapreduce, cloud computing,...   94.99   \n",
       "18  {computer science, data science, algorithms, b...   74.99   \n",
       "\n",
       "        course_title                                     course_url  \\\n",
       "4      deep learning     https://www.udemy.com/topic/deep-learning/   \n",
       "13      apache spark      https://www.udemy.com/topic/apache-spark/   \n",
       "18      data science      https://www.udemy.com/topic/data-science/   \n",
       "40     deep learning     https://www.udemy.com/topic/deep-learning/   \n",
       "43     deep learning     https://www.udemy.com/topic/deep-learning/   \n",
       "50  machine learning  https://www.udemy.com/topic/machine-learning/   \n",
       "4      deep learning     https://www.udemy.com/topic/deep-learning/   \n",
       "13      apache spark      https://www.udemy.com/topic/apache-spark/   \n",
       "18      data science      https://www.udemy.com/topic/data-science/   \n",
       "\n",
       "   course_display_name  overlap  coverage  course_score  \n",
       "4        deep learning        1     0.125    369.275710  \n",
       "13        apache spark        1     0.125     96.603427  \n",
       "18        data science        1     0.125     64.914677  \n",
       "40       deep learning        1     0.125     39.217962  \n",
       "43       deep learning        1     0.125     40.009206  \n",
       "50    machine learning        1     0.125     35.535204  \n",
       "4        deep learning        1     0.125    369.275710  \n",
       "13        apache spark        1     0.125     96.603427  \n",
       "18        data science        1     0.125     64.914677  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c_cleaned[df_c_cleaned[\"overlap\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cloud infrastructure',\n",
       " 'computer science',\n",
       " 'devops',\n",
       " 'data governance',\n",
       " 'data acquisition',\n",
       " 'java',\n",
       " 'dataset',\n",
       " 'ci cd']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AI Architect': ['AI Project Manager', 'Head of AI', 'Chief AI Officer'],\n",
       " 'AI Developer': ['Senior AI Developer',\n",
       "  'AI Architect',\n",
       "  'AI Project Manager',\n",
       "  'Head of AI',\n",
       "  'Chief AI Officer'],\n",
       " 'AI Project Manager': ['Head of AI', 'Chief AI Officer'],\n",
       " 'Big Data Architect': ['Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Big Data Engineer': ['Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Business Analysis Manager': ['Business Intelligence Analyst',\n",
       "  'Director of Business Analysis',\n",
       "  'Chief Strategy Officer',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist'],\n",
       " 'Business Analyst': ['Senior Business Analyst',\n",
       "  'Business Analysis Manager',\n",
       "  'Business Intelligence Analyst',\n",
       "  'Director of Business Analysis',\n",
       "  'Chief Strategy Officer',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist'],\n",
       " 'Business Intelligence Analyst': ['Senior Business Intelligence Analyst',\n",
       "  'Business Intelligence Manager',\n",
       "  'Director of Business Intelligence',\n",
       "  'Vice President of Business Intelligence',\n",
       "  'Chief Intelligence Officer'],\n",
       " 'Business Intelligence Manager': ['Director of Business Intelligence',\n",
       "  'Vice President of Business Intelligence',\n",
       "  'Chief Intelligence Officer'],\n",
       " 'Chief AI Officer': [],\n",
       " 'Chief Data Officer': [],\n",
       " 'Chief Data Scientist': [],\n",
       " 'Chief Information Officer (CIO)': [],\n",
       " 'Chief Intelligence Officer': [],\n",
       " 'Chief Product Officer': ['Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Chief Science Officer': [],\n",
       " 'Chief Strategy Officer': [],\n",
       " 'Chief Technology Officer (CTO)': [],\n",
       " 'Data Analyst': ['Data Engineer',\n",
       "  'Senior Data Engineer',\n",
       "  'Lead Data Engineer',\n",
       "  'Data Architect',\n",
       "  'Senior Data Architect',\n",
       "  'Enterprise Architect',\n",
       "  'Product Analyst',\n",
       "  'Data Product Manager',\n",
       "  'Senior Data Product Manager',\n",
       "  'Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)',\n",
       "  'Machine Learning Engineer'],\n",
       " 'Data Architect': ['Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer'],\n",
       " 'Data Engineer': ['Senior Data Engineer',\n",
       "  'Lead Data Engineer',\n",
       "  'Data Architect',\n",
       "  'Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer'],\n",
       " 'Data Engineering Manager': ['Director of Data Engineering',\n",
       "  'Chief Technology Officer (CTO)'],\n",
       " 'Data Manager': ['Director of Analytics', 'Chief Data Officer'],\n",
       " 'Data Pipeline Architect': ['Data Engineering Manager',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Technology Officer (CTO)'],\n",
       " 'Data Product Manager': ['Senior Data Product Manager',\n",
       "  'Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Data Science Manager': ['Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Data Scientist': ['Senior Data Scientist',\n",
       "  'Lead Data Scientist',\n",
       "  'Principal Data Scientist',\n",
       "  'Data Science Manager',\n",
       "  'Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Database Manager': ['Data Architect',\n",
       "  'Director of Database Management',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Director of Analytics': ['Chief Data Officer'],\n",
       " 'Director of Business Analysis': ['Chief Strategy Officer'],\n",
       " 'Director of Business Intelligence': ['Vice President of Business Intelligence',\n",
       "  'Chief Intelligence Officer'],\n",
       " 'Director of Data Engineering': ['Chief Technology Officer (CTO)'],\n",
       " 'Director of Data Science': ['Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Director of Database Management': ['Chief Information Officer (CIO)'],\n",
       " 'Director of Product Management': ['Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Director of Quantitative Research': [],\n",
       " 'Director of Research': ['Chief Science Officer'],\n",
       " 'Enterprise Architect': ['Product Analyst',\n",
       "  'Data Product Manager',\n",
       "  'Senior Data Product Manager',\n",
       "  'Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Head of AI': ['Chief AI Officer'],\n",
       " 'Head of Big Data': ['Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Head of Machine Learning': ['Chief AI Officer'],\n",
       " 'Junior AI Developer': ['AI Developer',\n",
       "  'Senior AI Developer',\n",
       "  'AI Architect',\n",
       "  'AI Project Manager',\n",
       "  'Head of AI',\n",
       "  'Chief AI Officer',\n",
       "  'Machine Learning Engineer',\n",
       "  'Data Engineer'],\n",
       " 'Junior Business Analyst': ['Business Analyst',\n",
       "  'Senior Business Analyst',\n",
       "  'Business Analysis Manager',\n",
       "  'Business Intelligence Analyst',\n",
       "  'Director of Business Analysis',\n",
       "  'Chief Strategy Officer',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist'],\n",
       " 'Junior DBA': ['Mid-level DBA',\n",
       "  'Senior DBA',\n",
       "  'Database Manager',\n",
       "  'Data Architect',\n",
       "  'Director of Database Management',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Junior Data Analyst': ['Data Analyst',\n",
       "  'Senior Data Analyst',\n",
       "  'Data Engineer',\n",
       "  'Senior Data Engineer',\n",
       "  'Lead Data Engineer',\n",
       "  'Data Architect',\n",
       "  'Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer',\n",
       "  'Business Intelligence Analyst',\n",
       "  'Machine Learning Engineer',\n",
       "  'Big Data Engineer'],\n",
       " 'Junior Data Engineer': ['Data Engineer',\n",
       "  'Senior Data Engineer',\n",
       "  'Data Pipeline Architect',\n",
       "  'Data Engineering Manager',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Technology Officer (CTO)',\n",
       "  'Machine Learning Engineer',\n",
       "  'Big Data Engineer'],\n",
       " 'Junior Data Scientist': ['Data Scientist',\n",
       "  'Senior Data Scientist',\n",
       "  'Lead Data Scientist',\n",
       "  'Principal Data Scientist',\n",
       "  'Data Science Manager',\n",
       "  'Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist',\n",
       "  'Data Engineer',\n",
       "  'AI Developer'],\n",
       " 'Junior Statistician': ['Statistician',\n",
       "  'Senior Statistician',\n",
       "  'Quantitative Analyst',\n",
       "  'Senior Quantitative Analyst',\n",
       "  'Quantitative Research Manager',\n",
       "  'Director of Quantitative Research',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist'],\n",
       " 'Lead Data Engineer': ['Data Architect',\n",
       "  'Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer'],\n",
       " 'Lead Data Scientist': ['Principal Data Scientist',\n",
       "  'Data Science Manager',\n",
       "  'Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Machine Learning Architect': ['Machine Learning Manager',\n",
       "  'Head of Machine Learning',\n",
       "  'Chief AI Officer'],\n",
       " 'Machine Learning Engineer': ['Senior Machine Learning Engineer',\n",
       "  'Machine Learning Architect',\n",
       "  'Machine Learning Manager',\n",
       "  'Head of Machine Learning',\n",
       "  'Chief AI Officer'],\n",
       " 'Machine Learning Manager': ['Head of Machine Learning', 'Chief AI Officer'],\n",
       " 'Mid-level DBA': ['Senior DBA',\n",
       "  'Database Manager',\n",
       "  'Data Architect',\n",
       "  'Director of Database Management',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Principal Data Scientist': ['Data Science Manager',\n",
       "  'Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Principal Scientist': ['Director of Research', 'Chief Science Officer'],\n",
       " 'Product Analyst': ['Data Product Manager',\n",
       "  'Senior Data Product Manager',\n",
       "  'Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Quantitative Analyst': ['Senior Quantitative Analyst',\n",
       "  'Quantitative Research Manager',\n",
       "  'Director of Quantitative Research'],\n",
       " 'Quantitative Research Manager': ['Director of Quantitative Research'],\n",
       " 'Research Analyst': ['Research Scientist',\n",
       "  'Senior Research Scientist',\n",
       "  'Principal Scientist',\n",
       "  'Director of Research',\n",
       "  'Chief Science Officer'],\n",
       " 'Research Assistant': ['Research Analyst',\n",
       "  'Research Scientist',\n",
       "  'Senior Research Scientist',\n",
       "  'Principal Scientist',\n",
       "  'Director of Research',\n",
       "  'Chief Science Officer',\n",
       "  'Data Scientist',\n",
       "  'Statistician'],\n",
       " 'Research Scientist': ['Senior Research Scientist',\n",
       "  'Principal Scientist',\n",
       "  'Director of Research',\n",
       "  'Chief Science Officer'],\n",
       " 'Senior AI Developer': ['AI Architect',\n",
       "  'AI Project Manager',\n",
       "  'Head of AI',\n",
       "  'Chief AI Officer'],\n",
       " 'Senior Big Data Engineer': ['Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Senior Business Analyst': ['Business Analysis Manager',\n",
       "  'Business Intelligence Analyst',\n",
       "  'Director of Business Analysis',\n",
       "  'Chief Strategy Officer',\n",
       "  'Data Analyst',\n",
       "  'Data Scientist'],\n",
       " 'Senior Business Intelligence Analyst': ['Business Intelligence Manager',\n",
       "  'Director of Business Intelligence',\n",
       "  'Vice President of Business Intelligence',\n",
       "  'Chief Intelligence Officer'],\n",
       " 'Senior DBA': ['Database Manager',\n",
       "  'Data Architect',\n",
       "  'Director of Database Management',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Senior Data Analyst': ['Data Engineer',\n",
       "  'Senior Data Engineer',\n",
       "  'Lead Data Engineer',\n",
       "  'Data Architect',\n",
       "  'Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer',\n",
       "  'Machine Learning Engineer',\n",
       "  'Big Data Engineer'],\n",
       " 'Senior Data Architect': ['Enterprise Architect',\n",
       "  'Product Analyst',\n",
       "  'Data Product Manager',\n",
       "  'Senior Data Product Manager',\n",
       "  'Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Senior Data Engineer': ['Lead Data Engineer',\n",
       "  'Data Architect',\n",
       "  'Data Manager',\n",
       "  'Director of Analytics',\n",
       "  'Chief Data Officer'],\n",
       " 'Senior Data Product Manager': ['Director of Product Management',\n",
       "  'Vice President of Product',\n",
       "  'Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)'],\n",
       " 'Senior Data Scientist': ['Lead Data Scientist',\n",
       "  'Principal Data Scientist',\n",
       "  'Data Science Manager',\n",
       "  'Director of Data Science',\n",
       "  'Vice President of Data Science',\n",
       "  'Chief Data Scientist'],\n",
       " 'Senior Machine Learning Engineer': ['Machine Learning Architect',\n",
       "  'Machine Learning Manager',\n",
       "  'Head of Machine Learning',\n",
       "  'Chief AI Officer'],\n",
       " 'Senior Quantitative Analyst': ['Quantitative Research Manager',\n",
       "  'Director of Quantitative Research'],\n",
       " 'Senior Research Scientist': ['Principal Scientist',\n",
       "  'Director of Research',\n",
       "  'Chief Science Officer'],\n",
       " 'Senior Statistician': ['Quantitative Analyst',\n",
       "  'Senior Quantitative Analyst',\n",
       "  'Quantitative Research Manager',\n",
       "  'Director of Quantitative Research'],\n",
       " 'Statistician': ['Senior Statistician',\n",
       "  'Quantitative Analyst',\n",
       "  'Senior Quantitative Analyst',\n",
       "  'Quantitative Research Manager',\n",
       "  'Director of Quantitative Research'],\n",
       " 'Vice President of Business Intelligence': ['Chief Intelligence Officer'],\n",
       " 'Vice President of Data Science': ['Chief Data Scientist'],\n",
       " 'Vice President of Product': ['Chief Product Officer',\n",
       "  'Big Data Engineer',\n",
       "  'Senior Big Data Engineer',\n",
       "  'Big Data Architect',\n",
       "  'Head of Big Data',\n",
       "  'Director of Data Engineering',\n",
       "  'Chief Information Officer (CIO)']}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_full_job_progression_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eval() arg 1 must be a string, bytes or code object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[201], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_c_cleaned[\u001b[39m'\u001b[39;49m\u001b[39mskills_tagged\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39meval\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/sandbox/lib/python3.9/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/anaconda3/envs/sandbox/lib/python3.9/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/envs/sandbox/lib/python3.9/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1175\u001b[0m             values,\n\u001b[1;32m   1176\u001b[0m             f,\n\u001b[1;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/envs/sandbox/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: eval() arg 1 must be a string, bytes or code object"
     ]
    }
   ],
   "source": [
    "df_c_cleaned['skills_tagged'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a spacy model to identify skills \n",
    "# create entities \n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # Load the model\n",
    "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")  # Create the matcher object\n",
    "\n",
    "\n",
    "# Convert the skills list to Doc objects and add them as patterns to the matcher\n",
    "patterns = [nlp.make_doc(skill) for skill in skills_list]\n",
    "matcher.add(\"Skills\", patterns)\n",
    "\n",
    "\n",
    "def get_entities(TRAIN_DATA):\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "        for ent in annotations.get('entities'):\n",
    "            print(ent)\n",
    "\n",
    "TRAIN_DATA = []\n",
    "\n",
    "# Loop through the job descriptions and create training data\n",
    "for job_description in job_descriptions:\n",
    "    # Process the job description to create a Spacy Doc\n",
    "    doc = nlp(job_description)\n",
    "    # Match the patterns to the doc\n",
    "    matches = matcher(doc)\n",
    "    # Create Span objects for the matched sequences\n",
    "    spans = [Span(doc, start, end, label=\"SKILLS\") for match_id, start, end in matches]\n",
    "    # Filter the spans to remove overlaps\n",
    "    #print(spans)\n",
    "    filtered_spans = filter_spans(spans)\n",
    "    #print(spans)\n",
    "    entities = [(span.start_char, span.end_char, span) for span in filtered_spans]\n",
    "    TRAIN_DATA.append((job_description, {\"entities\": entities}))\n",
    "\n",
    "#print(TRAIN_DATA)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train the model\n",
    "\n",
    "#train the model \n",
    "starting_fresh = False\n",
    "# Load a pre-existing spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')  # for example\n",
    "import random\n",
    "from spacy.util import minibatch\n",
    "# Get the Named Entity Recognizer component in the pipeline\n",
    "ner = nlp.get_pipe('ner')\n",
    "from spacy.training import Example\n",
    "from pathlib import Path\n",
    "\n",
    "# Add new entity labels to 'ner'\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for start,end,label in annotations.get('entities'):\n",
    "        #print(label)\n",
    "        ner.add_label(str(label))\n",
    "\n",
    "\n",
    "# Disable other pipes during training\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "\n",
    "\n",
    "# Begin training\n",
    "with nlp.disable_pipes(*unaffected_pipes):\n",
    "    if starting_fresh:\n",
    "        nlp.begin_training()\n",
    "\n",
    "    for itn in range(5):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "\n",
    "        # Batch up the examples using spaCy's minibatch\n",
    "        for batch in minibatch(TRAIN_DATA, size=2):\n",
    "            examples = []\n",
    "            for text, annotations in batch:\n",
    "                # Create a Spacy Doc from the text\n",
    "                doc = nlp.make_doc(text)\n",
    "                # Create an Example using the annotations\n",
    "                example = Example.from_dict(doc, annotations)\n",
    "                examples.append(example)\n",
    "\n",
    "            # Update the model\n",
    "            nlp.update(\n",
    "                examples,\n",
    "                drop=0.5,  # Dropout - make it harder to memorize data\n",
    "                losses=losses\n",
    "            )\n",
    "        print(losses)\n",
    "\n",
    "'''\n",
    "from pathlib import Path\n",
    "output_dir = Path('/Users/nyzy/nitzmali/job_transition_pathway/models/skills_tag_spacy_nlp_model')\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Saved model to\", output_dir)\n",
    "'''\n",
    "\n",
    "\n",
    "# Split your TRAIN_DATA into train, validate and test sets\n",
    "def train_test_val_split(data, test_size=0.2, val_size=0.25, random_state=42):\n",
    "    # Calculate actual validation set size of the remaining data after test split\n",
    "    val_size_adjusted = val_size / (1 - test_size)\n",
    "    # Split off test set from available data\n",
    "    train_val_data, test_data = train_test_split(data, test_size=test_size, random_state=random_state)\n",
    "    # Split remaining data into training and validation sets\n",
    "    train_data, val_data = train_test_split(train_val_data, test_size=val_size_adjusted, random_state=random_state)\n",
    "    return train_data, val_data, test_data\n",
    "train_data, val_data, test_data = train_test_val_split(TRAIN_DATA, test_size=0.2, val_size=0.25)\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "# Load the model you want to evaluate\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('/Users/nyzy/nitzmali/job_transition_pathway/models/skills_tag_spacy_nlp_model')  # replace with your model name\n",
    "\n",
    "# Split your TRAIN_DATA into train, validate and test sets\n",
    "train_data, val_data, test_data = train_test_val_split(TRAIN_DATA, test_size=0.2, val_size=0.25)\n",
    "\n",
    "# Convert the validation data to spaCy's Example format\n",
    "examples = []\n",
    "for input_, annots in val_data:\n",
    "    pred = nlp(input_)\n",
    "    example = Example.from_dict(pred, annots)\n",
    "    examples.append(example)\n",
    "\n",
    "\n",
    "# Use the Scorer to score the examples\n",
    "scorer = Scorer(nlp)\n",
    "scores = scorer.score(examples)\n",
    "\n",
    "\n",
    "precision = scores['ents_p']\n",
    "recall = scores['ents_r']\n",
    "f_score = scores['ents_f']\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F-score: {f_score}\")\n",
    "\n",
    "examples[0]\n",
    "\n",
    "\n",
    "# Assume 'nlp' is your loaded NLP model\n",
    "for text, annots in val_data[3:5]:  # Let's use val_data as an example\n",
    "    doc = nlp(text)  # Process the text to predict entities\n",
    "\n",
    "    '''\n",
    "    print(\"Predictions by model:\")\n",
    "    for ent in doc.ents:\n",
    "        print(\"Predictions\")\n",
    "        #print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\n",
    "    # Now print the correct data for comparison\n",
    "    print(\"\\nCorrect labels:\")\n",
    "    for start, end, label in annots['entities']:\n",
    "        print(\"Actual\")\n",
    "        #print(text[start:end], start, end, label)\n",
    "    '''\n",
    "    # You can use displacy here as well if you prefer visual comparison\n",
    "    displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "\n",
    "    # Adding a separation for readability between different examples\n",
    "    print(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17 (main, Jul  5 2023, 16:17:03) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75cbfe992e831883bebc34d351837a73fc44aae74ab7e2dffad989642b16aeb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
